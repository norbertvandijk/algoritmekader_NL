{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welkom bij het algoritmekader!","text":"<p>TL;DR</p> <p>Algoritmes en AI bieden kansen, maar ook risico\u2019s. Om ervoor te zorgen dat algoritmes en AI op een verantwoorde manier gebruikt worden en publieke waarden gewaarborgd zijn, maken we een interactief Algoritmekader, zodat organisaties in alle fasen van de levenscyclus van algoritmische en AI-toepassingen praktische handvatten hebben en weten aan welke vereisten zij zich moeten houden. </p> <p>De invloed van digitalisering is overal merkbaar in ons persoonlijke en zakelijke leven: het internet, smartphones, apps en online platformen zijn niet meer weg te denken uit ons dagelijks bestaan.  Dat geldt ook voor hoe de overheid haar werk doet.  Het gaat daarbij niet alleen om het aanbieden van digitale dienstverlening, maar ook om hoe de overheid beslissingen neemt. Algoritmes en AI bieden hierbij kansen, maar ook risico\u2019s.    </p> <p>Het is niet altijd herleidbaar wanneer algoritmes en AI gebruikt worden en of in die gevallen publieke waarden gewaarborgd zijn en hoe dat gebeurt.  Specifiek voor de overheid geldt dat het voor burgers en ondernemers duidelijk moet zijn wanneer een algoritme is gebruikt in besluitvorming, vooral wanneer dat potentieel impact heeft iemand zijn situatie.  Bovendien is belangrijk dat beslissingen niet worden ervaren als \u2018black box\u2019. </p>"},{"location":"#het-algoritmekader","title":"Het Algoritmekader","text":"<p>Waardengedreven met algoritmes en AI werken, betekent dat er aandacht moet zijn voor zaken als:</p> <ol> <li>rollen en verantwoordelijkheden (governance);</li> <li>risico\u2019s op bias/discriminatie vroegtijdig detecteren;</li> <li>het veilig kunnen verweken van gegevens;</li> <li>de uitvoering van mensenrechtentoetsen (zoals IAMA\u2019s);</li> <li>adequate inkoopvoorwaarden afspreken voor algoritmes die de overheid inkoopt bij derden. </li> </ol> <p>Aan deze opsomming zie je al dat op een verantwoorde manier met AI en algoritmes werken niet de verantwoordelijkheid is of kan zijn van \u00e9\u00e9n enkele professional in een organisatie.  Het vraagt bewustzijn en adequaat optreden van alle betrokkenen.  Van data scientists en beleidsmedewerkers, tot inkopers en bestuurders. En voor elk van deze professionals zijn andere vereisten en maatregelen relevant.  Daarom maken we een Algoritmekader dat voor elk van deze professionals op een praktische manier te raadplegen is. Waarbij ze niet stranden in een overload aan informatie, maar kunnen vinden wat voor hen nuttig is. </p> <p>Bij het bouwen aan het Algoritmekader maken we zoveel mogelijk gebruik van wat er al is: vereisten uit wet- en regelgeving en standaarden, maatregelen uit de praktijk (best practises) en instrumenten.  Het kader brengt dit samen op een logische manier in een interactieve kennisbank.  Zodat overheden in alle fasen van de levenscyclus van algoritmische en AI-toepassingen praktische handvatten hebben.  Het kader wordt een praktisch hulpmiddel om algoritmes en AI verantwoord te kunnen inzetten en te voldoen aan de (minimale) vereisten die wet- en regelgeving daaraan stellen. </p> <p>De informatie in het Algoritmekader is logisch aan elkaar gekoppeld, zodat gebruikers interactief door de informatie kunnen navigeren.  Je kunt starten vanuit de levenscyclus van een algoritme, de bouwblokken, de vereisten, maatregelen of rollen via het navigatiemenu.  De informatie is 'gelaagd' opgebouwd.  Dat betekent dat je kunt doorklikken om meer gedetailleerde informatie te raadplegen.  Je kunt ook de zoekbalk gebruiken. Daarnaast is het binnenkort mogelijk om een PDF-export te maken van de informatie op deze website.  </p> <p>We werken open en samen aan het Algoritmekader; iedereen kan deze ontwikkeling volgen en eraan bijdragen. We werken samen met verschillende overheidsorganisaties en kennisinstellingen.  Wil je hier meer over weten, lees dan verder op de pagina waar we dit toelichten. </p> <p>Disclaimer</p> <p>Het Algoritmekader is volop in ontwikkeling. Het is mogelijk dat je zaken in het kader tegenkomt die niet af of soms zelfs fout zijn. Mocht je denken dat er iets niet klopt, laat het ons weten via GitHub. We werken stap voor stap naar een inhoudelijk zo correct en dekkend mogelijk Algoritmekader.  </p>"},{"location":"#eerdere-versies-van-het-algoritmekader","title":"Eerdere versies van het algoritmekader","text":"<p>Zie het Implementatiekader dat in juni 2023 naar de Tweede Kamer is verzonden. </p>"},{"location":"#bijdragen-aan-het-algoritmekader","title":"Bijdragen aan het algoritmekader?","text":"<p>We ontwikkelen het Algoritmekader op een open manier via GitHub. Bekijk de ontwikkelomgeving van het Algoritmekader en lees onze Contributing Guidelines.</p>"},{"location":"#heb-je-een-vraag-of-opmerking","title":"Heb je een vraag of opmerking?","text":"<p>Neem contact op via GitHub of stuur een email naar algoritmes@minbzk.nl.</p> <p>Stuur een mail </p>"},{"location":"#wil-je-op-de-hoogte-blijven","title":"Wil je op de hoogte blijven?","text":"<p>Schrijf je in voor de maandelijkse nieuwsbrief over algoritmes. </p>"},{"location":"bouwblokken/","title":"Bouwblokken","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/#fundamentele-rechten","title":"Fundamentele rechten","text":"<p>Het bouwblok fundamentele rechten is opgesplitst in verschillende delen</p> <p> Naar fundamentele rechten</p>"},{"location":"bouwblokken/#publieke-inkoop","title":"Publieke inkoop","text":"<p>Op deze pagina vind je relevante informatie wanneer je als overheidsorganisatie algoritmes of AI wilt inkopen. </p> <p> Naar publieke inkoop</p>"},{"location":"bouwblokken/#privacy-en-gegevensbescherming","title":"Privacy en gegevensbescherming","text":"<p>Op deze pagina vind je relevante informatie over privacy en gegevensbescherming die van belang is wanneer je gebruik maakt van algoritmes of AI. </p> <p> Naar privacy en gegevensbescherming</p>"},{"location":"bouwblokken/#transparantie","title":"Transparantie","text":"<p>Op deze pagina vind je de relevantie informatie over transparantie die van belang is wanneer je gebruik maakt van algoritmes of AI.</p> <p> Naar transparantie</p>"},{"location":"bouwblokken/#bias-en-non-discriminatie","title":"Bias en non-discriminatie","text":"<p>Op deze pagina vind je de relevantie informatie over bias en non-discriminatie die van belang is wanneer je gebruik maakt van algoritmes of AI.</p> <p> Naar bias en non-discriminatie</p>"},{"location":"bouwblokken/#data","title":"Data","text":"<p>Hier kunnen we een korte tekst kwijt over data</p> <p> Naar data</p>"},{"location":"bouwblokken/#duurzaamheid","title":"Duurzaamheid","text":"<p>Hier kunnen we een korte tekst kwijt over duurzaamheid</p> <p> Naar duurzaamheid</p>"},{"location":"bouwblokken/#governance","title":"Governance","text":"<p>Hier kunnen we een korte tekst kwijt over governance</p> <p> Naar governance</p>"},{"location":"bouwblokken/#menselijke-controle","title":"Menselijke controle","text":"<p>Hier kunnen we een korte tekst kwijt over menselijke controle</p> <p> Naar menselijke controle</p>"},{"location":"bouwblokken/#technische-robuustheid-en-veiligheid","title":"Technische robuustheid en veiligheid","text":"<p>Hier kunnen we een korte tekst kwijt over technische robuustheid en veiligheid</p> <p> Naar technische robuustheid en veiligheid</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/","title":"Bias en non-discriminatie","text":""},{"location":"bouwblokken/bias-en-non-discriminatie/#wat-en-waarom","title":"Wat en waarom?","text":"<p>Algoritmes worden binnen de overheid veelvuldig ingezet om publieke taken uit te voeren. Dit biedt veel kansen, maar er zijn ook risico's aan verbonden. Hoewel algoritmes in sommige gevallen kunnen bijdragen aan het tegengaan van discriminatie, kan bias in het algoritme leiden tot een ongelijke en oneerlijke behandeling van burgers of groepen, en kan er sprake zijn van discriminerende effecten.  In dit bouwblok van het algoritmekader besteden we aandacht aan de onderwerpen bias, eerlijkheid en non-discriminatie.  We werken uit wat bias is, hoe bias kan ontstaan, hoe we dit kunnen signaleren, welke maatregelen er genomen kunnen worden om dit te voorkomen en geven we handvatten wat te doen wanneer een (onwenselijke) bias is gesignaleerd. </p> <p>Hierbij is het goed om op te merken dat het omgaan met het thema bias gedurende het ontwikkelen, inkopen of gebruik van het algoritme vraagt om continue aandacht voor dit onderwerp.  Het betreft geen probleem dat eenmalig kan worden weggenomen, maar het vraagt voortdurende reflectie op eerlijkheid en rechtvaardigheid van het systeem. </p> <p>Dit bouwblok wordt uitgewerkt in vereisten die weergeven wat er vanuit wet- en regelgeving en bestaande toetsingskaders vereist is om bias en discriminatie tegen te gaan.  Daarbij worden er suggesties gedaan hoe deze vereisten kunnen worden nageleefd met concrete maatregelen, en welke actoren daarbij betrokken kunnen zijn.  Waar mogelijk worden concrete voorbeelden en best practices uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is. Deze vereisten en maatregelen worden ook gekoppeld aan de algoritme levenscyclus.  Dit geeft een beeld van wanneer bepaalde vereisten of maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd.   </p> <p>Door bij de ontwikkeling van algoritmes rekening te houden met vereisten die voorkomen uit wet- en regelgeving, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. </p> <p>De onderwerpen bias en non-discriminatie spelen daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren. </p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#wat-is-bias","title":"Wat is bias?","text":"<p>Bias is een Engelse term die in het Nederlands wordt vertaald als vooringenomenheid, vooroordeel of neiging.  Omdat niet \u00e9\u00e9n van die termen helemaal de lading van het begrip bias dekt, maken we in het Algoritmekader gebruik van de term bias.  De term bias heeft verschillende betekenissen afhankelijk van de context waarin het gebruikt wordt en de disciplines die daarbij betrokken zijn.  Vaak wordt er naar bias gekeken als een technisch concept, maar het omvat daarnaast menselijke aspecten.  We maken we onderscheid tussen drie verschillende aspecten van bias: statistische bias, systemische bias en menselijke bias.</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#statistische-bias","title":"Statistische bias","text":"<p>Statistische bias wordt gedefinieerd als een consistente numerieke afwijking van een schatting ten opzichte van de werkelijke onderliggende waarde.<sup>1</sup> Dit fenomeen kan in allerlei verschillende contexten plaatsvinden, niet alleen bij het gebruik van algoritmes of AI.  Een voorbeeld is wanneer een bepaalde meting van een waarde niet goed gekalibreerd is en er sprake is van een consistente afwijking van de te meten waarde (bijvoorbeeld dat we consistent 10% hoger meten). </p> <p>In de context van algoritmes en AI kan deze vorm van bias voorkomen wanneer er een steekproef wordt gebruikt die niet representatief is voor de populatie, en de schattingen op basis van de steekproef vervolgens systematisch afwijken van de werkelijke waarde in de gebruikte doelpopulatie. Statistische bias duidt op een systematische fout die gemaakt wordt door het algoritme.  Deze fout kan hetzelfde zijn voor alle groepen en hoeft daardoor niet in alle gevallen te duiden op ongelijke behandeling of discriminerende effecten.  Voorbeelden van statistische bias zijn meetfouten (measurement bias), foute data of data op een te simpele manier representeren (representatie bias).</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#systemische-bias","title":"Systemische bias","text":"<p>We spreken van systemische bias als er sprake is van een systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.<sup>1</sup> Dit systematische verschil of onderscheid kan zowel op een directe als op een indirecte manier ontstaan. </p> <p>De Algemene wet gelijke behandeling spreekt van direct onderscheid wanneer een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat.</p> <p>De Algemene wet gelijke behandeling spreekt van indirect onderscheid indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat in vergelijking met andere personen bijzonder treft. </p> <p>Een geconstateerd systematische onderscheid is niet altijd fout en is niet altijd verboden.  Het geconstateerde onderscheid kan in bepaalde situaties en onder bepaalde strikte voorwaarden gerechtvaardigd zijn.  Voor direct onderscheid kan er bijvoorbeeld sprake zijn van een wettelijke uitzondering die het gemaakte onderscheid toelaat.  Voor indirect onderscheid geldt dat behalve een wettelijke uitzondering er ook een objectieve rechtvaardiging kan bestaan, waarmee het geconstateerde onderscheid in bepaalde gevallen toelaatbaar kan zijn. </p> <p>Het maken van een eventueel onderscheid is in sommige gevallen nauw verbonden met het gebruik van algoritmes en AI.  Soms worden algoritmes en AI bijvoorbeeld juist ingezet om op een zo objectief mogelijke manier te bepalen welke groepen meer of minder belang hebben bij een andere behandeling.  In deze gevallen zal er altijd na moeten worden gegaan of er sprake is van een objectieve rechtvaardiging voor het gemaakte onderscheid.</p> <p>In de context van algoritmes en AI wordt de term unfairness gebruikt wanneer er sprake is van een ongerechtvaardigd onderscheid waarbij bepaalde groepen meer bevoordeeld worden dan andere.<sup>2</sup>  In de Nederlandse taal spreken we dan van oneerlijkheid of onrechtvaardigheid (of in positieve zin van respectievelijk fairness, eerlijkheid en rechtvaardigheid). </p> <p>Ongerechtvaardigde systemische bias kan voorkomen wanneer bepaalde processen of systemen op zo'n wijze worden gebruikt dat bepaalde groepen bevoordeeld worden en andere groepen benadeeld worden. Dit is vaak geen bewuste vorm van vooringenomenheid, maar kan bijvoorbeeld ontstaan doordat de meerderheid bestaande regels of normen volgt, en het systeem geoptimaliseerd is op de meerderheid.</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#menselijke-bias","title":"Menselijke bias","text":"<p>Menselijke bias omvat systematische fouten in het menselijk denken.  Deze menselijke vooroordelen zijn vaak impliciet van aard en hebben betrekking op de manier waarop een individu bepaalde informatie waarneemt en verwerkt om bijvoorbeeld een beslissing te nemen.  In de context van algoritmes kan deze vorm van bias invloed hebben op de verzamelde data, op de wijze waarop het algoritme wordt geoptimaliseerd en de besluiten die door mensen worden genomen op basis van het algoritme. Voorbeelden van vormen menselijke bias zijn wanneer er voorkeur wordt geven aan de voorspellingen van een algoritme die reeds bestaande overtuigingen bevestigen (bevestigingsbias), of wanneer mensen de neiging hebben om voorkeur te geven aan suggesties die door het algoritme worden gedaan (automatiseringsbias)</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#gebruikte-definities","title":"Gebruikte definities","text":"<p>Onderstaand bieden we een overzicht van de gebruikte definities in het algoritmekader die betrekking hebben op het onderwerp bias en non-discriminatie. </p> Term of begrip Definitie Bron direct onderscheid indien een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat Algemene wet gelijke behandeling indirect onderscheid indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat in vergelijking met andere personen bijzonder treft. Algemene wet gelijke behandeling discriminatie mensen anders behandelen, achterstellen of uitsluiten op basis van (persoonlijke) kenmerken. College voor de rechten van de mens directe discriminatie de ongelijke behandeling van een persoon of groep personen ten opzichte van andere personen in een vergelijkbare situatie, op grond van een beschermd persoonskenmerk (discriminatiegrond). College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader indirecte discriminatie wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaald beschermd persoonskenmerk (discriminatiegrond) in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader algoritmische fairness het vakgebied dat bestudeert hoe algoritmische systemen zich moeten gedragen om mensen eerlijk te behandelen, dat wil zeggen zonder discriminatie op grond van beschermde gevoelige kenmerken zoals leeftijd, geslacht, handicap, etnische of raciale afkomst, religie of geloofsovertuiging, of seksuele geaardheid The fairness handbook ground truth (NL vertaling?) waarde van de doelvariabele voor een bepaald item van gelabelde invoergegevens. <sup>4</sup> NEN-EN-ISO/IEC 22989:2023 en <sup>3</sup> etnisch profileren Het gebruik door overheidsinstanties van selectiecriteria als ras, huidskleur, taal, religie, nationaliteit of nationale of etnische afkomst bij de uitoefening van toezichts-, handhavings- en opsporingsbevoegdheden, zonder dat daarvoor een objectieve en redelijke rechtvaardiging bestaat. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader discriminatiegrond Beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Bijvoorbeeld: ras, nationaliteit, religie, geslacht, seksuele gerichtheid, handicap of chronische ziekte College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader risicoprofiel Een verzameling van \u00e9\u00e9n of meer selectiecriteria op basis waarvan een bepaald risico op normovertreding wordt ingeschat en een selectiebeslissing wordt gemaakt. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader groep deelverzameling van objecten in een domein die zijn gekoppeld omdat ze gemeenschappelijke kenmerken hebben. ISO/IEC TR 24027:2021 en <sup>3</sup> <p>Omdat bias op verschillende manieren kan ontstaan, zijn er allerlei verschillende vormen van bias, die hieronder gedefinieerd worden. Deze lijst is niet uitputtend. </p> Begrip Definitie Bron automatiseringsbias de neiging van mensen om de voorkeur te geven aan suggesties van geautomatiseerde besluitvormingssystemen en om tegenstrijdige informatie te negeren die zonder automatisering is verkregen, zelfs als deze correct is ISO/IEC TR 24027:2021 en <sup>3</sup> data bias dataeigenschappen die, als ze niet worden aangepakt, leiden tot AI-systemen die beter of slechter presteren voor verschillende groepen ISO/IEC TR 24027:2021 en <sup>3</sup> statistische bias soort consistente numerieke afwijking in een schatting ten opzichte van de werkelijke onderliggende waarde, inherent aan de meeste schattingen ISO/IEC TR 24027:2021 en <sup>3</sup> historische bias verwijzend naar de langdurige vooroordelen die in de loop der tijd in de samenleving zijn gecodeerd. Verwant aan, maar verschillend van, vooroordelen in historische beschrijving, of de interpretatie, analyse en verklaring van de geschiedenis. Een veel voorkomend voorbeeld van historische vooringenomenheid is de neiging om de wereld te bekijken vanuit een Westers of Europees perspectief NIST, Towards a Standard for identifying and managing bias in artificial intelligence activiteitenbias een soort selectievooroordeel dat optreedt wanneer systemen/platforms hun trainingsgegevens krijgen van de meest actieve gebruikers, in plaats van minder actieve (of inactieve) gebruikers. NIST, Towards a Standard for identifying and managing bias in artificial intelligence versterkingsbias ontstaat wanneer de verdeling over voorspellingsoutputs scheef is in vergelijking met de prior-verdeling van het voorspellingsdoel. NIST, Towards a Standard for identifying and managing bias in artificial intelligence cognitieve bias een brede term die in het algemeen verwijst naar een systematisch patroon van afwijking van rationele oordeels- en besluitvorming. In vele decennia van onderzoek naar oordeelsvorming en besluitvorming is een grote verscheidenheid aan cognitieve vertekeningen ge\u00efdentificeerd, waarvan sommige adaptieve mentale snelkoppelingen zijn die bekend staan als heuristieken. NIST, Towards a Standard for identifying and managing bias in artificial intelligence bevestigingsbias soort menselijke cognitieve bias die de voorkeur geeft aan voorspellingen van AI-systemen die reeds bestaande overtuigingen of hypotheses bevestigen ISO/IEC TR 24027:2021 en <sup>3</sup> verankeringsbias een cognitieve bias, de invloed van een bepaald referentiepunt of anker op de beslissingen van mensen. Vaak vollediger aangeduid als anchoring-and-adjustment, of anchoring-and-adjusting: nadat een anker is vastgesteld, passen mensen zich onvoldoende aan vanuit dat ankerpunt om tot een definitief antwoord te komen. Beslissers zijn bevooroordeeld ten opzichte van een aanvankelijk gepresenteerde waarde NIST, Towards a Standard for identifying and managing bias in artificial intelligence gedragsbias systematische verstoringen in gebruikersgedrag tussen platforms of contexten, of tussen gebruikers die zijn vertegenwoordigd in verschillende datasets NIST, Towards a Standard for identifying and managing bias in artificial intelligence implementatie bias ontstaat wanneer systemen worden gebruikt als beslissingshulp voor mensen, omdat de menselijke tussenpersoon kan handelen op voorspellingen op manieren die meestal niet zijn gemodelleerd in het systeem. Het zijn echter nog steeds individuen die het gebruikte systeem gebruiken NIST, Towards a Standard for identifying and managing bias in artificial intelligence evaluatie bias ontstaat wanneer de test- of externe benchmarkpopulaties niet in gelijke mate de verschillende delen van de gebruikerspopulatie vertegenwoordigen of door het gebruik van prestatiemaatstaven die niet geschikt zijn voor de manier waarop het model zal worden gebruikt NIST, Towards a Standard for identifying and managing bias in artificial intelligence meetbias ontstaat wanneer kenmerken en labels benaderingen zijn voor gewenste grootheden, waarbij mogelijk belangrijke factoren worden weggelaten of groeps- of ingangsafhankelijke ruis wordt ge\u00efntroduceerd die leidt tot differenti\u00eble prestaties. NIST, Towards a Standard for identifying and managing bias in artificial intelligence representatie bias ontstaat doordat subgroepen niet willekeurig worden geselecteerd in een steekproef, waardoor trends die voor \u00e9\u00e9n populatie worden geschat, niet generaliseerbaar zijn naar gegevens van een nieuwe populatie NIST, Towards a Standard for identifying and managing bias in artificial intelligence systemische bias systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met andere. ISO/IEC TR 24027:2021 en <sup>3</sup>"},{"location":"bouwblokken/bias-en-non-discriminatie/#discriminatiegrond","title":"Discriminatiegrond","text":"<p>De discriminatiegrond beschrijft de beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Deze gronden zijn in verschillende bronnen vastgelegd. </p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#de-grondwet","title":"De grondwet","text":"<p>De Grondwet stelt dat discriminatie wegens:</p> <ul> <li>godsdienst </li> <li>levensovertuiging </li> <li>politieke gezindheid </li> <li>ras </li> <li>geslacht </li> <li>handicap</li> <li>seksuele gerichtheid</li> <li>of op welke grond dan ook</li> </ul> <p>niet is toegestaan. </p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#europees-verdrag-voor-de-rechten-van-de-mens","title":"Europees Verdrag voor de Rechten van de Mens","text":"<p>Het Europees Verdrag voor de Rechten van de Mens, artikel 14 stelt dat het genot van de rechten en vrijheden die in dat verdrag zijn vermeld, moet worden verzekerd zonder enig onderscheid op welke grond dan ook, zoals:</p> <ul> <li>geslacht</li> <li>ras</li> <li>kleur</li> <li>taal</li> <li>godsdienst</li> <li>politieke of andere mening</li> <li>nationale of maatschappelijke afkomst</li> <li>het behoren tot een nationale minderheid</li> <li>vermogen</li> <li>geboorte</li> <li>of andere status. </li> </ul>"},{"location":"bouwblokken/bias-en-non-discriminatie/#handvest-van-de-grondrechten-van-de-europese-unie","title":"Handvest van de grondrechten van de Europese Unie","text":"<p>Het Handvest van de grondrechten van de Europese Unie, artikel 21 stelt dat iedere discriminatie, met name op grond van:</p> <ul> <li>geslacht</li> <li>ras</li> <li>kleur</li> <li>etnische of sociale afkomst</li> <li>genetische kenmerken</li> <li>taal</li> <li>godsdienst</li> <li>politieke of andere denkbeelden</li> <li>het behoren tot een nationale minderheid</li> <li>vermogen</li> <li>geboorte</li> <li>een handicap</li> <li>leeftijd</li> <li>of seksuele gerichtheid</li> </ul> <p>is verboden. Daarnaast wordt expliciet vermeld dat binnen de werkingssfeer van de Verdragen en onverminderd de bijzondere bepalingen ervan, iedere discriminatie op grond van nationaliteit verboden is.</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#aanbevelingen","title":"Aanbevelingen","text":"<p>Rathenau</p> <ul> <li>Geef als uitvoeringsorganisatie meer inzicht in hoe biastoetsing plaatsvindt </li> <li>Zet een nationaal kennisplatform voor biastoetsing op waar expertise kan worden ontwikkeld en gedeeld. Bepaal welke mate van standaardisatie gewenst is en of wettelijke eisen nodig zijn.</li> </ul> <p>ADR</p> <ul> <li>Plaats de handreiking in een kader in relatie tot andere instrumenten </li> <li>Overweeg een risicogerichte benadering voor de toepassing van de handreiking </li> <li>Werk aan het vergroten van bewustzijn voor algoritmen en (data-)ethiek in de organisatie </li> <li>Zorg voor duidelijkheid in taken en verantwoordelijkheden van verschillende betrokkenen </li> <li>Beleg verantwoordelijkheid voor de handreiking en borg de (blijvende) aandacht ervoor </li> <li>Verplichte toepassing van de handreiking kan bestaande initiatieven tenietdoen </li> </ul> <p>Toetsingskader ADR</p> <ul> <li>De definitie van de verschillende groepen en de gewenste prestatie van het model voor deze groepen zijn opgenomen in de functionele eisen.</li> <li>De mate van geaccepteerde bias in de uitkomst is opgenomen in de functionele eisen en uitgewerkt in meetbare prestatiecriteria.</li> <li>De methoden om bias te voorkomen, detecteren en corrigeren zijn vastgelegd.</li> <li>De mate van bias in de data, dataverzameling en het model zijn in kaart gebracht.</li> <li>Tijdens de ontwikkeling van het model is beoordeeld of er een verschil bestaat tussen de prestatie van het model tussen verschillende subgroepen. De prestatiemetrieken afleidbaar uit de confusionmatrix zijn vergeleken voor deze subgroepen.</li> <li>De uitkomstbias van productiedata is beoordeeld voor de verschillende subgroepen en voldoet aan de prestatiecriteria.</li> <li>Bij de geconstateerde bias is beoordeeld of deze op discriminatie duidt.</li> </ul> <p>College voor de Rechten van de Mens (Richtlijnen)</p> <ul> <li>Overheidsinstanties mogen bij opsporings- en handhavingsbevoegdheden, met het oog op effectiviteit, effici\u00ebntie en kostenbesparing, gebruik maken van risicoprofielen. Binnen deze risicoprofielen mogen ervaringsgegevens die tot een bepaalde vooronderstelling leiden een rol spelen, tenzij dit leidt tot discriminatie op grond van ras of nationaliteit</li> <li>Risicoprofielen die uitsluitend of in doorslaggevende mate gebaseerd zijn op ras (waaronder etniciteit en afkomst) zijn in strijd met het discriminatieverbod;</li> <li>Risicoprofielen die zich richten op \u00e9\u00e9n bepaalde afkomst of nationaliteit hebben een stigmatiserend effect en zijn daarom strijdig met het discriminatieverbod;</li> <li>Risicoprofielen die uitsluitend gebaseerd zijn op nationaliteit zijn zeer moeilijk te rechtvaardigen;</li> <li>Risicoprofielen waarin ras of nationaliteit mede een rol speelt, kunnen slechts gerechtvaardigd worden door zeer zwaarwegende redenen;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel is nooit toegestaan als er geen objectieve relatie kan worden aangetoond tussen dit selectiecriterium en het legitieme doel van het profiel;</li> <li>In alle gevallen moeten de selectiecriteria  binnen een risicoprofiel samen voldoende relevant en objectief (geschikt) zijn om op een effectieve wijze bij te dragen aan de verwezenlijking van het nagestreefde legitieme doel;</li> <li>Het gebruik van ras of nationaliteit als selectiecriterium binnen een risicoprofiel moet daarnaast noodzakelijk zijn om het gewenste doel tebereiken.</li> <li>Selectiebeslissingen moeten te allen tijde uitlegbaar zijn.</li> </ul>"},{"location":"bouwblokken/bias-en-non-discriminatie/#mogelijke-hulpmiddelen-en-methoden","title":"Mogelijke hulpmiddelen en methoden","text":"<ul> <li>Fairness Handbook</li> <li>Handreiking non-discriminatie-by-design</li> <li>College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader</li> </ul> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"bouwblokken/bias-en-non-discriminatie/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/bias-en-non-discriminatie/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg <ol> <li> <p>Zie ISO/IEC TR 24027:2021 en <sup>3</sup> \u21a9\u21a9</p> </li> <li> <p>Zie NEN-EN-ISO/IEC 22989:2023 en <sup>3</sup> \u21a9</p> </li> <li> <p>Hoewel het gebruik van de NEN-ISO-normen in het Algoritmekader auteursrechtelijk is beschermd, heeft het Nederlands Normalisatie Instituut (NEN) voor het gebruik in het Algoritmekader toestemming verleend. Zie nen.nl voor meer informatie over NEN en het gebruik van hun producten.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>De term ground truth impliceert niet dat de gelabelde invoergegevens consistent overeenkomen met de werkelijke waarde van de doelvariabelen.\u00a0\u21a9</p> </li> </ol>"},{"location":"bouwblokken/data/","title":"Data","text":"<p>Het ontwikkelen en gebruiken van algoritmes en AI-systemen kan niet gepaard gaan zonder het verwerken van data.  In het geval van AI wordt data gebruikt om het algoritme te trainen, te valideren en te testen. </p> <p>Wanneer beslissingen worden genomen op basis van de output van een algoritme of AI-systeem, dan wordt dit ook gedaan op basis van de onderliggende data.  Om algoritmes en AI-systemen op een verantwoorde manier toe te passen, dient dus ook de data op een verantwoorde en rechtmatige manier te worden gebruikt. </p> <p>In dit bouwblok werken we uit welke vereisten er zijn voor verantwoord datagebruik, en geven we praktische maatregelen hoe dit ingevuld kan worden binnen overheidsorganisaties.  We zoeken hierbij de aansluiting op bestaande instrumenten, zoals de Toolbox verantwoord datagebruik.  </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"bouwblokken/data/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenVerdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan."},{"location":"bouwblokken/data/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegControleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is."},{"location":"bouwblokken/data/#nuttige-informatie","title":"Nuttige informatie","text":"<ul> <li>FAIR data: GO FAIR Foundation.</li> </ul>"},{"location":"bouwblokken/data/FAIR%20data/","title":"FAIR data","text":"<p>Het doel van de principes voor FAIR data is waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar maken binnen en buiten de eigen organisatie. Nadrukkelijk niet alleen voor menselijke gebruikers maar juist ook voor machines. Voldoen aan de principes voor FAIR data maakt data \"machine actionable\", daarom wordt het acronym FAIR ook wel uitgelegd als \"Fully AI Ready\". De principes voor FAIR data worden beheerd door de Nedelndse stichting GO FAIR Foundation. De naleving van de FAIR Guiding Principes krijgt een wettelijke grondslag in de Wet Hergebruik Overheidsinformatie.</p>"},{"location":"bouwblokken/duurzaamheid/","title":"Duurzaamheid","text":"<p>Onze impact op natuur en milieu is groot.  Er zijn grote doelen gesteld om duurzamer te gaan leven en werken. Binnen alle overheidsorganisaties, op allerlei verschillende gebieden, wordt gekeken hoe er duurzamer te werk kan worden gegaan, dus ook bij ICT-voorzieningen. </p> <p>Bij het duurzamer maken van ICT kan gedacht worden aan de fysieke kant (hardware) en de digitale kant (software, algoritmes). Met betrekking tot hardware kan men bijvoorbeeld zo duurzaam mogelijk hardware inkopen (circulariteit van apparaten en materialen) en proberen de levensduur van apparaten en onderdelen te maximaliseren. Bij ontwikkeling en inzet van software, zoals algoritmen, zal gekeken moeten worden naar andere zaken, zoals energieverbruik van het trainen van complexe modellen. In het Algoritmekader gaan we specifiek in op deze duurzaamheidsaspecten van algoritmes en AI-systemen. </p>"},{"location":"bouwblokken/duurzaamheid/#duurzaamheid-algoritmes-en-ai-systemen","title":"Duurzaamheid algoritmes en AI-systemen","text":"<p>Het concept duurzaamheid is een groot en generiek begrip, dat vele sub-thema\u2019s introduceert.  Deze thema\u2019s raken onder andere het ontwerp, de ontwikkeling en de inzet van algoritmes en AI-systemen.  Met de opkomst van grotere en ingewikkeldere modellen, grotere datasets, en de groeiende interesse in (generatieve) AI, groeit ook het energie- en waterverbruik. Dit verbruik ontstaat ook bij het trainen van grotere en complexere rekenmodellen zoals Large Language Models, en de opslag van zeer grote (vaak multimediale) datasets in datacenter. </p> <p>Dit bouwblok van het Algoritmekader biedt een gestructureerd overzicht van vereisten, maatregelen en instrumenten die ondersteunen bij het ontwikkelen en toepassen van algoritmes en AI-systemen op een duurzame wijze. Zo kunnen bewuste keuzes worden gemaakt die niet alleen voldoen aan de functionaliteiten, maar ook bijdragen aan de Sustainable Development Goals (SDG's) en de doelstellingen uit het Nederlandse klimaatakkoord. Bij duurzame ontwikkeling en toepassing van algoritmes kan bijvoorbeeld gedacht worden aan energie-effici\u00ebnte programmering en duurzaam datacenterbeheer. </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vindt je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"bouwblokken/duurzaamheid/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"bouwblokken/duurzaamheid/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg"},{"location":"bouwblokken/fundamentele-rechten/","title":"Fundamentele rechten","text":"<p>Wanneer overheden publieke taken uitvoeren, dienen fundamentele rechten van burgers te worden beschermd.  Dat geldt ook als overheden gebruik maken van algoritmes of AI-systemen om hun plublieke taken uit te voeren.  </p> <p>In Nederland beschermen we onze grondrechten met de Grondwet en met (internationale) mensenrechtenverdragen, zoals het Europees Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden (EVRM). Mensenrechtenverdragen bevatten een aantal fundamentele rechten en vrijheden die niet in de Grondwet staan.  </p> <p>Afhankelijk van de werking van algoritmes en AI-systemen en de publieke taak die wordt ondersteund, kunnen verschillende grondrechten worden geraakt.  Denk hierbij aan het verbod op ongelijke behandeling of het recht op eerbiediging van de persoonlijke levenssfeer.  Het is van belang hier in een vroeg stadium aandacht aan te besteden door dit te analyseren.  Een zorgvuldige aanpak tijdens de ontwikkeling van een algoritme kan ervoor zorgen dat er tijdig wordt geanticipeerd en maatregelen worden getroffen om een ongerechtvaardigde inbreuk op grondrechten te voorkomen. </p> <p>Een aantal wezenlijke grondrechten die vaak worden geraakt met de inzet van algoritmen en AI, komen ook afzonderlijk in andere onderdelen van het Algoritmekader aan bod. </p> <p>Dit geldt bijvoorbeeld op het recht op persoonsgegevensbescherming in het bouwblok Privacy en gegevensbescherming of het verbod op ongelijke behandeling in het bouwblok Bias en non-discriminatie.  </p> <p>In dit bouwblok van het algoritmekader beschrijven we wat de vereisten zijn rondom het beschermen van fundamentele rechten.  Vervolgens worden deze vereisten ook vertaald in praktische maatregelen en instrumenten die overheden kunnen toepassen om invulling te geven aan deze vereisten.  </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p> <p>Onderdeel van het bouwblok Fundamentele rechten is het onderwerp Bias en non-discriminatie. </p>"},{"location":"bouwblokken/fundamentele-rechten/#vereisten","title":"Vereisten","text":"VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Klachtrecht aanbieders verder in AI-waardeketenAanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"bouwblokken/fundamentele-rechten/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBetrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Kwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden."},{"location":"bouwblokken/fundamentele-rechten/#instrumenten","title":"Instrumenten","text":"InstrumentUitlegImpact Assessment Mensenrechten en AlgoritmesHet Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen."},{"location":"bouwblokken/menselijke-controle/","title":"Menselijke controle","text":"<p>Bij het uitvoeren van publieke taken is het van belang dat natuurlijke personen kunnen controleren of deze taken correct worden uitgevoerd en dat er kan worden bijgestuurd als dat nodig is.  Datzelfde geldt voor als een overheidsinstantie algoritmes of AI-systemen gebruiken bij het ondersteunen van deze taken. Het is van belang dat zowel bij de ontwikkeling en als het gebruik door natuurlijke personen kan worden ingegrepen en dat er sprake is van betekenisvolle menselijke tussenkomst waar dat nodig is.  Hier kan worden gedacht aan het verkeerd (gaan) werken van een AI-systeem en dat hierdoor de output onbetrouwbaar en onjuist wordt. In dergelijke gevallen zal een natuurlijk persoon in staat moeten zijn om deze situatie te signaleren en het algoritme of AI-systeem (tijdelijk) te kunnen stoppen.  </p> <p>Het verschilt, afgewogen tegen de potenti\u00eble negatieve gevolgen of risico's voor personen, welke mechanismen moeten worden ingericht in en rondom algoritmes en AI-systemen.  Hoog risico AI-systemen zullen een intensiever inrichting van menselijke controle nodig hebben, bijvoorbeeld met meerdere mensen die de output controleren, dan algoritmes die niet impact vol zijn.  Om deze controles uit te kunnen voeren zullen deze personen moeten beschikken over de noodzakelijke competenties, opleiding en bevoegdheden om deze taak uit te voeren. Er zullen ook functionele eisen aan het systeem moeten worden gesteld, zodat ook daadwerkelijk kan worden ingegrepen.  Hierbij kan worden gedacht aan een stopknop die kan worden gebruikt waarmee die werking van het algoritme of AI-systeem kan worden gepauzeerd.  Gedurende de gehele levenscyclus is het van belang dat menselijke controle wordt gepositioneerd en dat bijbehorende taken goed kunnen worden uitgevoerd. </p> <p>In dit bouwblok van het Algoritmekader wordt uitgewerkt aan welke vereisten moet worden voldaan met betrekking menselijke controle.  Dit wordt aangevuld met praktische maatregelen die kunnen worden toegepast ter inspiratie voor organisaties. Deze vereisten en maatregelen worden gekoppeld aan de levenscyclus, zodat zowel bij de ontwikkeling als het gebruik kan worden geraadpleegd hoe organisaties invulling kunnen geven aan menselijk controle.  </p>"},{"location":"bouwblokken/menselijke-controle/#vereisten","title":"Vereisten","text":"VereisteUitlegBevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemGebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI VerordeningToezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen."},{"location":"bouwblokken/menselijke-controle/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/privacy-en-gegevensbescherming/","title":"Privacy en gegevensbescherming","text":"<p>Overheidsinstanties verwerken vaak persoonsgegevens om hun taken uit te voeren en maatschappelijke waarden te cre\u00ebren. Met de opkomst van algoritmes en kunstmatige intelligentie (AI) worden deze gegevens steeds vaker gebruikt om processen te optimaliseren, zoals bij het beoordelen van subsidieaanvragen of het verlenen van vergunningen.  </p> <p>Bij het gebruik van algoritmes en AI-systemen is van groot belang om aandacht te besteden aan privacy en gegevensbescherming. Deze technologie\u00ebn vari\u00ebren van eenvoudige rekenregels tot complexe machine learning-modellen en generatieve AI, elk met hun eigen specifieke risico\u2019s.  Bijvoorbeeld, eenvoudige AI kan basisberekeningen uitvoeren, terwijl complexere AI-voorspellingen kan doen of informatie kan genereren. Ongeacht de complexiteit is het identificeren van risico\u2019s en het implementeren van passende beheersmaatregelen essentieel om de privacy van burgers te waarborgen en gevoelige gegevens te beschermen. </p> <p>Bij de inzet van AI in de publieke sector moeten overheidsinstanties rekening houden met de vereisten uit privacywetgeving, zoals de Algemene Verordening Gegevensbescherming (AVG). Dit omvat onder andere het minimaliseren van gegevensgebruik, implementeren van een privacy by design werkwijze waar mogelijk, en het transparant zijn over hoe en waarom (persoons)gegevens worden verwerkt.  Het toewijzen van verantwoordelijkheden en het opstellen van duidelijke richtlijnen voor gegevensverwerking zijn belangrijke stappen in dit proces. </p> <p>Het bouwblok privacy en gegevensbescherming van algoritmen en AI-systemen wordt ook ge\u00efntegreerd in de algoritmelevenscyclus.  Dit biedt inzicht in wanneer specifieke vereisten en maatregelen tijdens de ontwikkeling van algoritmen en AI-systemen moeten worden toegepast.  Door deze vereisten in de levenscyclus te integreren, kunnen de gebruikers inzichten opdoen wanneer deze maatregelen kunnen worden ge\u00efmplementeerd. </p>"},{"location":"bouwblokken/privacy-en-gegevensbescherming/#vereisten","title":"Vereisten","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"bouwblokken/privacy-en-gegevensbescherming/#maatregelen","title":"Maatregelen","text":""},{"location":"bouwblokken/publieke-inkoop/","title":"Publieke inkoop","text":"<p>Door middel van publieke inkoop wordt door overheidsinstellingen software ingekocht. Deze software wordt ingekocht om ambtenaren te ondersteunen met hun werkzaamheden om zo maatschappelijk waarden te cre\u00ebren. Het kan bijvoorbeeld gaan om het inkopen van een systeem waarmee een aanvraag voor een subsidie of vergunning kan worden behandeld. Het virtueel vergaderen of het digitaal samenwerken aan documenten zijn hier ook voorbeelden van. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Software met algoritmen  en AI wordt vaak ontwikkeld door gespecialiseerde aanbieders en bevat steeds meer algoritmen en AI. Het komt ook voor dat de overheid deze technologie zelf ontwikkelt. Deze algoritmen en AI kunnen eenvoudig van aard zijn, zoals het maken van een eenvoudige berekening. Zij kunnen complexer van aard zijn, zoals een voorspelling geven of het genereren van informatie. In het laatste geval kan worden gedacht aan ChatGPT, Google Bard of Co-Pilot. Er zijn verschillende type technologie\u00ebn die vallen onder het bereik van algoritmen en AI. In dit kader drukken we deze uit als \u2018rekenregel\u2019, \u2018machine learning\u2019 en \u2018generatieve AI\u2019. Elke technologie heeft eigen bijzondere aandachtspunten. Ook de bijbehorende risico\u2019s kunnen per type verschillen. Het identificeren van deze risico\u2019s en het treffen van beheersmaatregelen is daarbij van belang. Dat geldt in het bijzonder als algoritmen en AI bijdragen aan de totstandkoming van overheidsbesluitvorming en impactvolle beslissingen die burgers en ondernemingen raken. </p> <p>Door bij publieke inkoop van software met algoritmen en AI rekening te houden met vereisten die voorkomen uit wet- en regelgeving, toepassen van publieke waarden, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. Publieke inkoop speelt daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren.  In dit deel van het Algoritmekader wordt nader ingegaan op deze vereisten. Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd en welke rollen daarbij betrokken kunnen zijn. Waar mogelijk worden concrete voorbeelden uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.</p> <p>Het publiek inkopen van algoritmen en AI wordt ook gekoppeld aan de algoritme levenscyclus. Dit geeft een beeld van wanneer bepaalde vereisten en maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd. Door deze vereisten ook te vertalen naar het inkoopproces, zullen de rollen binnen het inkoopproces beter in staat zijn om te duiden wanneer en hoe dit kan worden geadresseerd. Dit moet bijdragen aan een goed samenspel met aanbieders, zodat de kansen van algoritmen en AI worden benut en de negatieve gevolgen worden voorkomen.  </p>"},{"location":"bouwblokken/publieke-inkoop/#algoritme-levenscyclus","title":"Algoritme levenscyclus","text":"<p>Algoritmen en AI kunnen een grote impact hebben op onze maatschappij. Daarom is het van belang dat deze op een verantwoorde manier worden ontwikkeld en gebruikt. Het toepassen van de algoritme levenscyclus is hierover een bruikbare leidraad. De algoritme levenscyclus bestaat uit meerdere fasen. De werkzaamheden die noodzakelijk zijn om een verantwoord algoritme of AI te ontwikkelen, kunnen logisch worden gekoppeld aan deze fasen.  Deze levenscyclus kan worden gebruikt voor alle typen algoritmen en AI. Het verschilt uiteraard wel per type wat moet worden gedaan en dit is mede afhankelijk van de risico classificatie. Bij hoge risico toepassing zal meer moeten worden gedaan om risico\u2019s te mitigeren dan als er sprake is van lage risico toepassingen. De levenscyclus geeft een bruikbaar overzicht voor leveranciers en opdrachtgevers wanneer welke werkzaamheden moeten worden uitgevoerd. Het laat ook zien welke werkzaamheden moeten zijn afgerond als algoritmen en AI in de markt mogen worden gezet en klaar zijn voor gebruik. </p> <p>Bij het publiek inkopen van software met bijbehorende algoritmen en AI zijn de wensen van de behoeftesteller en de doelstellingen van de organisatie van groot belang. Dit kan tot verschillende situaties leiden:</p> <p>\u2022   Een al ontwikkelde kant-en-klare oplossing voldoet direct aan deze wensen en doelstellingen;</p> <p>\u2022   Een al ontwikkelde oplossing moet eerst worden aangepast voordat deze kan worden gebruikt;</p> <p>\u2022   Er moet een nieuwe oplossing worden ontwikkeld om te voldoen aan de wensen. </p> <p>Deze inschatting is dus bepalend wat wel en niet van een product mag worden verwacht. Dit is relevant voor zowel de leverancier als de opdrachtgever. Het is aannemelijk dat als het om risicovolle (nog te ontwikkelen) algoritmen of AI gaat, de opdrachtgever een intensieve bijdrage moet leveren aan de samenwerking om het product te kunnen gebruiken. De opdrachtgever zal bijvoorbeeld moeten aangeven wat de juridische en ethische grenzen zijn van de uiteindelijk werking van het algoritme of AI. Als een kant-en-klare oplossing wordt afgenomen, dan zal de leverancier moeten laten zien dat de ontwikkelde algoritmen en AI voldoen aan alle vereisten en moet dit kunnen aantonen. </p> <p>De inzichten uit de algoritme levenscyclus kunnen ondersteunen bij bijvoorbeeld de behoeftestelling, het maken van make-or-buy beslissingen, de te hanteren aanbestedingsvorm, de totstandkoming van de selectie- en gunningseisen, contractspecificaties en de uitvoering en management van het contract. De algoritme levenscyclus kan worden geraadpleegd via het tabblad boven aan deze pagina. Per fase en per type algoritme of AI kan worden bekeken aan welke vereisten moet worden voldaan en welke beheersmaatregelen kunnen worden getroffen. </p>"},{"location":"bouwblokken/publieke-inkoop/#vereisten","title":"Vereisten","text":"<p>Nagenoeg alle vereisten die gelden voor algoritmen en AI kunnen een plek krijgen in het publiek inkoopproces.  Daarom is ervoor gekozen om hier niet een opsomming te geven van al deze vereisten, maar verwijzen we naar het onderdeel vereisten in het Algoritmekader.</p> <p>In de laag van 'maatregelen' wordt ook uitgewerkt wat vanuit publieke inkoop kan worden gedaan om op een betekenisvolle wijze invulling aan te geven aan de betreffende vereiste.  Daarvoor kan ook op het tabblad 'publieke inkoop' worden geklikt om deze maatregelen te filteren.</p> <p>Zie hieronder bij bruikbare informatie en bronnen in het bijzonder de Europese modelcontractbepaling voor (niet) hoog risico AI-systemen en contractvoorwaarden voor algoritmen.  Dit geeft een beeld hoe de vereisten onderdeel kunnen worden gemaakt van contractvoorwaarden.   </p>"},{"location":"bouwblokken/publieke-inkoop/#maatregelen","title":"Maatregelen","text":"<p>Hieronder volgt een overzicht van de maatregelen die (voor zover zijn uitgewerkt) kunnen worden getroffen om invulling te geven aan de vereisten. </p> MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Er wordt momenteel hard gewerkt, mede door de Werkgroep Publieke Inkoop, om maatregelen te defini\u00ebren vanuit het perspectief publieke inkoop bij de vereisten. Mocht er iets niet kloppen, laat het ons weten via GitHub of via algoritmes@minbzk.nl.</p>"},{"location":"bouwblokken/publieke-inkoop/#bruikbare-informatie-en-bronnen","title":"Bruikbare informatie en bronnen","text":"<p>Europese modelcontractbepalingen AI-systemen (hoog risico)</p> <p>Europese modelcontractbepalingen AI-systemen (niet hoog risico)</p> <p>Contractvoorwaarden voor algoritmen gemeente Amsterdam</p> <p>Inkoopproces</p> <p>Community of Practis Digitale Innovatie</p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/","title":"Technische robuustheid en veiligheid","text":"<p>Wanneer algoritmes of AI-systemen worden gebruikt om publieke taken uit te voeren, dient het onderliggende systeem voldoende robuust en veilig te zijn.  </p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#technische-robuustheid","title":"Technische robuustheid","text":"<p>De technische robuustheid van een algoritme of AI-systeem beschrijft het vermogen om het gewenste prestatieniveau onder alle omstandigheden te handhaven <sup>1</sup>.  Dit betekent dat algoritmes en AI-systemen vergelijkbaar moeten presteren ondanks externe of zware veranderingen in de omgeving.  Robuustheid kan daarnaast ook duiden op eigenschappen als veerkracht, betrouwbaarheid en nauwkeurigheid van het systeem.</p> <p>Wanneer het algoritme of het AI-systeem niet voldoet aan de eisen wat betreft robuustheid, nauwkeurigheid of de prestaties van het systeem, voordat het systeem in gebruik is genomen kan het systeem onbedoelde schade aanrichten voor betrokkenen, bijvoorbeeld door negatieve impact op grondrechten wanneer resultaten onjuist of niet worden gegenereerd of ge\u00efnterpreteerd. </p> <p>Er moeten technische en organisatorische maatregelen getroffen worden om de robuustheid van algoritmes en AI-systemen te waarborgen.  Dit kunnen bijvoorbeeld maatregelen zijn bestaande uit vooraf bepaalde mechanismen die het systeem in staat stellen om de werking veilig te onderbreken wanneer daar redenen voor zijn of wanneer de prestaties van het algoritme buiten vooraf bepaalde grenzen treedt.  </p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#veiligheid","title":"Veiligheid","text":"<p>Naast robuustheid dient het onderliggende systeem ook voldoende beveiligd te zijn, zodat het systeem weerbaar is tegen pogingen het systeem te wijzigen en onrechtmatig gebruik door derden, en die onbedoelde schade tot een minimum beperkt.  Om te zorgen voor een passend niveau van cyberbeveiliging die aansluit op de risico's van het systeem, dienen er passende maatregelen zoals veiligheidscontroles genomen te worden.  Daarbij dient er rekening te worden gehouden met de onderliggende ICT-infrastructuur.  </p> <p>In dit bouwblok van het algoritmekader werken we uit aan welke vereisten er voldaan moet worden om de technische robuustheid en veiligheid te waarborgen.  Dit wordt aangevuld met praktische maatregelen en instrumenten die gebruikt en toegepast kunnen worden om invulling te geven aan deze vereisten.  </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#vereisten","title":"Vereisten","text":"VereisteUitlegAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensOntwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening."},{"location":"bouwblokken/technische-robuustheid-en-veiligheid/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data. <ol> <li> <p>Zie NEN-EN-ISO/IEC 22989:2023 en <sup>2</sup> \u21a9</p> </li> <li> <p>Hoewel het gebruik van de NEN-ISO-normen in het Algoritmekader auteursrechtelijk is beschermd, heeft het Nederlands Normalisatie Instituut (NEN) voor het gebruik in het Algoritmekader toestemming verleend. Zie nen.nl voor meer informatie over NEN en het gebruik van hun producten.\u00a0\u21a9</p> </li> </ol>"},{"location":"bouwblokken/transparantie/","title":"Transparantie","text":"<p>Om openheid te bieden en controleerbaar te zijn moeten overheidsinstanties transparant zijn over inzet van algoritmen en AI-systemen. </p> <p>Het is van belang dat overheden nadenken over hun besluitvormingsprocessen en dat zij de werking en toegevoegde waarde van het inzetten van een algoritme kunnen uitleggen. Dit is bijzonder relevant als een algoritme of AI-systeem, al dan niet geautomatiseerd, impact heeft op besluitvorming die burgers raakt.  </p> <p>Als burgers geen kennis kunnen nemen van de gebruikte algoritmes en in hoeverre diens output hen raakt, worden ze onrechtmatig beperkt in de mogelijkheid om zicht te verdedigen tegen nadelige gevolgen zoals discriminatie of een onjuist genomen beslissing of besluit. Daarnaast versterkt transparantie de controlerende functie van burgers en journalistiek, omdat burgers kunnen aangeven of een uitleg over een algoritmisch systeem duidelijk is en of zij de werking van het systeem hetzelfde ervaren. </p> <p>Transparantie bij algoritmes en AI gaat zowel over het bekendmaken van de inzet en bijbehorende doelen, als ook over openheid van het type model en de gebruikte factoren.  Gebruikers moeten in staat zijn om de werking en de output van een algoritme of AI-systeem te begrijpen, zodat zij onderbouwde beslissingen of besluiten kunnen nemen.  Dit betekent bijvoorbeeld ook dat gebruikers bewust moet worden gemaakt dat zij communiceren of samenwerken met een algoritme of AI-systeem, dat zij worden ge\u00efnformeerd over de mogelijkheden en beperkingen van een systeem en dat betrokkenen worden ge\u00efnformeerd over hun rechten. </p> <p>In dit bouwblok van het algoritmekader besteden we aandacht aan transparantie naar gebruikers en betrokkenen, transparantie door documentatie en opname in het algoritmeregister, uitlegbaarheid en traceerbaarheid van een besluit.   Hier worden de vereisten uitgewerkt die bestaan op basis van wet- en regelgeving en bestaand beleid met betrekking tot transparantie van algoritmen en AI.   Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd met concrete maatregelen en welke rollen betrokken kunnen zijn.   Waar mogelijk worden voorbeelden en best practices uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.  Deze vereisten en maatregelen worden ook gekoppeld aan de levenscyclus van een algoritme.   Dit geeft een beeld van wanneer vereisten of maatregelen met betrekking tot transparantie, bij het ontwikkelen en gebruiken van algoritmen en AI, moeten en kunnen worden geadresseerd. </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"bouwblokken/transparantie/#vereisten","title":"Vereisten","text":"VereisteUitlegImpactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren."},{"location":"bouwblokken/transparantie/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegNeem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregister"},{"location":"governance/","title":"Governance","text":"<p>Governance is een breed begrip, en er bestaan verschillende opvattingen van. In essentie gaat het over het inrichten van de organisatie, processen en bijbehorende verantwoordelijkheden. Een belangrijk aspect van governance is bepalen wie waarvoor verantwoordelijk is. Dit kan op verschillende niveaus: van (inter)nationaal niveau, naar organisatieniveau naar het niveau van het AI-systeem. In het Algoritmekader wordt gefocust op het niveau van organisatie en AI-systeem.  </p> <p>Het Algoritmekader laat zien aan welke vereisten moet worden gedaan, hoe daar invulling aan kan worden gegeven (maatregelen) en welke rollen daar logischerwijs bij betrokken zijn.  Governance raakt in zekere zin al deze elementen doordat het deze, op verschillende niveaus, met elkaar verbindt.  </p> <p>In dit deel van het Algoritmekader worden de volgende zaken uitgewerkt; </p> <ul> <li>een verzameling praktijkvoorbeelden die tonen hoe organisaties hun governance kunnen inrichten om verantwoord met algoritmes en AI-systemen om te gaan. Daarbij worden goede praktijkvoorbeelden samengevat op hoofdlijnen; </li> <li>een handreiking hoe om te gaan met een governancestructuur die rekening houdt met verschillende niveaus van complexiteit van een organisatie.  </li> <li>uitwerken van governance-maatregelen en koppeling aan rollen die hier logischerwijs bij passen, waarmee invulling kan worden gegeven aan een vereiste.  </li> </ul> <p>De eerste twee punten zijn breed en geven algemene handvatten voor governance, het laatste punt gaat specifiek in op de vereisten/maatregelen. </p> <p>Let wel: Het Algoritmekader schrijft niet voor hoe een organisatie ingericht moet worden qua eindverantwoordelijken/governance. We proberen met behulp van voorbeelden praktische handvatten te bieden over hoe organisaties dit kunnen inrichten.  </p>"},{"location":"governance/#vereisten","title":"Vereisten","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Recht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensGebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemGebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI VerordeningKwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.Klachtrecht aanbieders verder in AI-waardeketenAanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezetVoordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"governance/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Configuratie met de mensZorg voor complementariteit tussen algoritmische systeem en de mensen die ermee moeten werken.Formuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensStel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie."},{"location":"governance/governance-structuur/","title":"Governance structuur","text":"<p>Hier komt een tekst. </p>"},{"location":"governance/interactie-burgers-en-omgeving/","title":"Interactie met burgers en omgeving","text":"<p>Hier komt een tekst. </p>"},{"location":"governance/levenscyclus/","title":"Levenscyclus","text":"<p>Hier komt een tekst. </p>"},{"location":"governance/politiek-bestuurlijk-kader/","title":"Politiek bestuurlijk kader","text":"<p>Hier komt een tekst</p>"},{"location":"governance/rollen_en_verantwoordelijkheden/","title":"Rollen en verantwoordelijkheden","text":"<p>Hier komt een tekst. </p>"},{"location":"governance/type_algoritme/","title":"Type algoritme en risicoclassificatie","text":"<p>Hier komt een tekst. </p>"},{"location":"governance/volwassenheidsniveau/","title":"Volwassenheidsniveau","text":"<p>Hier komt een tekst. </p>"},{"location":"instrumenten/","title":"Instrumenten","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Er is een groot aanbod aan instrumenten die kunnen worden ingezet tijdens de ontwikkeling, gebruik, beoordeling en/of monitoring van algoritmes. Binnen het Algoritmekader worden instrumenten als volgt gedefinieerd:  </p> <p>Een instrument heeft als doel om op systematische wijze (een bepaald aspect van) verantwoorde en effectieve inzet van algoritmes te bevorderen en/of te evalueren. Een instrument bevat hulpmiddelen of richtlijnen om kenmerken, prestaties, effecten en risico\u2019s van de inzet van algoritmes in kaart te brengen, te beoordelen en mogelijk te verbeteren<sup>1</sup>.  </p> <p>Instrumenten worden ontwikkeld door de verschillende partijen, zoals de overheid, wetenschap en industrie.  Bekende voorbeelden hiervan zijn het IAMA (UU) en het Toetsingskader Algoritmes (ARK).  Het team Algoritmekader heeft verschillende instrumenten geanalyseerd.  Wat opvalt is dat er (veel) overlap zit tussen deze instrumenten wat betreft doel en onderwerpen.  Het is voor gebruikers ook niet altijd duidelijk wanneer welk instrument kan of moeten worden ingezet en of het dan alle relevante aspecten van een onderwerp dekt. </p> <p>Door een beperkt aantal instrumenten op te nemen in het Algoritmekader, wordt geprobeerd om organisaties handvatten te bieden voor het inzetten van passende instrumenten.  Er is gekozen voor een aanpak waarbij bekende instrumenten worden gelinkt aan de verschillende bouwblokken van het Algoritmekader.  Een instrument zal worden opgenomen wanneer: </p> <ul> <li>Deze bekend is onder een gebruikersgroep (van overheidsorganisaties/-medewerkers) die relatief groot genoeg is; </li> <li>Kan worden vastgesteld of het instrument reeds vaker wordt ingezet; </li> <li>Kan worden vastgesteld of ervaringen met het instrument overwegend positief zijn </li> </ul> <p>Bovendien is het van belang dat een instrument in ieder geval passend is voor algoritmes binnen het overheidsdomein.  Wanneer een gebruiker informatie zoekt binnen een bouwblok, zal (wanneer beschikbaar) worden verwezen naar het betreffende instrument dat onderwerpen uit het betreffende bouwblok ondersteunt.  Het is de bedoeling dat daarbij een korte beschrijving van het instrument wordt opgenomen.  Indien hier (op termijn) informatie over beschikbaar is, zullen ook voor- en nadelen worden opgenomen.  Een gebruiker kan er dan voor kiezen het betreffende instrument wel of niet in te zetten. </p> <p>Deze aanpak geniet de voorkeur boven het opnemen van alle bestaande/bekende instrumenten in het Algoritmekader.  Er zou dan alsnog sprake zijn van een grote hoeveelheid overlap tussen de verschillende instrumenten en onduidelijkheid opleveren voor gebruikers.  Een ander praktisch aspect is dat het niet  voor elk instrument valt vast te stellen of het van goede kwaliteit is.  Een inhoudelijke analyse van elk individueel instrument zou ook een opdracht op zichzelf zijn, die op het moment van schrijven niet is uit te voeren binnen de ontwikkeling van het Algoritmekader. </p> <p>Tot slot is het belangrijk te benadrukken dat een instrument iets anders is dan een wettelijke verplichting.  Er bestaan wettelijke verplichtingen die de inzet van bepaalde instrumenten voorschrijven. Een bekend voorbeeld hiervan is de DPIA. Echter is de inzet van de meeste instrumenten niet verplicht en ligt de keuze meestal bij de gebruiker.   </p>"},{"location":"instrumenten/#de-instrumenten","title":"De instrumenten","text":"<p>Het Algoritmekader is tot stand gekomen op basis van de volgende instrumenten:</p> Naam instrument Categorie Jaartal uitgebracht Verantwoordelijke organisatie Ontwikkeld door null null Ontwikkeld voor null null Voor overheidsorganisatie specfiek Volwassenheidsniveau Locatie Doel null null null Mogelijke wettelijke verplichting Toelichting doel Toepassing overheid wetenschap overig overheid wetenschap overig Informerend Sturend Normerend Faciliterend technologie algemeen Impact Assessment Mensenrechten en Algoritmes Impact Assessment 2021 Universiteit Utrecht ja ja ja ja In gebruik Internationaal \u00b1 - - + ja Dit impact assessment werkt in eerste instantie faciliterend voor het gesprek. Maar biedt ook veel informatie. \u00b1 Handreiking Non-discriminatie by Design Handleiking/leidraad 2021 Binnenlandse Zaken ja ja nee ja ja ja In gebruik Nationaal + + - \u00b1 nee Deze handreiking is bedoeld voor projectleiders die sturing geven aan systeembouwers, data-analisten en AI-experts op het gebied van het discriminatieverbod. - De Ethische Data Assistent (DEDA) Handleiking/leidraad 2022 Utrecht Data School nee ja nee ja ja ja In gebruik Nationaal + - - + nee DEDA helpt data-analisten, projectmanagers en beleidsmakers om samen ethische problemen in dataprojecten, datamanagement en databeleid te herkennen. - Toetsingskader Algoritmes Algemene Rekenkamer Toetsingskader 2020 Algemene Rekenkamer ja nee nee ja ja ja In gebruik Nationaal + + - - nee Dit toetsingskader is een instrument dat aandacht besteedt aan de relevante perspectieven op algoritmes. Met een vertaling van normenkaders en richtlijnen naar verschillende aspecten waarop algoritmes kunnen worden getoetst. Een instrument dat bovendien rekening houdt met de risico\u2019s en de onderzoeksvragen die in een toetsingskader aan bod moeten komen. - Baseline Informatiebeveiliging Overheid Wet- en regelgeving 2018 Binnenlandse Zaken ja nee nee ja nee nee In gebruik Nationaal - - + - ja De Baseline Informatiebeveiliging Overheid (BIO) is het basisnormenkader voor informatiebeveiliging binnen alle overheidslagen (Rijk, gemeenten, provincies en waterschappen). + Framework for Meaningful Engagement Handleiking/leidraad 2023 Action Coalition on Civic Engagement for AI (Denemarken) ja nee ja ja ja ja In gebruik Internationaal + \u00b1 - + nee Dit kader is gecre\u00eberd om iedereen die producten of diensten ontwerpt met behulp van AI, machine learning of op algoritme-gebaseerde gegegevensanalyse in staat te stellen belanghebbenden bij dat proces te betrekken. \u00b1 Waarborgen Selectie-Instrumenten voor de Belastingdienst Handleiking/leidraad 2023 Belastingdienst ja nee nee ja nee nee Financi\u00ebn (Fin) In gebruik Nationaal + + \u00b1 - nee Een waarborgenkader voor selectie-instrumenten waarmee de rechtmatigheid en transparantie van de instrumenten (beter) gegarandeerd kunnen worden. + Modelbepalingen en toelichting voor verantwoord gebruik van algoritme door de overheid (contractvoorwaarden) Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja nee nee Gemeenten In gebruik Nationaal + + \u00b1 - nee + AI Impact Assessment Handleiking/leidraad 2022 Infrastructuur en Waterstaat ja nee nee ja ja ja In gebruik Nationaal \u00b1 - - + nee Het AI Impact Assessment (AIIA) is een hulpmiddel voor het maken van afwegingen bij het inzetten van kunstmatige intelligentie (artificial intelligence, AI) in een project. Het AIIA dient als instrument voor het gesprek en het vastleggen van het denkproces zodat onder andere de verantwoording, kwaliteit en reproduceerbaarheid worden vergroot. - Artificial Intelligence Impact Assessment Handleiking/leidraad 2018 ECP nee nee ja ja ja ja In gebruik Nationaal \u00b1 - - + nee De Artificial Intelligence Impact Assessment (AIIA) helpt bedrijven artificial intelligence verantwoord in te zetten, nu slimme algoritmes steeds vaker taken van mensen overnemen. Aan de hand van een stappenplan, bestaande uit acht stappen, maken bedrijven inzichtelijk welke juridische en ethische normen een rol spelen bij de ontwikkeling en inzet van AI-toepassingen, en welke afwegingen ten grondslag liggen aan keuzes en besluiten. - Data Protection Impact Assessment Impact Assessment 2018 Autoriteit Persoonsgegevens ja nee nee ja ja ja In gebruik Nationaal - - + - ja Is een organisatie van plan persoonsgegevens te verwerken, maar levert dat waarschijnlijk een hoog privacyrisico op? Dan is de organisatie verplicht eerst een 'data protection impact assessment' (DPIA) uit te voeren. Een DPIA is een instrument om vooraf de privacyrisico\u2019s van een gegevensverwerking in kaart te brengen. + The Fairness Handbook Handleiking/leidraad 2022 Gemeente Amsterdam ja nee nee ja ja ja In gebruik Nationaal + \u00b1 - \u00b1 nee The Fairness Handbook is uitgebracht door de gemeente Amsterdam om bias in algoritmische systemen te minimaliseren en fairness te maximaliseren. Het handboek legt uit hoe vooroordelen en andere problemen rondom fairness tijdens de ontwikkeling van algoritmes kunnen voorkomen en wat hieraan gedaan kan worden. - Ethics Guideline for Trustworthy AI Handleiking/leidraad 2019 EU High-Level Expert Group on AI ja nee nee ja ja ja In gebruik Internationaal \u00b1 + - - nee Deze richtlijnen, opgesteld door leden van de 'high level expert group on AI', hebben als doel gebruikers te begeleiden in het ontwikkelen van betrouwbare AI. Hiervoor worden drie domeinen belicht; juridisch, ethisch en robuustheid. - Norea Guiding Principles Trustworthy AI Investigations Handleiking/leidraad 2021 Norea Beroepsorganisatie van IT-auditors nee nee ja ja ja ja In gebruik Internationaal \u00b1 + - - nee - <ol> <li> <p>Definitie opgesteld door team Algoritmekader\u00a0\u21a9</p> </li> </ol>"},{"location":"instrumenten/IAMA/","title":"Impact Assessment Mensenrechten en Algoritmes","text":"<p>ProbleemanalyseOntwerpVerificatie en validatieImplementatieProjectleiderAanbiederData engineerData scientistEthicusGemandateerd verantwoordelijkeJuristPrivacy officerProceseigenaarSecurity officerFundamentele rechten</p> <p>Direct naar het IAMA</p>"},{"location":"instrumenten/IAMA/#instrument","title":"Instrument","text":"<p>Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen.  Het IAMA stelt een reeks vragen die moeten worden besproken en beantwoord om een zorgvuldige afweging van de inzet van algoritmen te waarborgen.  Dit proces is onderverdeeld in drie fasen: voorbereiding, input en throughput, en output en toezicht, waarbij steeds aandacht wordt besteed aan het vierde onderdeel van het IAMA: de impact op mensenrechten.  Het IAMA fungeert als naslagwerk voor de besluitvorming en is gekoppeld aan andere relevante richtlijnen en instrumenten, zoals de gegevensbeschermingseffectbeoordeling (ook wel DPIA).  Hierdoor biedt het een overkoepelend kader dat helpt om algoritmen verantwoord te implementeren en mogelijke risico\u2019s, zoals inbreuken op grondrechten, te identificeren en te mitigeren.</p>"},{"location":"instrumenten/IAMA/#relevantie","title":"Relevantie","text":"<p>Het IAMA kan op dit moment op veel politieke en internationale belangstelling rekenen.  In zowel de Eerste als Tweede Kamer zijn hierover moties ingediend en vragen gesteld.  Daarbij is het IAMA een van de weinige instrumenten in de EU die een interdisciplinaire discussie rondom (de ontwikkeling, inzet en monitoring van) algoritmes, AI en grondrechten initieert en bevordert. </p>"},{"location":"instrumenten/IAMA/#auteur","title":"Auteur","text":"<p>Het IAMA is ontwikkeld door de Utrecht Data School. De auteurs van het IAMA zijn prof. mr. Janneke Gerards, dr. Mirko Tobias Sch\u00e4fer, Arthur Vankan en Iris Muis, allen werkzaam aan de Universiteit Utrecht. Opdrachtgever voor de ontwikkeling is het Ministerie van Binnenlandse Zaken.</p>"},{"location":"instrumenten/IAMA/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"VereisteUitlegBeoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI."},{"location":"instrumenten/IAMA/#bronnen","title":"Bronnen","text":"Bron Impact Assessment Mensenrechten en Algoritmes"},{"location":"instrumenten/IAMA/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"levenscyclus/","title":"Levenscyclus","text":"<p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Algoritmes en AI kunnen door overheidsorganisaties worden gebruikt, bijvoorbeeld bij het leveren van diensten of het nemen van besluiten.  Algoritmes en AI-systemen doorlopen een zogeheten levenscyclus.  Een algoritme wordt ontwikkeld, in productie genomen, en na enige tijd van gebruik kan worden besloten het gebruik ervan te be\u00ebindigen.  Omdat de levenscyclus van een algoritme en AI aanzet tot nadenken over de inzet van algoritmes van begin tot eind is het bruikbaar als leidraad om relevante informatie te structureren en te communiceren.  Wat is het doel, gaat het gebruik ervan wel naar verwachting, wanneer moet wat worden gedaan en wat als het gebruik ten einde loopt?  In praktijk kan het zo zijn dat de levenscyclus anders verloopt, bijvoorbeeld omdat na validatie en verificatie eerst terug naar de tekentafel moet worden gegaan (ontwerpfase) omdat het nog niet aan de wensen of vereisten voldoet.  </p> <p></p>"},{"location":"levenscyclus/#verschillende-versies-levenscyclus","title":"Verschillende versies levenscyclus","text":"<p>De stappen in de levenscyclus van het Algoritmekader zijn gebaseerd op een samenvoeging van meer dan tien verschillende levenscyclusmodellen.  Zie hier een overzicht.  Afhankelijk van hoe een organisatie het ontwikkelproces inricht, kan een levenscyclusmodel er net weer anders uitzien.  De huidige indeling is gekozen omdat deze het beste aansluit bij bestaande levenscyclusmodellen en bij de behoeftes en werkwijze van overheidsinstanties. </p>"},{"location":"levenscyclus/#doorlopend-verantwoord","title":"Doorlopend verantwoord","text":"<p>Om tot een wettige, ethisch verantwoorde en robuuste inzet van algoritmes en AI te komen zullen in elke fase van de levenscyclus specifieke handelingen of maatregelen moeten worden getroffen.  In het Algoritmekader worden vereisten en maatregelen gekoppeld aan de levenscyclus. De meeste vereisten waar algoritmen en AI aan moeten voldoen zullen in meerdere fasen van levenscyclus relevant zijn.  Zo zijn transparantie, veiligheid, privacy, risicomanagement, en de afweging van ethische aspecten belangrijk in iedere fase van de levenscyclus.  Maatregelen bij de vereisten kunnen fijnmaziger worden gekoppeld aan verschillende fases van de levenscyclus, hoewel bepaalde maatregelen ook terugkerend zullen zijn en voortdurend aandacht moeten krijgen.  Naast een beschrijving van de betreffende fase, wordt weergeven welke vereisten en maatregelen relevant kunnen zijn binnen deze fase.  </p>"},{"location":"levenscyclus/archiveren/","title":"Archiveren","text":"<p>Wanneer het algoritme of AI-model niet langer nodig is of wordt vervangen door een verbeterde versie, wordt het gearchiveerd. Dit omvat het behouden van documentatie en eventuele relevante artefacten.</p>"},{"location":"levenscyclus/archiveren/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"levenscyclus/archiveren/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/","title":"Dataverkenning en datapreparatie","text":"<p>In deze fase worden relevante datasets ge\u00efdentificeerd en wanneer nodig wordt nieuwe data verzameld.  In deze fase zal ook de ontwikkelomgeving (verder) worden ingericht indien nodig.  Het is van belang dat voorafgaand aan verzameling is vastgesteld dat de benodigde data mag worden verwerkt en dat de juiste maatregelen worden getroffen, zodra de data kan worden verwerkt.  Denk hierbij aan het anonimiseren, pseudonimiseren of aggregeren van persoonsgegevens.  De data zullen vervolgens worden opgeschoond, geanalyseerd en voorbereid voor verdere verwerking. </p> <p>Het is van belang dat dataverzameling op de juiste manier gebeurt, en dat datasets die gebruikt gaan worden van goede kwaliteit zijn.  In deze fase is het van belang om de datakwaliteit en eventuele bias in de dataset te onderzoeken.  Indien er risico's optreden door bijvoorbeeld missende data of niet representatieve data, is het belangrijk om te kijken wat voor effecten dit heeft op het oorspronkelijke ontwerp van het algoritme of AI-systeem.  Dit kan betekenen dat nieuwe keuzes moeten worden gemaakt in het ontwerp en eventueel eerste deze fase van ontwerp (deels) opnieuw moet worden doorlopen. </p> <p>Met voorgaande handelingen wordt het fundament gelegd om het algoritme of AI-systeem te kunnen ontwikkelen.  In de praktijk zal bijvoorbeeld het analyseren van de data niet stoppen na deze fase, maar terugkerend zijn in alle fasen die volgen.  Als de verzamelde data van voldoende kwaliteit is en de vereiste maatregelen zijn getroffen, dan kan worden gestart met het ontwikkelen van het algoritme of AI-systeem. </p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#vereisten","title":"Vereisten","text":"VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenEenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegStel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.FAIR dataMaak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/implementatie/","title":"Implementatie","text":"<p>In deze fase wordt het algoritme of AI-systeem in de praktijk gebracht en duurzaam ge\u00efntegreerd in het bedrijfsproces.  In de praktijk worden veelal eerst een pilot uitgevoerd voor een afgebakende periode of over een beperkt aan zaken.  In deze situatie, een pilot, wordt tijdelijk productiedata verwerkt.  Dit vraagt om een goede samenwerking tussen het ontwikkelteam en de gebruikers van het algoritme of AI-systeem.  Niet alleen de prestaties van het algoritme of AI-systeem worden nogmaals gevalideerd, maar bijvoorbeeld ook of de output zodanig wordt gepresenteerd dat gebruikers hiermee kunnen werken.  Na deze pilot wordt onderzocht in hoeverre het algoritme of AI-systeem presteert conform wens en verwachting.  Er kan worden gekozen om het algoritme eerst nog door te ontwikkelen op basis van de bevindingen, uit te faseren of om de oplossing structureel onderdeel te maken van de bedrijfsvoering door het te implementeren. </p> <p>Als een besluit wordt genomen om de oplossing te implementeren, dan is het van belang dat gebruikers goed begrijpen hoe de resultaten van het algoritme of AI-systeem moeten worden ge\u00efnterpreteerd, dat de rest-risico's bekend zijn, de verantwoordelijkheden belegd zijn en dat er duidelijke werkinstructies zijn over het gebruik van het algoritme of AI-systeem. Service- en incidentmanagement moet volledig worden geoperationaliseerd, zodat gebruikers kunnen worden geholpen bij vragen of incidenten.  Een kenmerkend element van deze fase is dat vanaf nu betrokkenen onderhevig zijn aan de werking van het algoritme of AI-systeem.  Beslissingen en besluiten komen nu bijvoorbeeld mede of geheel door de werking van het algoritme of AI-systeem tot stand.  Waar passend, bijvoorbeeld bij impactvolle of hoog risico AI-systemen wordt dit duidelijk gecommuniceerd naar betrokken, voordat de oplossing volledig is ge\u00efmplementeerd.  </p>"},{"location":"levenscyclus/implementatie/#vereisten","title":"Vereisten","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensGebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenEenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezetVoordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/implementatie/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Configuratie met de mensZorg voor complementariteit tussen algoritmische systeem en de mensen die ermee moeten werken.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterStel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/monitoren/","title":"Monitoren","text":"<p>Het algoritme of AI-model wordt voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht. Eventuele afwijkingen of verslechtering van prestaties worden ge\u00efdentificeerd en aangepakt.</p>"},{"location":"levenscyclus/monitoren/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"levenscyclus/monitoren/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/monitoring-en-beheer/","title":"Monitoring en beheer","text":"<p>Het algoritme of AI-systeem wordt in deze fase voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht en kan worden gebruikt door gebruikers.  Eventuele afwijkingen of degradatie van prestaties worden gesignaleerd en er worden maatregelen getroffen om dit te herstellen.  Dit is van belang vanuit een technisch perspectief (presteert het model nog wel waar het voor ontworpen is), maar ook vanuit een juridische en ethische blik (functioneert het model nog wel rechtmatig en zijn er geen onvoorziene nadelige effecten op mens en maatschappij).  Hierbij dient ook voortdurend gemonitord te worden of de omstandigheden waarin het algoritme of AI-systeem wordt gebruikt veranderlijk zijn, en of daar op geanticipeerd moet worden.  Dit kan bijvoorbeeld spelen bij veranderende data of bij het uitvoeren van nieuw beleid of wet- en regelgeving in het werkproces dat wordt ondersteund met het algoritme of AI-systeem. </p> <p>Het is van belang dat beheer wordt uitgevoerd over het algoritme of AI-systeem, zodat de (gehele) oplossing operationeel blijft.  Een wijziging in onderliggende systemen kan er bijvoorbeeld voor zorgen dat het algoritme of AI-systeem niet meer wordt voorzien van de noodzakelijk data om de benodigde output te genereren.  Het beheerteam zorgt ervoor dat dergelijke situaties worden voorkomen of opgelost. Er kunnen ook incidenten worden gemeld door gebruikers die worden opgelost door het beheerteam.  </p>"},{"location":"levenscyclus/monitoring-en-beheer/#vereisten","title":"Vereisten","text":"VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemGebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI VerordeningMelden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Klachtrecht aanbieders verder in AI-waardeketenAanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.Recht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/monitoring-en-beheer/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBetrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwerp/","title":"Ontwerp","text":"<p>In de ontwerpfase wordt het conceptuele ontwerp van het AI-systeem uitgedacht.  Het is van belang om belangrijke uitgangspunten en beleid, zoals doelarchitectuur en de datastrategie, van de betreffende organisatie meteen te verwerken in het ontwerp en dat het applicatielandschap en de databronnen in beeld wordt gebracht.  In deze fase worden doorgaans veel werkzaamheden verzet, zoals business- en informatieanalyse, om een goed beeld te krijgen hoe aan de beoogde doelstellingen kan worden voldaan met een passende oplossing.  </p> <p>Het is goed denkbaar dat meerdere ontwerpen in deze fase tot stand komen voor het te ontwikkelen algoritme of AI-systeem.  Het is van belang om deze ontwerpen te toetsen bij bijvoorbeeld de proceseigenaar, opdrachtgever en gebruiker, maar ook bij informatiebeveiligingsadviseurs, privacy officers, informatiebeheerders, architecten of een ethicus.  Deze experts kunnen vanuit hun vakgebied een eerste toets doen in hoeverre het ontwerp haalbaar of gewenst is, aansluit bij de gebruikersbehoefte, aan welke vereisten moet worden voldaan of dat er risicoanalyses moeten worden uitgevoerd en een onafhankelijke commissies moet worden betrokken.</p> <p>Met deze input kan het ontwerp worden verbeterd en vraagstukken over bijvoorbeeld governance en risicomanagement verder worden uitgewerkt.  In deze fase kan ook een eerste stap worden gezet om de vereisten te vertalen naar concrete maatregelen, te structureren en te beleggen bij de betrokken experts.  Als bijvoorbeeld is vastgesteld dat persoonsgegevens noodzakelijkerwijs moeten worden verwerkt en hier een grondslag voor is, dan is het van belang dat voorafgaand aan de dataverkenning en datapreparatie fase voldoende (technische) maatregelen zijn getroffen om de data veilig te verwerken in de beoogde (ontwikkel)omgeving. </p> <p>Daarnaast dient er in de ontwerpfase ook aandacht besteed te worden aan de succesfactoren van een algoritme of AI-systeem.  Het is belangrijk om in een multidisciplinaire setting te bepalen hoe het algoritme in de praktijk ge\u00ebvalueerd kan worden en wanneer we kunnen spreken van een rechtvaardig succes. Hierbij dient er ook te worden nagedacht over evaluatiemethoden om na te gaan of het algoritme of AI-systeem voldoet aan bijvoorbeeld het vereiste van non-discriminatie. </p> <p>Nadat een besluit is genomen over het definitieve ontwerp van het algoritme of AI-systeem, kan worden gestart met het inrichten van de ontwikkelomgeving (indien nodig), de dataverkenning, datapreparatie.  Dit besluit betekent dat een akkoord wordt gegeven voor het type algoritme en de beoogde werking.  </p>"},{"location":"levenscyclus/ontwerp/#vereisten","title":"Vereisten","text":"VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezetVoordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/ontwerp/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Kwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwikkelen/","title":"Ontwikkelen","text":"<p>Dit is de fase waarin het algoritme of AI-systeem wordt ontwikkeld door het ontwikkelteam.  Als het gaat om AI-systemen, omvat deze fase het trainen van modellen met behulp van de voorbereide gegevens. Als het gaat om algoritmes op basis van rekenregels, betreft dit het implementeren van deze rekenregels in de (ontwikkelomgeving van de) systemen.  </p> <p>Het algoritme of AI-systeem technisch correct ontwikkelen, inclusief het kunnen begrijpen van de beperkingen ervan, vraagt om een samenspel van expertise vanuit verschillende disciplines.  Denk hierbij aan de proceseigenaar, domeinexperts van het te ondersteunen werkproces, data scientists, data engineer, (privacy)juristen, beleidsmedewerkers en een ethicus.  Een voorbeeld hiervan is het beoordelen van de zogenaamde inputvariabelen of rekenregels (die voor een groot deel bepalen hoe een algoritme of AI-systeem functioneert) van een machine learning model of algoritme.  Deze rollen zijn bijzonder waardevol bij het beoordelen of deze variabelen of rekenregels juridisch zijn toegestaan, ethisch wenselijk zijn, technisch gezien- voldoende significant zijn en of deze van toegevoegde waarde zijn voor gebruikers.  Dit multidisciplinaire team kan tijdens de ontwikkeling continu bijsturen, zodat het algoritme of AI-systeem op een verantwoorde wijze functioneert en aansluit bij de beoogde doelstellingen.  </p> <p>In deze fase is niet alleen het ontwikkelen van een algoritme of AI-systeem, maar ook het documenteren van belangrijke afwegingen en het opstellen van technische documentatie van groot belang.  Daarnaast zullen tal van (technische) maatregelen moeten worden getroffen zoals de verdere beveiliging van het informatiesysteem of bij de ontsluiting van de output naar gebruikers, het automatische genereren van logs en het inrichten van service en incidentmanagementprocedures.  </p>"},{"location":"levenscyclus/ontwikkelen/#vereisten","title":"Vereisten","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Recht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelImpactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensPrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/ontwikkelen/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/probleemanalyse/","title":"Probleemanalyse","text":"<p>In deze fase wordt het probleem en de doelstellingen van een opdrachtgever geanalyseerd en beschreven.  Er wordt bijvoorbeeld onderzocht welke publieke taak moet worden ondersteund en welke publieke waarden daarbij moeten worden beschermd of juist gerealiseerd.  In deze fase wordt onderzocht of het ontwikkelen van een algoritme of AI-systeem een geschikt middel is om het doel te realiseren en het probleem op te lossen. Dat hangt van verschillende zaken af.  Hierbij kan worden gedacht aan de middelen (capaciteit en financi\u00eble middelen) die nodig zijn om algoritmen en AI op een verantwoorde wijze te ontwikkelen, de complexiteit van de oplossing, het in beeld brengen van de verwachte risico's (hoog over), een eerste beeld krijgen bij wat voor data nodig zijn en het in kaart brengen en beleggen van de verschillende verantwoordelijkheden.  Daarnaast is het van belang om het beleid met betrekking tot de inzet van algoritme en AI van een organisatie te raadplegen.  </p> <p>Er zal een conclusie moeten volgen of de ontwikkeling van een algoritme of AI-systeem passend is.  Deze fase wordt doorgaans afgerond met een akkoord van de (gemandateerd) verantwoordelijk(en)/opdrachtgever om een algoritme of een AI-systeem te ontwikkelen.  Een vastgestelde business case of plan van aanpak vormen veelal de basis om de ontwerpfase te starten met de benodigde experts. </p>"},{"location":"levenscyclus/probleemanalyse/#vereisten","title":"Vereisten","text":"VereisteUitlegProportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/probleemanalyse/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Formuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/uitfaseren/","title":"Uitfaseren","text":"<p>Als wordt besloten dat het algoritme of AI-systeem niet langer nodig is of wordt vervangen door een wezenlijk andere versie, wordt het gearchiveerd en uitgefaseerd.  Hiermee wordt ervoor gezocht dat later kan worden gereconstrueerd hoe het algoritme of AI-systeem heeft gefunctioneerd en dat gebruikers er geen gebruik meer van kunnen maken.  </p> <p>Archiveren betekent dat documentatie en eventuele relevante artefacten (zoals logbestanden en de parameters van het model) worden bewaard voor een bepaalde periode.  Het gaat daarbij ook om informatie over het algoritme of AI-systeem, bijvoorbeeld het besluit en onderbouwing waarom het niet meer wordt gebruikt en waarom het in het verleden wel gebruikt werd.  Archiveren is niet enkel relevant aan het einde van de levenscyclus, maar is ook gedurende het gebruik van het algoritme of AI-systeem van belang.  Er moet tijdig worden vastgesteld welke versies van een model moeten worden gearchiveerd, bijvoorbeeld al tijdens de ontwerpfase. </p> <p>Bij AI-systemen is er in praktijk vaak sprake van hertrainen op nieuwe data, wat het model anders maakt en andere voorspellingen kan doen geven.  Ook meer eenvoudige algoritmes kunnen gedurende de tijd veranderen en andere voorspellingen geven, bijvoorbeeld door veranderende data of veranderende rekenregels.  Er moet worden vastgesteld welke versies van een model moet gearchiveerd. </p> <p>Bij uitfaseren wordt het algoritme of AI-systeem verwijderd uit de productieomgeving en, na archivering, wordt de trainingsdata uit de ontwikkelomgeving verwijderd.  Het algoritme is hiermee niet meer te gebruiken door gebruikers.  Gebruikers moeten hier vooraf over worden ge\u00efnformeerd en waar passend, bijvoorbeeld bij impactvolle of hoog risico AI-systemen, worden betrokkenen ge\u00efnformeerd over het be\u00ebindigen van het gebruik. </p>"},{"location":"levenscyclus/uitfaseren/#vereisten","title":"Vereisten","text":"VereisteUitlegVerplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/uitfaseren/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/verificatie-en-validatie/","title":"Verificatie en validatie","text":"<p>Bij de verificatie en validatie van het algoritme of AI-systeem dient bepaald te worden of het algoritme of AI-systeem gebouwd is volgens de (technische) specificaties en voldoet aan de beoogde doelstellingen.  Hiervoor moeten technische, maar ook organisatorische maatregelen worden getroffen.  </p> <p>Bij verificatie kan worden gedacht aan het (laten) controleren of het algoritme of AI-systeem voldoet aan de (technische) specificaties, bijvoorbeeld door een interne of externe audit of in de toekomst een conformiteitsbeoordeling voor hoog risico AI-systemen.  Hiermee kan (onafhankelijk) worden vastgesteld of het systeem voldoet aan de vereisten die organisaties daaraan stellen.  Op basis van bevindingen uit een audit of conformiteitsbeoordeling, is het denkbaar dat het ontwikkelteam nog bepaalde maatregelen moet treffen om te voldoen aan de specificaties. </p> <p>Bij het valideren van een algoritme of AI-systeem moet worden bepaald of het goed genoeg presteert en of het geschikt is voor het beoogde doel van het systeem.  Wanneer het een AI-systeem betreft, is het belangrijk dat dit gevalideerd wordt op nieuwe, niet eerder geziene data.  Het valideren betreft het iteratief evalueren van de nauwkeurigheid en prestaties van het systeem.  Daarnaast is het ook belangrijk om te valideren of het algoritme gelijke prestaties toont voor verschillende groepen en om te testen hoe het algoritme presteert in uitzonderlijke gevallen.  Het is net als in de ontwerpfase belangrijk dat een multidisciplinair team beoordeelt of de werking passend en bijvoorbeeld non-discriminatoir is.  In het geval van impactvolle algoritmen of hoog risico AI-systemen, is het raadzaam om een onafhankelijke commissie of partij te betrekken die een advies geeft over de werking van het algoritme of AI-systeem.  </p> <p>In praktijk zal vaak na validatie weer worden teruggegaan naar de ontwikkelfase om prestaties van het model te verbeteren voorafgaand aan implementatie van de oplossing.  Het is ook denkbaar dat het algoritme of AI-systeem onvoldoende aansluit bij de doelstellingen en het gebruik ervan moet wordt be\u00ebindigd.  Een andere conclusie kan zijn dat het presteert conform verwachting en naar de implementatiefase kan worden gegaan.  </p>"},{"location":"levenscyclus/verificatie-en-validatie/#vereisten","title":"Vereisten","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldDocumentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"levenscyclus/verificatie-en-validatie/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterRestrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"maatregelen/","title":"Maatregelen","text":"<p>De maatregelen die zijn opgenomen in het Algoritmekader geven aan 'hoe' overheidsorganisaties invulling kunnen geven aan specifieke vereisten. Deze laag is aan het Algoritmekader toegevoegd, omdat het organisaties handvatten kan geven om zelf op een betekenisvolle wijze invulling te geven aan de vereisten. In het Algoritmekader zijn al deze maatregelen gekoppeld aan de levenscyclus van een algoritme, vereisten en rollen. Daarmee is inzichtelijk wanneer en met wie deze maatregelen logischerwijs in stelling kunnen worden gebracht. Organisaties zijn niet verplicht om deze maatregelen te volgen, hoewel ze soms dermate sterk aan de vereisten zijn gekoppeld of voortkomen uit standaarden dat ze praktisch gezien wel moeten worden toegepast.</p> <p>Een maatregel kan bijvoorbeeld zijn:</p> <p>'onderzoek het ontwikkelde algoritme op onbewuste vooringenomenheid (discriminatie) door middel van een bias-analyse'.</p> <p>Deze maatregel geeft invulling aan het vereiste van 'non-discriminatie'. Er kunnen meerdere maatregelen zijn die invulling geven aan het vereiste van non-discriminatie. Het is ook denkbaar dat bepaalde maatregelen aan meerdere vereisten kunnen worden gekoppeld. Dit moet organisaties helpen om met hun beschikbare middelen effectief en gericht te komen tot een verantwoorde ontwikkeling en inzet van algoritmes en AI.</p> <p>Om tot een overzicht van de maatregelen te komen is naar een aantal waardevolle bronnen gekeken. Het Toetsingskader Algoritmes van de Algemene Rekenkamer en het Onderzoekskader algoritmesvan de Auditdienst Rijk zijn daar goede voorbeelden van. Daarnaast is ook de kennis van experts binnen en buiten het team Algoritmekader toegevoegd om te kunnen duiden welke maatregelen in de praktijk kunnen worden getroffen om te voldoen aan de vereisten.</p>"},{"location":"maatregelen/#standaarden","title":"Standaarden","text":"<p>Op nationaal, Europees en internationaal niveau wordt momenteel gewerkt aan de totstandkoming van standaarden. Deze standaarden worden opgesteld door gespecialiseerde organisaties (NEN, JTC21 en ISO) en ondergaan een uitgebreid proces. Dit proces zorgt uiteindelijk voor brede consensus voor de standaarden. Het naleven van deze standaarden door organisaties levert een vermoeden van conformiteit op, ofwel, door het naleven van standaarden is de kans groot dat organisaties voldoen aan de vereisten. De standaarden worden daarom een waardevolle bron voor het Algoritmekader. Waar mogelijk zullen de standaarden onderdeel worden van het Algoritmekader en tot uiting komen in de laag van 'maatregelen'. Er zal een verwijzing worden gemaakt naar de betreffende standaard. Hierover moeten nog nadere afspraken worden gemaakt met deze standaardisatieorganisaties.</p>"},{"location":"maatregelen/#overzicht-van-maatregelen","title":"Overzicht van maatregelen","text":"<p>Onderstaand volgt een overzicht van maatregelen per fase van de levenscyclus. </p> Probleemanalyse MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Formuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. Ontwerp MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Kwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. Dataverkenning en datapreparatie MaatregelUitlegStel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.FAIR dataMaak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens Ontwikkelen MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. Verificatie en validatie MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterRestrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben. Implementatie MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Betrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Configuratie met de mensZorg voor complementariteit tussen algoritmische systeem en de mensen die ermee moeten werken.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterStel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens Monitoring en beheer MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBetrek belanghebbendenBreng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden. Uitfaseren MaatregelUitleg"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/","title":"Aansprakelijkheidsvoorwaarden worden beoordeeld in de aanbesteding","text":"<p>ProbleemanalyseImplementatieProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#maatregel","title":"Maatregel","text":"<p>Maak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#toelichting","title":"Toelichting","text":"<p>Eindgebruikers kunnen er niet altijd op vertrouwen, en ook niet (eenvoudig) nagaan, of datgene wat zij door middel van een algoritme of AI-systeem laten genereren, inbreuk maakt op rechten van derden. Hoe groot de kans is dat zij vanwege het gebruik van gegenereerde output aansprakelijk worden gesteld, is in het verlengde daarvan evenmin vast te stellen. Er zijn wel voorbeelden waarbij gebruikers voor een eventuele inbreuk aansprakelijk kunnen worden gesteld.</p> <p>Op dit moment zijn ons (nog) geen gevallen of rechtszaken bekend waarin eindgebruikers (of hun werkgevers) aansprakelijk werden gesteld voor een inbreuk op het intellectuele-eigendomsrecht vanwege het gebruik van op basis van algoritme of AI gegenereerde inhoud. Feit is echter wel dat een dergelijke aansprakelijkstelling in voorkomende gevallen dus mogelijk zullen zijn, te meer nu de aanbieders van algoritmen en AI in hun algemene voorwaarden het risico voor aansprakelijkheid (waaronder vanwege inbreuken op intellectuele eigendom) volledig of grotendeels uitsluiten, of zelfs verlangen dat gebruikers hen vrijwaren voor de gevolgen van eventuele aansprakelijkstellingen.</p> <p>Maak een beoordeling in hoeverre de aansprakelijkheidsvoorwaarden van de aanbieder passend worden geacht gezien de toepassing. Maak een jurist onderdeel van de beoordeling hiervan.</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/","title":"Archiveren beperkingen openbaarheid","text":"<p>OntwerpOntwikkelenProceseigenaarInformatiebeheerderArchiefdeskundigeJuristGovernance</p>"},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/#maatregel","title":"Maatregel","text":"<p>Stel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.</p>"},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/#toelichting","title":"Toelichting","text":"<p>Er zijn gevallen waarbij het openbaren van archiefbescheiden is uitgesloten. Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet. Stem in het begin van het proces (pro-actief) met de opdrachtgever af wat de wenselijkheid is t.a.v. transparantie/openheid (uitgangspunt zou 'open, tenzij' moeten zijn).</p>"},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden."},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/archiveren_beperkingen_openbaarheid/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/archiveren_bewaartermijnen/","title":"Vaststellen bewaartermijnen voor archiefbescheiden","text":"<p>OntwerpOntwikkelenProceseigenaarInformatiebeheerderArchiefdeskundigeGovernance</p>"},{"location":"maatregelen/archiveren_bewaartermijnen/#maatregel","title":"Maatregel","text":"<p>Stel de bewaartermijnen vast voor de archiefbescheiden.</p>"},{"location":"maatregelen/archiveren_bewaartermijnen/#toelichting","title":"Toelichting","text":"<p>Archiefbescheiden moeten voor een bepaalde tijd worden bewaard. Dit wordt de bewaartermijn genoemd. Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet. Zorg dat de ter zake c.q. van toepassing zijnde formeel vastgesteld selectielijst wordt toegepast en pas de informatie rondom algoritmes en AI hierop toe. Het is mogelijk dat de selectielijsten nog niet duiden welke informatie of data, specifiek bij de toepassing van algoritmen en AI, moet worden bewaard en dat hier dus ook nog geen termijnen aan zijn gekoppeld.</p>"},{"location":"maatregelen/archiveren_bewaartermijnen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode."},{"location":"maatregelen/archiveren_bewaartermijnen/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Rekenen en rekenschap. Essay over Algoritmes en de Archiefwet"},{"location":"maatregelen/archiveren_bewaartermijnen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/","title":"Bewaartermijnen zijn toegepast","text":"<p>OntwikkelenVerificatie en validatieProceseigenaarAanbiederData engineerData scientistSecurity officerGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/#maatregel","title":"Maatregel","text":"<p>Zorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.</p>"},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/#toelichting","title":"Toelichting","text":"<p>Hierbij kan worden gedacht aan het inrichten van de bewaartermijn voor logbestanden bij Cloudoplossingen of het bewaren van de output van algoritmen of AI-systemen in zaaksystemen. Een aanbieder moet </p>"},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode."},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/archiveren_bewaartermijnen_implementeren/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/","title":"Archiefbescheiden zijn duurzaam toegankelijk","text":"<p>OntwikkelenProceseigenaarInformatiebeheerderArchiefdeskundigeGovernance</p>"},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/#maatregel","title":"Maatregel","text":"<p>Stel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.</p>"},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/#toelichting","title":"Toelichting","text":"<p>Het moet mogelijk zijn dat de archiefbescheiden daadwerkelijk overhandigd kunnen worden aan betrokken partijen. Denk hierbij aan burgers, onderneming, toezichthouder of rechters. Duurzaam betekent hier met behoud van functie en kwaliteit voor langere tijd. Onderzoek welke voorziening hiervoor beschikbaar is binnen de organisatie.</p>"},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden."},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/archiveren_duurzaam_toegankelijk/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/archiveren_vaststellen_documenten/","title":"Archiefbescheiden vaststellen","text":"<p>OntwerpOntwikkelenProceseigenaarInformatiebeheerderArchiefdeskundigeData scientistJuristGovernance</p>"},{"location":"maatregelen/archiveren_vaststellen_documenten/#maatregel","title":"Maatregel","text":"<p>Stel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.</p>"},{"location":"maatregelen/archiveren_vaststellen_documenten/#toelichting","title":"Toelichting","text":"<p>Hierbij kan worden gedacht aan de broncode, trainings- en testdata, (technische) documentatie en de output. Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet. Het is mogelijk dat de selectielijsten nog niet duiden welke informatie of data, specifiek bij de toepassing van algoritmen en AI, moet worden toegepast. Formeer hierbij een multi-discipinaire groep (bestaande uit bv. een inkoper, ontwikkelaar, data scientist, proceseigenaar en archief deskundige) om deze maatregel toe te passen.</p>"},{"location":"maatregelen/archiveren_vaststellen_documenten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode."},{"location":"maatregelen/archiveren_vaststellen_documenten/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Rekenen en rekenschap. Essay over Algoritmes en de Archiefwet"},{"location":"maatregelen/archiveren_vaststellen_documenten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/autorisatiematrix_inrichten/","title":"Stel een autorisatiematrix op","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenImplementatieProceseigenaarAanbiederSecurity officerInkoopadviseurPrivacy en gegevensbeschermingTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/autorisatiematrix_inrichten/#maatregel","title":"Maatregel","text":"<p>Uitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.</p>"},{"location":"maatregelen/autorisatiematrix_inrichten/#toelichting","title":"Toelichting","text":"<p>Stel een RACI-matrix op en definieer rollen en verantwoordelijkheden. Verwerk dit in de ontwikkelomgeving (inrichten rollen en bevoegdheden).</p>"},{"location":"maatregelen/autorisatiematrix_inrichten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegBeveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn."},{"location":"maatregelen/autorisatiematrix_inrichten/#bronnen","title":"Bronnen","text":"Bron Baseline Informatiebeveiliging Overheid"},{"location":"maatregelen/autorisatiematrix_inrichten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/","title":"Bepaal of de output bepalende invloed heeft in een besluit richting personen","text":"<p>OntwikkelenMonitoring en beheerBehoeftestellerProceseigenaarGebruikerInkoopadviseurEthicusJuristPublieke inkoop</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#maatregel","title":"Maatregel","text":"<p>Ga na of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat de aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#toelichting","title":"Toelichting","text":"<p>Maak een beoordeling in hoeverre de mate waarin menselijke tussenkomst is of kan worden gerealiseerd. Raadpleeg voor deze beoordeling verschillende experts, zoals een gebruiker, proceseigenaar, ethicus en jurist.</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen."},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/","title":"Bespreek de vereiste met aanbieder of opdrachtnemer","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristAanbiederOpdrachtnemerPublieke inkoop</p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#maatregel","title":"Maatregel","text":"<p>Bespreek de vereiste met aanbieder. </p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#toelichting","title":"Toelichting","text":"<p>Ga met een aanbieder en/of met opdrachtnemers in gesprek over in hoeverre deze invulling heeft gegeven of gaat geven aan de vereiste. Op basis van nieuwe of gewijzigde wet- en regelgeving is het denkbaar dat een aanbieder van algoritmes of AI-systemen nog niet of niet meer voldoet aan deze vereiste. Indien van toepassing, laat de aanbieder inzichtelijk maken welke stappen deze gaat zetten om hieraan te gaan voldoen. Dit is ook relevant bij reeds afgesloten contracten.  </p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/betrek_belanghebbenden/","title":"Betrek belanghebbenden","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerFundamentele rechten</p>"},{"location":"maatregelen/betrek_belanghebbenden/#maatregel","title":"Maatregel","text":"<p>Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus. Belanghebbenden zijn onder meer eindgebruikers, mensen en rechtspersonen die door het algoritme geraakt kunnen worden en vertegenwoordigende organisaties.</p>"},{"location":"maatregelen/betrek_belanghebbenden/#toelichting","title":"Toelichting","text":"<p>Algoritmes worden vaak gebruikt binnen een (specifieke) context waar deze invloed op uitoefenen. Medewerkers moeten bijvoorbeeld werken met de uitkomsten of anderen zijn onderwerp van het algoritme. Om te voorkomen dat er een mismatch ontstaat met de realiteit, is het van belang om specifieke domeinkennis te betrekken.</p> <p>Het betrekken van belanghebbenden is van belang in bijna alle fasen van de levenscyclus.</p> <p>In de fase van de probleemanalyse is het allereerst van belang in kaart te brengen welke stakeholders er zijn. Wie gaan bijvoorbeeld werken met het algoritme (eindgebruikers)? En welke demografie\u00ebn worden geraakt door een algoritme? Bij wie liggen de voordelen en bij wie liggen de nadelen? Ga vervolgens in gesprek met belanghebbenden - al dan niet vertegenwoordigd door belangenorganisaties zoals burgerrechtenorganisaties - over het te ontwerpen algoritme en de context waarin het gebruikt wordt. Bespreek daarbij welke definitie en metriek van fairness past bij de context.</p> <p>In de fase van dataverkenning en datapreparatie is het van belang om domeinexpertise te betrekken, om zo in kaart te brengen wat de data features betekenen en waar zij vandaan komen. Op basis daarvan kan in kaart gebracht worden of er sprake is van bias en/of links met beschermde persoonskenmerken.</p> <p>In de fase van implementatie is het van belang de eindgebruikers te betrekken. Het is dan vooral van belang om maatregelen te nemen om automation bias, deployment bias en reinforcing feedback loop te voorkomen of te beperken.</p> <p>In de fase van monitoren is het van belang belanghebbenden te betrekken bij de evaluatie. Dit kan bijvoorbeeld in de vorm van een survey of focusgroep. Zij kunnen problemen in de praktijk naar voren brengen, die niet altijd terug te vinden zijn in de data.</p> <p>Terugkoppelen aan buitenwereld.</p>"},{"location":"maatregelen/betrek_belanghebbenden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitleg"},{"location":"maatregelen/betrek_belanghebbenden/#bronnen","title":"Bronnen","text":"Bron Toetsingskader Algemene Rekenkamer 2.12 The Fairness Handbook Handreiking non-discriminatie by design Ethics Guidelines for Trustworthy AI Onderzoekskader Algoritmes Auditdienst Rijk, SV.10"},{"location":"maatregelen/betrek_belanghebbenden/#risico","title":"Risico","text":"<p>De mismatch kan nadelige gevolgen hebben voor de effectiviteit van het algoritme binnen een context. Het kan daarnaast ook ongerechtvaardigde discriminatie in de hand werken. Ontwikkelaars kunnen bijvoorbeeld missen dat in de context van het algoritme een variabele een proxy is voor een discriminatiegrond.</p>"},{"location":"maatregelen/betrek_belanghebbenden/#voorbeeld","title":"Voorbeeld","text":"<p>Richt een burgerpanel in.</p> <p>Methodologie van Waag, Civic AI lab, Stakeholder escalation ladder. Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/configuratie_met_de_mens/","title":"Configuratie met de mens","text":"<p>ImplementatieGovernanceMenselijke controle</p>"},{"location":"maatregelen/configuratie_met_de_mens/#maatregel","title":"Maatregel","text":"<ul> <li>Maak keuzes rondom de rol van het systeem in de werkwijze van medewerkers.</li> <li>Gebruik duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden be\u00efnvloed.</li> <li>Stel een structuur op voor het melden van mogelijke problemen met het systeem.</li> <li> <p>Opleiding van medewerkers over:</p> <ul> <li> <p>AI en algoritmes;</p> </li> <li> <p>het systeem waarmee ze gaan werken;</p> </li> <li> <p>de rol van het systeem in hun werkwijze;</p> </li> <li> <p>de risico's die aan het gebruik van een systeem verbonden zijn (bijv. (automation) bias, false positives/negatives);</p> </li> <li> <p>de maatregelen die genomen zijn om deze risico\u2019s te beperken (bijv. Willekeurige of fictieve casussen, transparantie over de output).</p> </li> </ul> </li> <li> <p>Bespreek regelmatig de uitdagingen die medewerkers ondervinden bij het werken met het systeem (bijv. tijdsdruk).</p> </li> <li>Documenteer alle keuzes en de onderliggende redenen/afwegingen rondom  menselijke tussenkomst en overzicht, bijvoorbeeld in een Algoritme Impact Assessment. Evalueer en pas gemaakte keuzes waar nodig aan.</li> </ul>"},{"location":"maatregelen/configuratie_met_de_mens/#toelichting","title":"Toelichting","text":"<p>Zorg voor complementariteit tussen medewerkers en systemen. Dit helpt bij het voorkomen van (automation) bias en discriminatie, het signaleren van algoritmische problemen, en het vermijden van de facto automatische besluitvorming.</p>"},{"location":"maatregelen/configuratie_met_de_mens/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat."},{"location":"maatregelen/configuratie_met_de_mens/#bronnen","title":"Bronnen","text":"Bron Handreiking non-discriminatie by design Impact Assessment Mensenrechten en Algoritmes Ethics Guidelines of Trustworthy AI"},{"location":"maatregelen/configuratie_met_de_mens/#risico","title":"Risico","text":"<p>Bias, discriminatie, de facto automatische besluitvorming.</p>"},{"location":"maatregelen/configuratie_met_de_mens/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/","title":"Contractuele afspraken over data en artefacten","text":"<p>OntwerpMonitoring en beheerProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristAanbiederPublieke inkoop</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#maatregel","title":"Maatregel","text":"<p>Maak (contractuele) afspraken met de aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#toelichting","title":"Toelichting","text":"<p>Hier kan worden gedacht aan de initi\u00eble trainingsdataset, outputdata (richting gebruikers) en nieuwe trainingsdata (vanuit gebruikers).</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/","title":"Controleren eigen data op schending auteursrechten","text":"<p>OntwerpDataverkenning en datapreparatieProceseigenaarInformatiebeheerderJuristData</p>"},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/#maatregel","title":"Maatregel","text":"<p>Controleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.</p>"},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/#toelichting","title":"Toelichting","text":"<p>Het is van belang om te controleren of de te verwerken data waar overheidsorganisaties zelf over beschikken rechtmatig zijn verkregen en geen inbreuken maken op auteursrechten. Hier kan worden gedacht aan data die is gescraped van het internet en zou kunnen worden gebruikt voor de ontwikkeling van een algoritme of AI-systeem.</p>"},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/controle_eigen_data_schending_auteursrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/","title":"Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken output","text":"<p>OntwikkelenMonitoring en beheerProceseigenaarGebruikerAanbiederMenselijke controle</p>"},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/#maatregel","title":"Maatregel","text":"<p>Zorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.</p>"},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/#toelichting","title":"Toelichting","text":"<p>Dit punt is onderdeel van een procesinrichting bij de gebruiksverantwoordelijke en gebruiker van het algoritme of AI-systeem en zou technisch gefaciliteerd moeten kunnen worden. Dit ligt dan deels bij de aanbieder als het door de opdrachtgever wordt voorgeschreven dat doorklikken niet hetzelfde is als menselijke tussenkomst en in dat kader de technische mogelijkheid moet worden voorkomen.</p>"},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen."},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/controle_mechanisme_betekenisvolle_menselijke_tussenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/","title":"Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerInkoopadviseurAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#maatregel","title":"Maatregel","text":"<p>Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#toelichting","title":"Toelichting","text":"<p>Om op een betekenisvolle manier invulling te geven aan bepaalde vereisten, kan het noodzakelijk zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) moeten samenwerken. Op basis van nieuwe wet- en regelgeving (bv. AI-Verordening) kunnen aanbieders mogelijk nog niet voldoen aan deze nieuwe vereisten of is onduidelijk op welke manier hier invulling aan moet worden gegeven.  In de context van algoritmes en AI kan het voor bepaalde onderwerpen zoals non-discriminatie, transparantie en eerbiedigen van fundamentele rechten van belang zijn om samen te verkennen hoe hier invulling aan moet worden gegeven. Het is belangrijk om bij de behoeftestelling al te verkennen op welke onderwerpen dit mogelijk van toepassing is. </p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegVerplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Ruimte voor Innovatie in het contract"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/","title":"Pas maatregelen toe om (persoons)gegevens te beschermen","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenProceseigenaarAanbiederData engineerSecurity officerPrivacy officerPrivacy en gegevensbeschermingTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/#maatregel","title":"Maatregel","text":"<p>Pas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.</p>"},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/#toelichting","title":"Toelichting","text":""},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegBeveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn."},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Art. 25 AVG Algemene Verordening Gegevensbescherming"},{"location":"maatregelen/dataminimalisatie_pseudonimisering_anonimisering_aggregeren_persoonsgegevens/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/fair-data/","title":"FAIR data","text":"<p>Dataverkenning en datapreparatieData engineer</p>"},{"location":"maatregelen/fair-data/#maatregel","title":"Maatregel","text":"<p>Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.</p>"},{"location":"maatregelen/fair-data/#toelichting","title":"Toelichting","text":"<p>De internationale FAIR-principes zijn richtlijnen voor de manier van beschrijven, opslag en publicatie van data. </p> <ul> <li>Findable (vindbaar): Metadata moet gemakkelijk te vinden zijn voor zowel mensen als computers.</li> <li>Accessible (toegankelijk): Gebruikers moeten weten hoe toegang tot de data verkregen kan worden (autorisatie en authenticatie)</li> <li>Interoperable (uitwisselbaar): Data moet meestal ge\u00efntegreerd worden met andere data en bijbehorden applicaties, opslag en processen.</li> <li>Reusable (herbruikbaar): Het uiteindelijke doel van FAIR is om hergebruik van data te optimaliseren.</li> </ul> <p>Wanneer je voldoet aan de 15 principes is je data 'machine actionable'. Dit maakt het mogelijk dat de data effectief gebruikt kan worden voor verschillende algoritmes en AI-systemen.</p> <p>FAIR data betekent niet per definitie dat data open data is. Juist ook voor (privacy) gevoelige data (gesloten data) kan het heel zinvol zijn om te voldoen aan de principes voor FAIR data, om juist daarmee specifieke geautoriseerde toegang tot gevoelige data mogelijk te kunnen maken.</p>"},{"location":"maatregelen/fair-data/#15-principes-voor-fair-data","title":"15 principes voor FAIR data","text":"<p>Er zijn 15 principes voor FAIR data geformuleerd:</p>"},{"location":"maatregelen/fair-data/#findable-vindbaar","title":"Findable (vindbaar)","text":"<ul> <li> <p>F1: Aan (meta)data wordt een wereldwijd unieke en permanente identifier toegevoegd</p> <p>Voorbeeld</p> <p>Met behulp van Persistent Identifiers (PID) zorg je ervoor dat jouw data (bijvoorbeeld onderzoeksdata) altijd vindbaar blijft.  PID's kun je vergelijken met het ISBN-nummer bij boeken. Het idee is dat ook als de locatie of de onderliggende infrastructuur verandert, de verwijzing intact blijft. </p> </li> <li> <p>F2: Data wordt beschreven met rijke metadata</p> <p>Voorbeeld</p> <p>Het team van data.overheid.nl heeft de metadata standaard DCAT-AP-DONL ontwikkeld die speciaal voor de uitwisseling van dataset informatie voor de Nederlandse situatie is ingericht. Dit is gebaseerd op de Data Catalog Vocabulary (DCAT) versie die de Europese Unie heeft opgesteld. Je kan hierover meer lezen op de site van data.overheid.nl.</p> </li> <li> <p>F3: Metadata bevat duidelijk en expliciet de identificatie van de data die ze beschrijven</p> </li> <li>F4: (Meta)data worden geregistreerd of ge\u00efndexeerd in een doorzoekbare bron </li> </ul>"},{"location":"maatregelen/fair-data/#accessible-toegankelijk","title":"Accessible (toegankelijk)","text":"<ul> <li>A1: (Meta)data zijn opvraagbaar op basis van hun identificatiecode met behulp van een gestandaardiseerd communicatieprotocol </li> <li>A1.1: Het protocol is open, vrij en universeel implementeerbaar </li> <li>A1.2: Het protocol maakt waar nodig een authenticatie- en autorisatieprocedure mogelijk </li> <li>A2: Metadata zijn toegankelijk, ook als de data niet meer beschikbaar zijn </li> </ul>"},{"location":"maatregelen/fair-data/#interoperable-uitwisselbaar","title":"Interoperable (uitwisselbaar)","text":"<ul> <li>I1: (Meta)data gebruikt een formele, toegankelijke, gedeelde en breed toepasbare taal voor kennisrepresentatie </li> <li> <p>I2: (Meta)data gebruikt gegevenswoordenboeken of vocabulaires die FAIR-principes volgen </p> <p>Voorbeeld woordenboek</p> <p>In het woordenboek Hitte staan ongeveer 230 definities van termen rond het thema hitte die gebruikt worden in het klimaatadaptatieveld. Dit woordenboek is ontwikkeld in opdracht van het ministerie van Infrastructuur en Waterstaat door overheidsstichting Geonovum.</p> </li> <li> <p>I3: (Meta)data bevat gekwalificeerde verwijzingen naar andere (meta)data </p> </li> </ul>"},{"location":"maatregelen/fair-data/#reusable-herbruikbaar","title":"Reusable (herbruikbaar)","text":"<ul> <li>R1: (Meta)data wordt rijkelijk beschreven met een veelheid aan nauwkeurige en relevante attributen </li> <li>R1.1: (Meta)data wordt vrijgegeven met een duidelijke en toegankelijke licentie voor datagebruik </li> <li> <p>R1.2: (Meta)data wordt geassocieerd met gedetailleerde herkomst </p> <p>Voorbeeld</p> <p>PROV-DM is een conceptueel datamodel dat gebruikt kan worden voor de herkomstinformatie (provenance) van data. </p> </li> <li> <p>R1.3: (Meta)data voldoet aan domein-relevante normen </p> </li> </ul>"},{"location":"maatregelen/fair-data/#vereisten","title":"Vereisten","text":"VereisteUitleg <p>Opmerking</p> <p>Artikel 5b van de Wet hergebruik van overheidsinformatie stelt dat dnderzoeksgegevens in overeenstemming met de FAIR-beginselen actief beschikbaar moeten worden gesteld voor hergebruik door een publiek gefinancierde onderzoeksorganisatie. Dit geldt voor zover:</p> <ol> <li>die documenten zijn geproduceerd in het kader van geheel of gedeeltelijk met overheidsmiddelen gefinancierde wetenschappelijke onderzoeksactiviteiten;</li> <li>die documenten openbaar zijn gemaakt via een institutionele of thematische databank als bedoeld in artikel 10, tweede lid, van de richtlijn; en</li> <li>rechtmatige handelsbelangen, activiteiten inzake kennisoverdracht en reeds bestaande intellectuele eigendomsrechten zich hiertegen niet verzetten.</li> </ol>"},{"location":"maatregelen/fair-data/#bronnen","title":"Bronnen","text":"<ul> <li>GO FAIR Foundation</li> <li>3-point FAIRification framework 3PFF</li> <li>Toolbox verantwoord datagebruik, 2b</li> <li>NORA online</li> </ul>"},{"location":"maatregelen/formuleren_doelstellling/","title":"Formuleren doelstelling","text":"<p>ProbleemanalyseProjectleiderOpdrachtgeverDomeinspecialistGovernance</p>"},{"location":"maatregelen/formuleren_doelstellling/#maatregel","title":"Maatregel","text":"<p>Het doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.  Maak de consequenties van het algoritme specifiek en zorg dat het doel van het algoritme formeel is vastgesteld en vastgelegd. </p>"},{"location":"maatregelen/formuleren_doelstellling/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Het doel van de inzet van een algoritme dient zo concreet en specifiek mogelijk gedefinieerd te worden.  Indien er meerdere doelen zijn, is het belangrijk om een zekere rangorde te maken: wat zijn de belangrijkste doelen? En waarom? Welke doelen zijn subdoelen, waarvoor het minder belangrijk is om deze te realiseren?</p> </li> <li> <p>Indien mogelijk, dienen de doelstellingen gekwantificeerd te worden (SMART). </p> </li> <li> <p>Om te zorgen voor voldoende draagvlak voor de beoogde doelen, is het noodzaak om voldoende belanghebbenden te betrekken.  Hierbij kan het ook helpen om burgers te betrekken bij de totstandkoming van de doelstellingen, bijvoorbeeld door middel van een burgerpanel of het betrekken van belangengroepen. </p> </li> </ul>"},{"location":"maatregelen/formuleren_doelstellling/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"maatregelen/formuleren_doelstellling/#risico","title":"Risico","text":"<p>Het algoritme dient niet het beoogde doel en onderliggend probleem.  Zonder eenduidigheid over het doel is geen sturing op en verantwoording over het algoritme mogelijk.  Er is dan een groter risico op fouten en/of verschillen in interpretatie. </p> <p>Wanneer doelstellingen niet meetbaar zijn gemaakt, is het onmogelijk om achteraf te kwantificeren of de doelstellingen zijn behaald.  Doelstellingen zijn in dat geval moeilijk bespreekbaar.  </p>"},{"location":"maatregelen/formuleren_doelstellling/#bronnen","title":"Bronnen","text":"Bron Toetsingskader Algoritmes Algemene Rekenkamer, 1.01, 1.02 Impact Assessment Mensenrechten en Algoritmes, 1.2 Onderzoekskader Algoritmes Auditdienst Rijk, SV.3"},{"location":"maatregelen/formuleren_doelstellling/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/formuleren_probleemdefinitie/","title":"Formuleren aanleiding en probleemdefinitie","text":"<p>ProbleemanalyseProjectleiderOpdrachtgeverDomeinspecialistGovernance</p>"},{"location":"maatregelen/formuleren_probleemdefinitie/#maatregel","title":"Maatregel","text":"<p>Formuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.  Formuleer duidelijk de probleemdefinitie en probleemafbakening waarvoor het algoritme een oplossing zou moeten vormen. </p>"},{"location":"maatregelen/formuleren_probleemdefinitie/#toelichting","title":"Toelichting","text":"<p>Formuleer de probleemdefinitie en probleemafbakening zo concreet en precies mogelijk. Maak dit waar mogelijk kwantificeerbaar. </p>"},{"location":"maatregelen/formuleren_probleemdefinitie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"maatregelen/formuleren_probleemdefinitie/#risico","title":"Risico","text":"<p>Het algoritme dient niet het onderliggende probleem.  Zonder eenduidigheid over het op te lossen probleem is geen sturing op en verantwoording over het algoritme mogelijk. </p>"},{"location":"maatregelen/formuleren_probleemdefinitie/#bronnen","title":"Bronnen","text":"Bron Impact Assessment Mensenrechten en Algoritmes, 1.1 Onderzoekskader Algoritmes Auditdienst Rijk, SV.1"},{"location":"maatregelen/formuleren_probleemdefinitie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/","title":"Verken maatregelen van aanbieder om schending auteursrechten te voorkomen","text":"<p>ProbleemanalyseImplementatieProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristAanbiederPublieke inkoop</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#maatregel","title":"Maatregel","text":"<p>Verken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#toelichting","title":"Toelichting","text":"<p>Als 'open gaten' worden ervaren, dan is het van belang om hierover met de aanbieder in gesprek te gaan, bijvoorbeeld door een marktconsultatie of algemene materie gerelateerde gesprekken. De ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) adresseren het schenden van intellectueel eigendom.</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#bronnen","title":"Bronnen","text":"Bron ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) Algoritmekader"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/kwetsbare_groepen/","title":"Kwetsbare groepen in kaart brengen en beschermen","text":"<p>OntwerpProjectleiderOpdrachtgeverEthicusFundamentele rechten</p>"},{"location":"maatregelen/kwetsbare_groepen/#maatregel","title":"Maatregel","text":"<p>Bepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.</p>"},{"location":"maatregelen/kwetsbare_groepen/#toelichting","title":"Toelichting","text":"<ul> <li>Verschillende groepen kunnen op een andere manier geraakt worden door het inzetten van een algoritme. Dit is afhankelijk van de context waarin het algoritme wordt ingezet, en dient daardoor bij iedere toepassing opnieuw bekeken te worden. </li> <li>Bedenk wat er met de uitkomsten van het algoritme gedaan wordt, en wat de consequenties daarvan zijn voor burgers. Hierbij kan gedacht worden aan de volgende aspecten:<ul> <li>Worden bepaalde groepen sneller gemonitord?</li> <li>Wat als het model het fout heeft? </li> <li>Wordt het systeem gebruikt om informatie te verkrijgen, om besluiten voor te bereiden of om zelfstandige besluiten te nemen en welke gevolgen heeft dat voor de mate waarin het algoritme bepalend zal zijn in de praktijk? </li> <li>Worden de gegevens veilig en vertrouwelijk behandeld; welke gevolgen zou een datalek hebben voor groepen of categorie\u00ebn personen?</li> <li>Worden data gedeeld met andere partijen en wat is het gevaar dat die misbruik maken van de data met negatieve gevolgen voor groepen of categorie\u00ebn personen?</li> </ul> </li> <li>Houd hierbij ook rekening met de impact van het in te zetten algoritme op de samenleving (vanuit sociaal, democratisch en milieu/ecologisch perspectief).</li> <li>Om de impact op groepen te bepalen, kan het handig zijn een mensenrechtentoets zoals het Impact Assessment Mensenrechten en Algoritmes toe te passen. </li> <li>Bepaal of er maatregelen genomen kunnen worden om de ge\u00efdentificeerde groepen extra bescherming te bieden. Hierbij kan men denken aan de volgende aspecten: Kan de (extra) administratieve druk voor bepaalde groepen worden weggenomen? Worden resultaten van het algoritme naast de resultaten van een expert gelegd? Is het wenselijk om een proces in te richten waarbij zowel algoritme als een expert een uitkomst geven? Kunnen we de betreffende groep extra hulp aanbieden? Is het wenselijk bij negatieve uitkomsten een vier-ogen-principe toe te passen? </li> <li>De impact van het algoritme op de groepen die ge\u00efdentificeerd worden in deze stap, kunnen mogelijk onderzocht worden in een biasanalyse. Daarbij kan geidentificeerd worden of bepaalde groepen oververtegenwoordigd of ondervertegenwoordigd zijn in selecties, of dat het algoritme andere of meer fouten maakt voor bepaalde groepen. </li> <li>Merk op dat het onmogelijk is om de risico's voor alle specifieke groepen af te vangen. Hierbij kan het helpen om te focussen op de meest kwetsbare groepen. </li> </ul>"},{"location":"maatregelen/kwetsbare_groepen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitleg"},{"location":"maatregelen/kwetsbare_groepen/#risico","title":"Risico","text":"<p>De impact van het algoritme op de besluitvorming en op personen, doelgroepen en/of de samenleving is niet inzichtelijk, waardoor onvoldoende maatregelen zijn getroffen om ongewenste effecten (zoals bias en discriminatie) te voorkomen. </p>"},{"location":"maatregelen/kwetsbare_groepen/#bronnen","title":"Bronnen","text":"Bron Onderzoekskader Algoritmes Auditdienst Rijk, SV.4 Kamerstukken II 2023/24, 31066-1374 Impact Assessment Mensenrechten en Algoritmes, 4.1 Handreiking non-discriminatie by design, 1.7 en 1.8 en 1.15"},{"location":"maatregelen/kwetsbare_groepen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/","title":"Bewijs laten leveren dat auteursrechten niet worden geschonden met de output","text":"<p>OntwerpMonitoring en beheerProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristGemandateerd verantwoordelijkePublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#maatregel","title":"Maatregel","text":"<p>Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen of de output van een algoritme een (potenti\u00eble) inbreuk maakt op auteursrechten. Maak een jurist onderdeel van de beoordeling hiervan.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/","title":"Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdata","text":"<p>OntwerpMonitoring en beheerProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#maatregel","title":"Maatregel","text":"<p>Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#toelichting","title":"Toelichting","text":"<p>Algoritmen en AI worden veelal getraind aan de hand van een omvangrijke hoeveelheid data. Op basis van de data wordt het algoritme of AI getraind om, op een later moment, de (door de eindgebruiker gewenste) uitkomsten te kunnen genereren.</p> <p>Wanneer grote hoeveelheden data, bijvoorbeeld door deze te scrapen van internet, worden gebruikt voor de training van algoritmen of AI, is het zeer aannemelijk (of: nagenoeg zeker) dat zich onder de gescrapete inhoud (ook) veel auteursrechtelijk beschermde werken bevinden, zoals bijvoorbeeld e-books en afbeeldingen. De gebruikte auteursrechtelijke werken kunnen soms bijvoorbeeld uit illegale bron verkregen zijn, en ook los daarvan zijn rechthebbenden veelal niet op de hoogte van het feit dat hun auteursrechtelijke werken voor de ontwikkeling van een algoritme of AI gebruikt worden.</p> <p>Onder auteursrechtjuristen wordt aangenomen dat het gebruik van auteursrechtelijke beschermde werken ter training van algoritme of AI (waarschijnlijk) een verveelvoudigingshandeling is die de rechthebbende kan verbieden. Dat betekent dat aanbieders van algoritmen en AI het gebruik van auteursrechtelijk beschermd materiaal in de inputfase steeds zullen moeten kunnen legitimeren op grond van (a) toestemming van de rechthebbende(n) of (b) een in de wet neergelegde exceptie op het auteursrechtelijke verveelvoudigingsrecht.</p> <p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Maak een jurist onderdeel van de beoordeling hiervan. Overweeg om een bronvermelding te laten opnemen.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/","title":"Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving","text":"<p>OntwerpOntwikkelenPublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#maatregel","title":"Maatregel","text":"<p>Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#toelichting","title":"Toelichting","text":"<p>Door de inschrijver/aanbieder bewijs te laten leveren dat deze voldoet aan de vereiste, kan worden beoordeeld door opdrachtgever in hoeverre daadwerkelijk wordt voldaan aan deze vereiste. Op deze manier worden inschrijvers/aanbieders aangespoord om te motiveren wat zij hebben gedaan om te voldoen aan de vereiste.  </p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico."},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/","title":"Maak de vereiste onderdeel van het programma van eisen","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerData scientistInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van het programma van eisen</p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#toelichting","title":"Toelichting","text":"<p>Door de vereiste onderdeel te maken van het programma van eisen, is het voor aanbieders duidelijk dat hun oplossing hieraan moet voldoen.  Afhankelijk van de specifieke toepassing, context en noodzaak kan een vereiste in het programma van eisen concreet worden gemaakt.  Het is hierbij van belang om dit af te wegen tegen zaken die mogelijk al zijn geregeld door middel van algemene inkoopvoorwaarden die gelden voor algoritmes en AI.   </p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegVerplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/","title":"Maak de vereiste onderdeel van contractvoorwaarden","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van contractvoorwaarden </p>"},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/#toelichting","title":"Toelichting","text":"<p>Door de vereiste onderdeel te maken van contractvoorwaarden, is voor aanbieder vooraf duidelijk aan welke voorwaarden zij moeten voldoen als zijn algoritmes en AI-systemen willen aanbieden.  Het is van belang om een afweging te maken in welke gevallen contractvoorwaarden worden ingezet en welke vereisten daarbij horen.  Welke vereisten onderdeel moeten worden gemaakt van contractvoorwaarden is afhankelijk van de beoogde toepassing.  Er zijn meer vereiste van toepassing bij impactvolle en hoog risico AI-systemen, waarmee burgers potentieel in aanmerkelijke mate kunnen worden getroffen dan bij geen impactvolle of laag risico AI-systemen. </p>"},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Contractvoorwaarden gemeente Amsterdam Europese Inkoopvoorwaarden Hoog Risico Europese Inkoopvoorwaarden Laag Risico"},{"location":"maatregelen/maak_vereiste_onder_van_contractvoorwaarden/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/","title":"Maak de vereiste onderdeel van de contractovereenkomst","text":"<p>OntwerpOntwikkelenPublieke inkoop</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van de contractovereenkomst </p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#toelichting","title":"Toelichting","text":"<p>Door de vereiste onderdeel te namen van de contractovereenkomst, zijn deze voorwaarden voor opdrachtgever richting aanbieder/opdrachtnemer afdwingbaar. Het is van belang dat bij de behoeftestelling een afweging wordt gemaakt in hoeverre de betreffende vereiste van toepassing is. </p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Contractvoorwaarden gemeente Amsterdam Europese Inkoopvoorwaarden Hoog Risico Europese Inkoopvoorwaarden Laag Risico"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/","title":"Maak de vereiste onderdeel van Service Level Agreement","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van Service Level Agreement</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#toelichting","title":"Toelichting","text":"<p>Onderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement (SLA). Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening. Hierbij kan worden gedacht aan onderwerpen als incidentmanagement, servicemanagement, verantwoordelijkheden matrix, hersteltijd en beveiliging.  Laat de aanbieder aangeven welke vormen van onderhoud aan het algoritme of AI-systeem nodig zijn en de snelheid waarmee signalen vanuit gebruik, ongeacht de bron, kunnen worden verwerkt in het systeem.</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAutomatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico."},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/","title":"Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocument","text":"<p>ProbleemanalyseOntwikkelenMonitoring en beheerBehoeftestellerProceseigenaarInkoopadviseurGovernancePublieke inkoop</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#maatregel","title":"Maatregel","text":"<p>Neem het element van menselijke tussenkomst op in het projectplan en d\u00e9chargedocument.</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#toelichting","title":"Toelichting","text":"<p>Dit punt is onderdeel van een procesinrichting bij de gebruiksverantwoordelijke of gebruiker van het altgoritme of AI-systeem en zou technisch gefaciliteerd moeten kunnen worden. Het inrichten van menselijke tussenkomst ligt niet enkel bij de aanbieder en kan contractueel niet enkel bij de aanbieder worden neergelegd. Overweeg om een waarschuwingsplicht te expliciteren, in geval de aanbieder ziet dat geautomatiseerde besluiten aan geautomatiseerde berichtgeving is gekoppeld zonder menselijke tussenkomst. Ook dan ligt het in beginsel bij de gebruiksverantwoordelijke, maar maken de omstandigheden een grijzer gebied.</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen."},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/","title":"Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerkt","text":"<p>OntwerpMonitoring en beheerProceseigenaarPrivacy officerInkoopadviseurPublieke inkoopPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/#maatregel","title":"Maatregel","text":"<p>Inventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.</p>"},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/#toelichting","title":"Toelichting","text":"<p>Een model-verwerkersoverenkomst is veelal een verplicht onderdeel bij het publiek inkopen van software waarbij persoonsgegevens worden verwerkt en bij de totstandkoming van de overeenkomst.</p>"},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegEen DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd."},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/model-verwerkersovereenkomst_onderdeel_aanbesteding/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/neem_technische_documentatie_in_algoritmeregister/","title":"Neem technische documentatie op in het algoritmeregister","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerProceseigenaarPrivacy officerData scientistData engineerBeleidsmedewerkerTransparantie</p>"},{"location":"maatregelen/neem_technische_documentatie_in_algoritmeregister/#maatregel","title":"Maatregel","text":"<p>Neem geschikte informatie uit technische documentatie op in het algoritmeregister.</p>"},{"location":"maatregelen/neem_technische_documentatie_in_algoritmeregister/#toelichting","title":"Toelichting","text":"<p>Met het opstellen van technische documentatie over algoritmes en AI-systemen wordt belangrijke informatie vastgelegd die moet worden opgenomen of kan worden opgenomen in het Algoritmeregister. De Handreiking Algoritmeregister en de Publicatiestandaard van het register kan worden geraadpleegd om te bepalen of en welke informatie van een algoritme of AI-systeem moet worden gepubliceerd. Door dit goed af te stemmen kan hergebruik worden gemaakt van al gedocumenteerde informatie. </p>"},{"location":"maatregelen/neem_technische_documentatie_in_algoritmeregister/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegImpactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen."},{"location":"maatregelen/neem_technische_documentatie_in_algoritmeregister/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Handreiking Algoritmeregister Publicatiestandaard"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/","title":"Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerData scientistEthicusPrivacy officerSecurity officerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#maatregel","title":"Maatregel","text":"<p>Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding. </p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#toelichting","title":"Toelichting","text":"<p>Door de vereiste op te nemen als subgunningscriteria, ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden. In de context van algoritmes en AI is dit in het bijzonder relevant, bijvoorbeeld in relatie tot vereisten als non-discriminatie, eerbiedigen privacyrechten of het verbod op schenden auteursrechten. Door vereisten te vertalen naar een subgunningscriteria, kan een inhoudelijke beoordeling worden gemaakt in hoeverre een aanbieder hier invulling aan geeft.</p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico."},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/","title":"Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaakt","text":"<p>OntwikkelenVerificatie en validatieProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#maatregel","title":"Maatregel","text":"<p>Maak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat de resterende risico's inzichtelijk zijn gemaakt, zodat aanbieder en gebruiksverantwoordelijke maatregelen kunnen treffen en handelen als dit nodig is.</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/","title":"Formuleren aanleiding en probleemdefinitie","text":"<p>ProbleemanalyseProjectleiderOpdrachtgeverDomeinspecialistGovernance</p>"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#maatregel","title":"Maatregel","text":"<p>Bepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. </p>"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Bepaal waarom het gewenst of nodig is om een algoritme in te zetten, en of er ook alternatieven zijn om het probleem op te lossen.  Documenteer de onderbouwing waarom een algoritme een betere oplossing zou bieden dan een niet-geautomatiseerd of niet-digitaal proces. </p> </li> <li> <p>Maak een bewuste afweging of een algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen, en documenteer deze afweging. </p> </li> </ul>"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegRelevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#risico","title":"Risico","text":"<p>Het algoritme is niet het juiste middel om het probleem op te lossen. Het risico daarbij bestaat dat het probleem niet wordt opgelost. </p>"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#bronnen","title":"Bronnen","text":"Bron Impact Assessment Mensenrechten en Algoritmes, 1.1 Onderzoekskader Algoritmes Auditdienst Rijk, SV.2"},{"location":"maatregelen/onderbouwen_gebruik_algoritme/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/","title":"Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de output","text":"<p>OntwikkelenMonitoring en beheerProceseigenaarBehoeftestellerInkoopadviseurContractbeheerderAanbestedingsjuristPublieke inkoop</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#maatregel","title":"Maatregel","text":"<p>Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder die actieve bewaking in zijn aanbieding omschrijven en neem het op in de beoordeling. oor zover van toepassing, laat deze omschrijving helder onderscheid maken in bewaking tijdens ontwikkeling (richting aan de maker), selectie (richting aan de koper), gebruik (richting aan de gebruiker/exploitant) en/of de output (richting aan het algoritme/AI-systeem). Dit kan aanvullend als specialis op bijvoorbeeld voorwaarden die in de ARBIT of ARVODI zijn opgenomen.</p> <p>Het is moeilijk om te bepalen wanneer en of de output van een algoritme of AI een inbreuk maakt op auteursrechten. Reden hiervoor is dat onduidelijk is of de uiteindelijk gegenereerde output naar auteursrechtelijke maatstaven (of in andere gevallen: naar maatstaven van andere intellectuele-eigendomsrechten, zoals databankenrechten, merkrechten of modelrechten) voldoende afstand houdt van (onder andere) de originele werken die ooit aan de training van de generatieve AI-tool ten grondslag hebben gelegen. Is dat niet het geval, dan kan bij veel vormen van gebruik van de output immers sprake zijn van een inbreuk op intellectuele eigendomsrechten.</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/","title":"Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdata","text":"<p>OntwerpMonitoring en beheerProceseigenaarBehoeftestellerInkoopadviseurAanbestedingsjuristContractbeheerderPublieke inkoop</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#maatregel","title":"Maatregel","text":"<p>Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder die actieve bewaking in zijn aanbieding omschrijven en neem het op in de beoordeling. Voor zover van toepassing, laat deze omschrijving helder onderscheid maken in bewaking tijdens ontwikkeling (richting aan de maker), selectie (richting aan de koper), gebruik (richting aan de gebruiker/exploitant) en/of de output (richting aan het algoritme/AI-systeem). Dit kan aanvullend als specialis op bijvoorbeeld voorwaarden die in de ARBIT of ARVODI zijn opgenomen.</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAuteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten."},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#bronnen","title":"Bronnen","text":"Bron ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) Algoritmekader"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/stel_archiefbescheiden_vast/","title":"Stel archiefbescheiden vast","text":"<p>OntwerpOntwikkelenPublieke inkoop</p>"},{"location":"maatregelen/stel_archiefbescheiden_vast/#maatregel","title":"Maatregel","text":"<p>Stel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden. Formeer een multi-discipinaire groep (bestaande uit bv. een inkoper, ontwikkelaar, data scientist en archief deskundige) om deze maatregel toe te passen.</p>"},{"location":"maatregelen/stel_archiefbescheiden_vast/#toelichting","title":"Toelichting","text":"<p>Hierbij kan worden gedacht aan de broncode, trainings- en testdata, (technische) documentatie en de output. Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet. </p>"},{"location":"maatregelen/stel_archiefbescheiden_vast/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden."},{"location":"maatregelen/stel_archiefbescheiden_vast/#bronnen","title":"Bronnen","text":"Bron Toetsingskader Algemene Rekenkamer 4.01"},{"location":"maatregelen/stel_archiefbescheiden_vast/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/stel_een_RACI-matrix_op/","title":"Stel een RACI-matrix op","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenImplementatieMonitoring en beheerProceseigenaarPrivacy officerData scientistData engineerInkoopadviseurContractbeheerderAanbiederPrivacy en gegevensbeschermingGovernance</p>"},{"location":"maatregelen/stel_een_RACI-matrix_op/#maatregel","title":"Maatregel","text":"<p>Stel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens.</p>"},{"location":"maatregelen/stel_een_RACI-matrix_op/#toelichting","title":"Toelichting","text":"<p>Het is van belang om de rollen en verantwoordelijkheden over en gedurende de gehele levenscyclus te beschrijven en eventueel onderdeel te maken van conceptovereenkomsten.  Tijdens de ontwikkelfase worden bijvoorbeeld andere (risicovolle) werkzaamheden uitgevoerd dan in de implementatie- of monitoring en beheerfase.  Doorgaans zijn ook andere actoren betrokken in verschillende fases en in de praktijk kunnen taken en verantwoordelijkheden opnieuw worden belegd. </p>"},{"location":"maatregelen/stel_een_RACI-matrix_op/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegVerantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten."},{"location":"maatregelen/stel_een_RACI-matrix_op/#bronnen","title":"Bronnen","text":"<p>| Algoritmekader |</p>"},{"location":"maatregelen/stel_een_RACI-matrix_op/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/","title":"Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst","text":"<p>OntwerpOntwikkelenPublieke inkoop</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#maatregel","title":"Maatregel","text":"<p>Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst </p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de contractvoorwaarden</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering."},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Contractvoorwaarden gemeente Amsterdam Europese Inkoopvoorwaarden Hoog Risico Europese Inkoopvoorwaarden Laag Risico"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/","title":"Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijke","text":"<p>OntwerpMonitoring en beheerBehoeftestellerInkoopadviseurAanbiederPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#maatregel","title":"Maatregel","text":"<p>Bespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#toelichting","title":"Toelichting","text":"<p>Bij publieke inkoop is het nodig duidelijke afspraken te hebben over wie dit document invult en welke informatie bij welke partij vandaan komt. De aanbieder zal een belangrijk deel van de technische documentatie moeten aanleveren, maar bij gebruik door de gebruiksverantwoordelijken zal deze informatie moeten worden aangevuld.</p> <p>Hierbij is het van belang dat de documentatie aansluit bij de verschillende gebruikers van het systeem, waarbij rekening wordt gehouden met verschillende toepassingen of versies.</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegTechnische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening."},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/","title":"De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbesteding","text":"<p>OntwerpMonitoring en beheerProceseigenaarAanbiederBehoeftestellerInkoopadviseurContractbeheerderPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/#maatregel","title":"Maatregel","text":"<p>Laat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald kan worden na implementatie als het systeem in productie c.q. in gebruik is.</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/#toelichting","title":"Toelichting","text":"<p>Sommige algoritmen of AI-systemen zijn zeer specialistisch, hierbij is het van belang dat afspraken worden gemaakt in hoeverre ondersteuning bij het gebruik onderdeel is van de inkoop. Hierbij is ook van belang dit onderdeel geactualiseerd wordt gedurende de contractperiode i.v.m. de technologische ontwikkelingen.</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegBevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's."},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_enondersteuning/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/","title":"Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemen","text":"<p>OntwerpMonitoring en beheerAanbiederProceseigenaarInkoopadviseurPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#maatregel","title":"Maatregel","text":"<p>Laat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#toelichting","title":"Toelichting","text":""},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegBevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's."},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/","title":"Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.","text":"<p>OntwerpOntwikkelenPublieke inkoopGovernance</p>"},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/#maatregel","title":"Maatregel","text":"<p>Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.</p>"},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/#toelichting","title":"Toelichting","text":"<p>Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing is en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen.  Dit is mede afhankelijk van de bijbehorende risicoclassificatie.  Hiervoor kan in de nabije toekomst de 'beslisboom' in het Algoritmekader voor worden gebruikt'.  Deze stap is van groot belang, omdat dit ook bepalend is welke contractuele verplichtingen moeten worden gecre\u00eberd tussen opdrachtgever en opdrachtnemer/aanbieder. </p>"},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegProportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten."},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_typen_algoritme_of_AI-systeem_en_risicoclassificatie/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/voer_een_data_beschikbaarheid_kwaliteit_en_toegankelijkheidsanalyse_uit/","title":"Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.","text":"<p>OntwerpOntwikkelenProceseigenaarBehoeftestellerInformatie analistData scientistInkoopadviseurContractbeheerderAanbestedingsjuristAanbiederOpdrachtnemerPublieke inkoopData</p>"},{"location":"maatregelen/voer_een_data_beschikbaarheid_kwaliteit_en_toegankelijkheidsanalyse_uit/#maatregel","title":"Maatregel","text":"<p>Voer voorafgaand aan een aanbesteding een data beschikbaarheids- en kwaliteitsanalayse uit. </p>"},{"location":"maatregelen/voer_een_data_beschikbaarheid_kwaliteit_en_toegankelijkheidsanalyse_uit/#toelichting","title":"Toelichting","text":"<p>Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is, gaat worden en of de data van voldoende kwaliteit is. Het is van belang om te onderzoeken of en hoe data vanuit de eigen organisatie of die van een aanbieder beschikbaar kan worden gesteld, kan worden opgeslagen en er goedkeuring kan worden gegeven voor het verwerken van de data.  De infrastructuur van de eigen organisatie en/of die van de aanbieder moeten van voldoende niveau zijn om de beoogde verwerkingen uit te kunnen voeren.  Een dergelijke analyse levert inzichten op welke problemen er eventueel op dit vlak kunnen ontstaan.</p>"},{"location":"maatregelen/voer_een_data_beschikbaarheid_kwaliteit_en_toegankelijkheidsanalyse_uit/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"VereisteUitlegData van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn."},{"location":"maatregelen/voer_een_data_beschikbaarheid_kwaliteit_en_toegankelijkheidsanalyse_uit/#bronnen","title":"Bronnen","text":"Bron Towards a Systematic Understanding on the Challenges of Procuring Artificial Intelligence in the Public Sector"},{"location":"overhetalgoritmekader/","title":"Over het Algoritmekader","text":"<p>Het is van belang dat algoritmes en AI op een verantwoorde manier worden ontwikkeld en gebruikt.  Dit betekent dat er aandacht moet zijn voor zaken als:</p> <ol> <li>rollen en verantwoordelijkheden (governance);</li> <li>risico\u2019s op bias/discriminatie vroegtijdig detecteren;</li> <li>de uitvoering van mensenrechtentoetsen (zoals IAMA\u2019s);</li> <li>adequate inkoopvoorwaarden afspreken voor algoritmes die de overheid inkoopt bij derden. </li> </ol> <p>Maar hoe doe je dat dan? Hier helpt het Algoritmekader je bij: een interactieve kennisbank waarin je kunt zoeken naar informatie op basis van een onderwerp, een fase uit de levenscyclus of jouw rol.  </p>"},{"location":"overhetalgoritmekader/#levenscyclus-van-een-algoritme-vereisten-maatregelen-en-rollen","title":"Levenscyclus van een algoritme, vereisten, maatregelen en rollen","text":"<p>Het Algoritmekader maakt inzichtelijk aan welke vereisten overheidsorganisaties moeten voldoen.  Daarbij wordt ook aangegeven hoe zij hier op een betekenisvolle wijze invulling aan kunnen geven (maatregelen). Het Algoritmekader is zo ingericht dat gebruikers vanuit verschillende invalshoeken informatie kunnen raadplegen die voor hen relevant is.  Zo kun je vanuit de levenscyclus van een algoritme onderzoeken in welke fase, aan welke vereisten en maatregelen je aandacht moet besteden.  Het is ook mogelijk om vanuit een specifieke rol, bijvoorbeeld een ethicus of data scientist, te raadplegen bij welke vereisten of maatregelen je logischerwijs betrokken moet zijn.  </p>"},{"location":"overhetalgoritmekader/#type-technologie-en-risicoclassificatie","title":"Type technologie en risicoclassificatie","text":"<p>Het Algoritmekader geeft gebruikers de mogelijkheid om informatie te 'filteren'. </p> <p>Dit kun je bijvoorbeeld doen op basis van type technologie en risico classificatie.  Zo kunnen gebruikers snel zien wat zij in een bepaalde situatie moeten doen.  In het geval van een hoog risico AI-systeem waarbij persoonsgegevens worden verwerkt moet je aan meer vereisten voldoen dan dan bij een eenvoudige rekenregel die geen impact heeft op individuen of de maatschappij.  Deze inzichten helpen overheidsorganisaties om effectief en gericht hun middelen in te zetten.  </p> <p>Opmerking</p> <p>Aan deze functionaliteit wordt nog gewerkt. Meer hierover zal volgen in een volgende versie. </p>"},{"location":"overhetalgoritmekader/#standaarden","title":"Standaarden","text":"<p>Een belangrijk uitgangspunt van het Algoritmekader is dat bestaande kennis zoveel mogelijk wordt gebundeld en aansluiting wordt gezocht bij relevante ontwikkelingen.  Het proces van standaardisering op nationaal, Europees en Internationaal niveau is daar een belangrijk voorbeeld van.  De standaarden gaan in grote mate duiden 'hoe' organisaties invulling kunnen geven aan specifieke vereisten.  De kracht achter standaarden is dat deze door gespecialiseerde organisaties zijn opgesteld en breed gedragen worden.  Het volgen van deze standaarden levert een 'vermoeden van conformiteit op' en is daarmee bijzonder waardevol om onderdeel uit te maken van het Algoritmekader.  </p>"},{"location":"overhetalgoritmekader/#best-practices-en-instrumenten","title":"Best practices en instrumenten","text":"<p>In het Algoritmekader wordt geprobeerd om zoveel mogelijk 'best practises' te koppelen aan vereisten en maatregelen die organisaties kunnen treffen.  Daarmee wordt de materie tastbaarder en praktischer.  Zo zijn rapporten te vinden van uitgevoerde bias analyses, gepubliceerde broncode van door overheidsorganisatie ontwikkeld algoritmes, specifieke adviezen en belangrijke uitspraken.  Er wordt ook een overzicht gegeven van bruikbare instrumenten die kunnen worden gehanteerd.   </p>"},{"location":"overhetalgoritmekader/#status-van-het-algoritmekader","title":"Status van het Algoritmekader","text":"<p>Overheidsorganisaties zijn niet verplicht om het Algoritmekader te gebruiken. Het kader gaat echter wel uit van bestaande vereisten op basis van wet- en regelgeving waar deze overheden aan gebonden zijn.  Het Algoritmekader geeft structuur aan wat organisaties moeten doen.  </p> <p>Overheden wordt aanbevolen het kader te volgen, maar mogen te allen tijde zelf bepalen hoe zij invulling geven aan de vereisten, wie daarbij betrokken zijn, onder wiens verantwoordelijkheid en wanneer.  Kortom, de vereisten zijn verplicht en de maatregelen (hoe kan men hieraan voldoen) zijn ter inspiratie om organisaties op weg te helpen.  </p>"},{"location":"overhetalgoritmekader/#doorontwikkeling","title":"Doorontwikkeling","text":"<p>7 juli 2023 is de eerste versie van het Implementatiekader naar de Tweede Kamer verstuurd, vergezeld door de Kamerbrief 'Verzamelbrief algoritmen reguleren'.  Dit kan worden beschouwd als de eerste versie van het Algoritmekader. Het implementatiekader verantwoorde inzet van algoritmen is in oktober 2023 hernoemd naar 'het Algoritmekader'. </p> <p>In oktober 2023 is gestart met de doorontwikkeling van het Algoritmekader, zowel op inhoud als op vorm. Dat betekent dat inhoudelijke toevoegingen worden gedaan (denk aan hetgeen voortkomt uit de AI-verordening) en er wordt onderzocht hoe informatie zo optimaal mogelijk aan gebruikers getoond kan worden.  Het doel is dat het Algoritmekader gebruikers op een praktische wijze helpt bij het uitvoeren van hun werkzaamheden.  Het interactief kunnen doorzoeken van de informatie is daar een voorbeeld van.  </p> <p>Eind 2024 wordt de tweede versie van het Algoritmekader opgeleverd.  Dan moeten de vereisten en de maatregelen zijn uitgewerkt voor zover dan bekend.  Hierna zal het Algoritmekader in 'beheer' worden genomen. Dat betekent dat doorlopend de laatste ontwikkelingen, in afstemming met de omgeving, worden toegevoegd zodat het Algoritmekader actueel en betrouwbaar blijft.  </p>"},{"location":"overhetalgoritmekader/#samenwerking-met-de-omgeving","title":"Samenwerking met de omgeving","text":"<p>Een belangrijk uitgangspunt van het Algoritmekader is dat het kader op een open en transparante manier wordt ontwikkeld.  Hierbij wordt gebruik gemaakt van verschillende communicatiekanalen, zoals een communityplatform Pleio, GitHub, periodieke bijeenkomsten en (waar passend) werkgroepen.  Informatie over algoritmes en AI worden uitgewerkt.  Zodra deze informatie op 'niveau' is, wordt dit in Github geplaatst en daarmee 'gepubliceerd'.  Dit noemen we releases. </p> <p>De motivatie om op deze \u2018open source\u2019 manier aan dit Algoritmekader te werken is enerzijds de omgeving van deze informatie te voorzien en anderzijds om de omgeving uit te nodigen om hier feedback op te geven.  Werken in Github is voor het team Algoritmekader nieuw en experimenteel.  Het biedt de mogelijkheid voor alle ge\u00efnteresseerden om hun kennis en zienswijze te delen.  Daarmee kan (nieuwe) kennis snel onderdeel worden gemaakt van het Algoritmekader.  Daardoor blijft het Algoritmekader zo actueel mogelijk en wordt de inhoud breed gedragen. Tegelijkertijd vraagt dit om een aangepaste werkwijze en is hier bepaalde expertise voor nodig.  Het begin is gemaakt en het team Algoritmekader is nog lerende om hier optimaal invulling aan te geven.  Voor nu betekent dit concreet dat het langer kan duren voordat wordt gereageerd op suggesties of toevoegingen.  Er wordt gewerkt aan het inrichten van goede processen om snel en kundig te reageren. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/","title":"Bijdragen aan het Algoritmekader","text":"<p>Allereerst, bedankt dat je de tijd hebt genomen om een bijdrage te leveren! \u2764\ufe0f</p> <p>We waarderen alle soorten bijdragen enorm. Zie die Inhoudsopgave voor verschillende manieren waarop je kan bijdragen aan het Algoritmekader. Zorg ervoor dat je de relevante hoofdstukken even leest voordat je een bijdrage levert. Het zal het voor het team van het Algoritmekader een stuk makkelijker maken en de ervaring voor alle betrokkenen soepeler laten verlopen. We kijken uit naar alle bijdragen! \ud83c\udf89</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#opmerking","title":"Opmerking","text":"<p>Werken in Github is voor het team Algoritmekader nieuw en experimenteel. Dit vraagt voor ons om een aangepaste werkwijze en hier is bepaalde expertise voor nodig.  Het begin is gemaakt en het team Algoritmekader is nog lerende om hier optimaal invulling aan te geven.  Hierdoor kan het iets langer duren voordat er wordt gereageerd op suggesties of toevoegingen.  We werken aan een duidelijk proces om hier goed mee om te gaan (deze guidelines zijn daar een voorbeeld van). Daarnaast werken we niet aan alle bouwblokken tegelijk. Deze worden \u00e9\u00e9n voor \u00e9\u00e9n opgepakt.  Aanbevelingen over onderwerpen die later op de planning staan kunnen daardoor ook iets langer duren om te verwerken, en worden mogelijk pas verwerkt wanneer dit bouwblok wordt uitgewerkt.  </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#inhoudsopgave","title":"Inhoudsopgave","text":"<ul> <li>Code of Conduct</li> <li>Ik heb een vraag</li> <li>Ik wil iets bijdragen</li> <li>Ik wil een fout of bug melden</li> <li>Hoe we werken op GitHub</li> </ul>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Dit project en iedereen die eraan deelneemt, valt onder de Code of Conduct. Door deel te nemen, wordt van je verwacht dat je je aan deze code houdt. Meld onacceptabel gedrag aan algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-heb-een-vraag","title":"Ik heb een vraag","text":""},{"location":"overhetalgoritmekader/CONTRIBUTING/#maak-een-issue-aan","title":"Maak een issue aan","text":"<p>Voordat je een Issues gaat aanmaken, kan je bekijken of jouw vraag al tussen de bestaande Issues staat. Wellicht staat er al een issue tussen die jou vraag kan beantwoorden. </p> <p>Als je jouw vraag nog steeds wilt stellen, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Schrijf je vraag of opmerking is en geef een heldere toelichting.</li> <li>Anderen kunnen nu opmerkingen toevoegen aan jouw issue.</li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>question</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#stel-een-vraag-via-mail","title":"Stel een vraag via mail","text":"<p>Je kan je vragen ook altijd stellen door een mail te sturen naar algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-iets-bijdragen","title":"Ik wil iets bijdragen","text":"<p>Er zijn verschillende manieren waarop je kan bijdragen. Zie hieronder de mogelijkheden. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ter-kennisgeving","title":"Ter kennisgeving","text":"<p>Wanneer je bijdraagt aan dit project, moet je ermee akkoord gaan dat je 100% van de inhoud hebt geschreven, dat je de benodigde rechten op de inhoud hebt en dat de inhoud die je bijdraagt mag worden geleverd onder de Code of Conduct.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#sluit-je-aan-bij-een-werkgroep","title":"Sluit je aan bij een werkgroep","text":"<p>Voor sommige bouwblokken wordt er gewerkt met werkgroepen, om de informatie verder uit te werken. Deelname aan een werkgroep kost tijd. Werkgroepen komen regelmatig bij elkaar, en tussendoor worden bepaalde zaken uitgewerkt door werkgroepleden. Wil je op \u00e9\u00e9n van de onderwerpen meewerken? Stuur dan een bericht naar algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#neem-deel-aan-een-sprint-review-klankbord-demo","title":"Neem deel aan een sprint review / klankbord / demo","text":"<p>Het team van het algoritmekader werkt in sprints van ongeveer 3 weken. Daarin werken we toe naar de volgende release van het Algoritmekader. Ongeveer eens in de 6 weken vindt er een nieuwe release plaats. Wanneer er een release is, wordt deze altijd toegelicht en gepresenteerd in een open online review / demo. Deze kan je vrijblijvend volgen. Zo blijf je op de hoogte en kun je een bijdrage leveren. Bekijk de agenda op Algoritmes Pleio voor de komende bijeenkomsten. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-een-fout-of-bug-melden","title":"Ik wil een fout of bug melden","text":"<p>Heb je een foutje gevonden in het Algoritmekader? Dan kan je deze melden door een Issue aan te maken. </p> <p>Voordat je een Issues gaat aanmaken, kan je bekijken of jouw gevonden fout al tussen de bestaande Issues staat. </p> <p>Als je de gevonden fout nog steeds wilt melden, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Beschrijf de fout duidelijk en geef een heldere toelichting. Voeg waar mogelijk een screenshot toe. </li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>bug</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-een-verbetering-voorstellen","title":"Ik wil een verbetering voorstellen","text":"<p>Heb je een suggestie of wil je een verbetering voorstellen? Dat kan gaan om een compleet nieuwe functionaliteit van de site of om kleine verbeteringen. Het volgen van onderstaande instructie helpt het team van het algoritmekader om je suggestie te begrijpen en gerelateerde suggesties te vinden.</p> <p>Je kan een suggestie doen door een Issue aan te maken of door een Pull Request te maken.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#voordat-je-een-suggestie-gaat-maken","title":"Voordat je een suggestie gaat maken","text":"<ul> <li>Voordat je een suggestie gaat maken, kan je bekijken of jouw suggestie al tussen de bestaande Issues staat. Wellicht bestaat er al een issue die jouw suggestie beschrijft, en zijn we er al mee bezig.</li> <li>Zoek uit of jouw idee past binnen het doel en de scope van het project. Wat zijn de voordelen van deze functionaliteit of toevoeging? Het is aan jou om het team van het Algoritmekader en de community te overtuigen dat dit een nuttige toevoeging is aan het Algoritmekader. Houd in gedachten dat we functioanliteiten willen die nuttig zijn voor de meerderheid van onze gebruikers en niet slechts voor een kleine groep.</li> </ul>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#een-issue-aanmaken","title":"Een issue aanmaken","text":"<p>Als je jouw suggestie nog steeds wilt doen, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Beschrijf duidelijk jouw suggestie en geef een heldere toelichting en onderbouwing waarom dit een goede toevoeging zal zijn aan het Algoritmekader</li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>enhancement</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol> <p>Afhankelijk van de complexiteit en het onderwerp van jouw suggestie kan het even duren voordat deze wordt opgepakt door het team van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#een-pull-request-maken","title":"Een pull-request maken","text":"<p>Kun je niet uit de voeten met de issues?  Bijvoorbeeld omdat je verschillende wijzigingsvoorstellen wilt doen? Je kan ook gebruik maken van een Fork en een Pull Request.</p> <p>Het team van Algoritmekader bekijkt daarna jouw aanpassingen en kan bij akkoord jouw aanpassingen mergen. Er zijn ook andere manieren om een pull request te doen. Meer daarover. </p> <p>Afhankelijk van de complexiteit en het onderwerp van jouw suggestie kan het even duren voordat deze wordt opgepakt door het team van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#preview-van-een-pull-request","title":"Preview van een pull-request","text":"<p>We maken gebruik van de tool pr-preview-action om automatisch previews te maken van een pull-request.  Dit maakt het mogelijk om de wijzigingen die zijn gedaan in een pull-request al te bekijken in de uiteindelijke omgeving.  Wanneer er een pull-request gedaan wordt via een fork, leidt dit helaas tot een error, zie Issue #79. Dit blokkeert de pull-request niet. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#hoe-we-werken-op-github","title":"Hoe we werken op Github","text":"<p>We werken met Markdown bestanden.  Dit is bestandsformaat voor platte tekstbestanden en wordt door veel verschillende tools ondersteund. Dit maakt het eenvoudig om versiebeheer op het Algoritmekader toe te passen. </p> <p>Daarnaast maken gebruik van mkdocs en material for mkdocs om de informatie op een interactieve wijze inzichtelijk te maken op de website van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#wil-je-een-nieuwe-pagina-aanmaken","title":"Wil je een nieuwe pagina aanmaken?","text":"<p>In het mkdocs.yml bestand staan de settings voor deze website.  In principe hoef je hier niets aan aan te passen, maar als je een nieuwe pagina wilt aanmaken kan het nodig zijn om hier een aanpassing in te doen. Onderdeel van deze settings is namelijk de navigatie voor de site (welke pagina's zijn zichtbaar, en welke pagina's vallen daaronder). Dit staat in de nav: sectie.  Indien je een nieuwe pagina wilt toevoegen, is het vaak nodig deze wijziging ook door te voeren in het mkdocs.yml bestand.</p>"},{"location":"overhetalgoritmekader/definities/","title":"Definities","text":"<p>Welke definities gebruikt het Algoritmekader? Je vindt een overzicht op deze pagina. Deze definities komen overeen met de definities van het het Algoritmeregister, zie daarvoor de Handreiking Algoritmeregister.</p>"},{"location":"overhetalgoritmekader/definities/#definitie-van-een-algoritme","title":"Definitie van een algoritme","text":"<p>Er zijn veel definities van een algoritme. Voor het algoritmekader hanteren we de definitie van de Algemene Rekenkamer:</p> <p>'Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden.\u2019</p> <p>Dit is een brede definitie die de maximale reikwijdte weergeeft van algoritmes waarvoor het Algoritmekader relevant is. Waar de definitie van de Algemene Rekenkamer schrijft \u201com een probleem op te lossen of een vraag te beantwoorden\u201d, verstaan we daar ook onder \u201com een taak of proces uit te voeren of tot een besluit te komen\u201d. In het uitvoeren van een taak of het komen tot een besluit kunnen \u00e9\u00e9n of meer algoritmes voorkomen. Daarnaast hebben we het bij het Algoritmekader over zowel Artifici\u00eble Intelligentie (AI) als algoritmes. De essentie is dat AI is opgebouwd uit algoritmes. Maar niet alle algoritmes zijn AI. </p> <p></p> <p>Gebruikte terminologie</p> <p>De termen hoog-risico, impactvol, AI en Algoritmes worden veel door elkaar gebruikt. Wij hanteren uitsluitend de volgende twee termen:</p> <ol> <li> <p>Hoog-risico AI (-systeem)  Hiermee bedoelen we altijd de definitie zoals deze in de AI-verordening wordt gehanteerd.</p> </li> <li> <p>Impactvolle algoritmes Dit betreft de minimale reikwijdte van het Algoritmekader. Het omvat de hoog-risico AI-systemen zoals gedefinieerd in de AI-verordening \u00e9n de algoritmes die we daarnaast als impactvol beschouwen. </p> </li> </ol>"},{"location":"overhetalgoritmekader/definities/#relatie-scope-algoritmekader-en-de-ai-verordening","title":"Relatie scope Algoritmekader en de AI-Verordening","text":"<p>Op dit moment wordt op EU-niveau de AI-verordening ontwikkeld, die naar verwachting van toepassing wordt op een deel van de algoritmes in gebruik bij de overheid. In de AI-verordening zijn AI-systemen onderverdeeld in verschillende categorie\u00ebn: verboden praktijken, hoog-risico AI-systemen, AI-systemen met manipulatierisico\u2019s en AI-systemen met geen/minimale risico\u2019s. Afhankelijk van de categorie waarin een AI-systeem valt, gelden zwaardere of minder zware eisen waar die systemen aan moeten voldoen.</p> <p>Het Algoritmekader is hoe dan ook relevant voor hoog-risico AI-systemen volgens de definitie van de AI-verordening. Een AI-systeem is hoog-risico als het voldoet aan de volgende eisen: 1. Het AI-systeem valt onder de definitie van AI-systemen in artikel 3 lid 1 van de verordening en moet o.a. autonome elementen bevatten, en</p> <ol> <li>Het AI-systeem wordt in een van de toepassingsgebieden van ANNEX III ingezet zoals biometrie, kritieke infrastructuur en rechtshandhaving. Bovenstaande betreft een versimpelde beschrijving van de AI-verordening. In bijlage 2 van de Handreiking Algoritmeregister is meer informatie te vinden over de AI-verordening. Aangezien de AI-verordening nog in onderhandeling is, bestaat de kans dat de classificatie van hoog-risico AI-systemen nog wordt aangepast. </li> </ol>"},{"location":"overhetalgoritmekader/definities/#definitie-van-impactvolle-algoritmes","title":"Definitie van impactvolle algoritmes","text":"<p>Om te bepalen of een algoritme in aanmerking komt voor publicatie in het Algoritmeregister, is een hulpmiddel 'Selectie' gemaakt. Het zijn dezelfde algoritmes die relevant zijn voor het Algoritmekader. Dit hulpmiddel wordt hieronder weergegeven in de figuur, en is ook leidend voor het Algoritmekader.</p> <p></p> <p>Voor meer toelichting over dit hulpmiddel verwijzen we naar de Handreiking Algoritmeregister.</p>"},{"location":"overhetalgoritmekader/definities/#begrippenlijst","title":"Begrippenlijst","text":"Begrip Definitie aanbieder Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling. aanbieders Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merknaam, al dan niet tegen betaling. aanbieder verder in de AI-waardeketen Een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\u00efntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal ge\u00efntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen aangemelde instantie Een conformiteitsbeoordelingsinstantie die overeenkomstig de AI-verordening en andere relevante harmonisatiewetgeving van de Unie is aangemeld aanmeldende autoriteit De nationale autoriteit die verantwoordelijk is voor het opzetten en uitvoeren van de noodzakelijke procedures voor de beoordeling, aanwijzing en kennisgeving van de conformiteitsbeoordelingsinstanties en de monitoring hiervan AI-bureau De taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie AI-geletterheid Vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico\u2019s van AI en de mogelijke schade die zij kan veroorzaken AI-model voor algemene doeleinden Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden ge\u00efntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht. AI-modellen voor algemene doeleinden Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden ge\u00efntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht. AI-systeem een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te werken en dat na het inzetten ervan aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud, aanbevelingen of beslissingen die van invloed kunnen zijn op fysieke of virtuele omgevingen; AI-systeem voor algemene doeleinden Een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen AI-testomgeving voor regelgeving Een door een bevoegde autoriteit opgezet gecontroleerd kader dat aanbieders of toekomstige aanbieders van AI-systemen de mogelijkheid biedt een innovatief AI-systeem te ontwikkelen, trainen, valideren en testen, zo nodig onder re\u00eble omstandigheden, volgens een testomgevingsplan, voor een beperkte periode en onder begeleiding van een toezichthouder. algoritme Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden auteursrecht Het auteursrecht is het uitsluitend recht van den maker van een werk van letterkunde, wetenschap of kunst, of van diens rechtverkrijgenden, om dit openbaar te maken en te verveelvoudigen, behoudens de beperkingen, bij de wet gesteld. beoogd doel Het gebruik waarvoor een AI-systeem door de aanbieder is bedoeld, met inbegrip van de specifieke context en voorwaarden van het gebruik, zoals gespecificeerd in de informatie die door de aanbieder in de gebruiksinstructies, reclame- of verkoopmaterialen en verklaringen, alsook in de technische documentatie is verstrekt bijzondere categorie\u00ebn persoonsgegevens De categorie\u00ebn persoonsgegevens als bedoeld in artikel 9, lid 1, van Verordening (EU) 2016/679, artikel 10 van Richtlijn (EU) 2016/680 en artikel 10, lid 1, van Verordening (EU) 2018/1725 biometrische gegevens Persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens biometrische identificatie De geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen biometrische verificatie De geautomatiseerde \u00e9\u00e9n-op-\u00e9\u00e9nverificatie, met inbegrip van de authenticatie, van de identiteit van natuurlijke personen door hun biometrische gegevens te vergelijken met eerder verstrekte biometrische gegevens capaciteiten met een grote impact Capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden. CE-markering Een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de voorschriften van hoofdstuk III, afdeling 2, van de AI-Verordening en andere toepasselijke harmonisatiewetgeving van de Unie, die in het aanbrengen ervan voorzien conformiteitsbeoordeling Het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2 van de AI-Verordening in verband met een AI-systeem met een hoog risico deepfake Door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor authentiek of waarheidsgetrouw zou worden aangezien direct onderscheid Indien een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat; directe discriminatie De ongelijke behandeling van een persoon of groep personen ten opzichte van andere personen in een vergelijkbare situatie, op grond van een beschermd persoonskenmerk (discriminatiegrond). discriminatiegrond Beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Bijvoorbeeld: ras, nationaliteit, religie, geslacht, seksuele gerichtheid, handicap of chronische ziekte. distributeur Een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt downstreamaanbieder Een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\u00efntegreerd, ongeacht of het model door hemzelf wordt verstrekt en verticaal ge\u00efntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen etnisch profileren Het gebruik door overheidsinstanties van selectiecriteria als ras, huidskleur, taal, religie, nationaliteit of nationale of etnische afkomst bij de uitoefening van toezichts-, handhavings- en opsporingsbevoegdheden, zonder dat daarvoor een objectieve en redelijke rechtvaardiging bestaat geharmoniseerde norm Een geharmoniseerde norm zoals gedefinieerd in artikel 2, lid 1,punt c), van Verordening (EU) nr. 1025/2012 gemeenschappelijke specificatie een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in de AI-verordening gebruiksinstructies de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over met name het beoogde doel en juiste gebruik van een AI-systeem gebruiksverantwoordelijke Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet- beroepsactiviteit. geharmoniseerde norm Een Europese norm die op verzoek van de Commissie is vastgesteld met het oog op de toepassing van harmonisatiewetgeving van de Unie ge\u00efnformeerde toestemming De vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder re\u00eble omstandigheden, na ge\u00efnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te nemen gemachtigde Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren; gemeenschappelijke specificatie Een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in deze verordening gevoelige operationele gegevens Operationele gegevens met betrekking tot activiteiten op het gebied van preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van strafprocedures in het gedrang zou kunnen brengen importeur Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of merknaam van een in een derde land gevestigde natuurlijke of rechtspersoon draagt in de handel brengen Het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor algemene doeleinden in gebruik stellen De directe levering van een AI-systeem door de aanbieder aan de gebruiksverantwoordelijke voor het eerste gebruik of voor eigen gebruik in de Unie voor het beoogde doel indirect onderscheid Indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat in vergelijking met andere personen bijzonder treft. indirecte discriminatie Wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaald beschermd persoonskenmerk (discriminatiegrond) in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat. inputdata Data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis waarvan het systeem een output genereert kritieke infrastructuur Kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU) 2022/2557 legaliteitsbeginsel Het legaliteitsbeginsel houdt in dat alle overheidsoptreden moet berusten op een overeenstemmen met - kenbare en voldoende specifieke - algemene regels. markttoezichtautoriteit De nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in Verordening (EU) 2019/1020 nationale bevoegde autoriteit Een aanmeldende autoriteit of een de markttoezichtautoriteit; wat betreft AI-systemen die door instellingen, organen en instanties van de EU in gebruik worden gesteld of worden gebruikt, worden verwijzingen naar nationale bevoegde autoriteiten of markttoezichtautoriteiten in deze verordening begrepen als verwijzingen naar de Europese Toezichthouder voor gegevensbescherming norm Een norm is een vrijwillige afspraak tussen partijen over een product, dienst of proces. Normen zijn geen wetten, maar \u2019best practices\u2019. Iedereen kan - op vrijwillige basis - hier zijn voordeel mee doen. In zakelijke overeenkomsten hebben normen een belangrijke functie. Ze bieden marktpartijen duidelijkheid over en vertrouwen in producten, diensten of organisaties en dagen de maatschappij uit te innoveren. NEN-normen worden ontwikkeld door inhoudsexperts en specialisten op het gebied van normontwikkeling. normalisatie Normalisatie is het proces om te komen tot een norm. Dit proces is open, transparant en gericht op consensus en vindt plaats in normcommissies die bestaan uit vertegenwoordigers van alle betrokken partijen. Dit gebeurt niet alleen op nationaal niveau, maar ook in Europees en mondiaal verband. objectieve rechtvaardiging Van een objectieve rechtvaardiging voor onderscheid is sprake wanneer onderscheid een legitiem doel nastreeft en er een redelijke relatie van evenredigheid bestaat tussen het gemaakte onderscheid en het nagestreefde doel. op de markt aanbieden Het in het kader van een handelsactiviteit, al dan niet tegen betaling, verstrekken van een AI-systeem of een AI-model voor algemene doeleinden met het oog op distributie of gebruik op de markt van de Unie operator Een aanbieder, productfabrikant, gebruiksverantwoordelijke, gemachtigde, importeur of distributeur prestaties van een AI-systeem Het vermogen van een AI-systeem om het beoogde doel te verwezenlijken plan voor testen onder re\u00eble omstandigheden Een document waarin de doelstellingen, methode, geografische reikwijdte, betrokken personen, duur, monitoring, organisatie en wijze van uitvoering van een test onder re\u00eble omstandigheden worden omschreven proceseigenaar De proceseigenaar is verantwoordelijk voor de kwaliteit van het proces en de vastlegging daarvan in een processchema proefpersoon In het kader van tests onder re\u00eble omstandigheden: een natuurlijk persoon die deelneemt aan een test onder re\u00eble omstandigheden publieke inkoop De verwerving van werken, leveringen of diensten door een overheid of publieke organisatie, van de markt of een andere externe instantie, terwijl zij tegelijkertijd publieke waarde cre\u00ebren en waarborgen vanuit het perspectief van de eigen organisatie. redelijkerwijs te voorzien misbruik Het gebruik van een AI-systeem op een wijze die niet in overeenstemming is met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te voorziene interactie met andere systemen, waaronder andere AI-systemen risico De combinatie van de kans op schade en de ernst van die schade; substanti\u00eble wijziging Een verandering van een AI-systeem nadat dit in de handel is gebracht of in gebruik is gesteld, die door de aanbieder niet is voorzien of gepland in de initi\u00eble conformiteitsbeoordeling en als gevolg waarvan de overeenstemming van het AI-systeem met de voorschriften van hoofdstuk III, afdeling 2, AI-Verordening wordt be\u00efnvloed, of die leidt tot een wijziging van het beoogde doel waarvoor het AI-systeem is beoordeeld systeem voor monitoring na het in de handel brengen Alle door aanbieders van AI-systemen verrichte activiteiten voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde AI-systemen, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig zijn systeem voor het herkennen van emoties Een AI-systeem dat is bedoeld voor het vaststellen of afleiden van de emoties of intenties van natuurlijke personen op basis van hun biometrische gegevens systeem voor biometrische categorisering Een AI-systeem dat is bedoeld voor het indelen van natuurlijke personen in specifieke categorie\u00ebn op basis van hun biometrische gegevens, tenzij dit een aanvulling vormt op een andere commerci\u00eble dienst en om objectieve technische redenen strikt noodzakelijk is systeem voor biometrische identificatie op afstand Een AI-systeem dat is bedoeld voor het identificeren van natuurlijke personen, zonder dat zij daar actief bij betrokken zijn en doorgaans van een afstand, door middel van vergelijking van de biometrische gegevens van een persoon met de biometrische gegevens die zijn opgenomen in een referentiedatabank systeem voor biometrische identificatie op afstand in real time Een systeem voor biometrische identificatie op afstand, waarbij het vastleggen van biometrische gegevens, de vergelijking en de identificatie zonder significante vertraging plaatsvinden, zowel wanneer de identificatie niet enkel onmiddellijk plaatsvindt, maar ook wanneer de identificatie met beperkte korte vertragingen plaatsvindt, om omzeiling te voorkomen systeem voor biometrische identificatie op afstand achteraf Een ander biometrisch systeem voor de identificatie op afstand dan een systeem voor biometrische identificatie op afstand in real time systeemrisico Een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid terugroepen van een AI-systeem Een maatregel gericht op het retourneren aan de aanbieder, het buiten gebruik stellen of het onbruikbaar maken van een AI-systeem dat aan gebruiksverantwoordelijken ter beschikking is gesteld testdata Data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld testomgevingsplan Tussen de deelnemende aanbieder en de bevoegde autoriteit overeengekomen document waarin de doelstellingen, de voorwaarden, het tijdschema, de methode en de vereisten voor de in de testomgeving uitgevoerde activiteiten worden beschreven testen onder re\u00eble omstandigheden Het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder re\u00eble omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens te verkrijgen, en te beoordelen en te verifi\u00ebren of het AI-systeem overeenstemt met de voorschriften van de AI-verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de zin van de AI-verordening, mits aan alle in artikel 57 of 60 vastgestelde voorwaarden is voldaan toestemming met kennis van zaken De vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder re\u00eble omstandigheden, na ge\u00efnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing deel te nemen trainingsdata Data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan aan te passen uit de handel nemen van een AI-systeem Een maatregel waarmee wordt beoogd te voorkomen dat een AI-systeem dat zich in de toeleveringsketen bevindt, op de markt wordt aangeboden validatiedata Data die worden gebruikt voor het verrichten van een evaluatie van het getrainde AI-systeem en voor het afstemmen van onder andere de niet-leerbare parameters en het leerproces ervan, om underfitting of overfitting te voorkomen validatiedataset Een afzonderlijke dataset of deel van de trainingsdataset, als vaste of variabele opdeling. veiligheidscomponent Een component van een product of systeem die een veiligheidsfunctie voor dat product of systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van personen of eigendom in gevaar brengt verwerker Een .. rechtspersoon, een overheidsinstantie, een dienst of een ander orgaan die/dat ten behoeve van de verwerkingsverantwoordelijke persoonsgegevens verwerkt. verwerkersverantwoordelijke Een rechtspersoon of overheidsinstantie die, alleen of samen met anderen, het doel van en de middelen voor de verwerking van persoonsgegevens vaststelt zwevendekommabewerking of \u201cfloating-point operation (FLOP) Elke wiskundige bewerking of toewijzing met zwevendekommagetallen, die een subset vormen van de re\u00eble getallen die gewoonlijk op computers worden gerepresenteerd door een geheel getal met een vaste precisie, geschaald door een gehele exponent van een vaste basis <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/","title":"Rollen","text":"<p>In dit deel van het Algoritmekader kan per rol informatie worden geraadpleegd over het verantwoord ontwikkelen en gebruiken van algoritmes en AI.  Om verantwoorde inzet van algoritmes en AI te bereiken is een samenspel nodig tussen verschillende expertises die op het juiste moment worden ingezet.  In de praktijk cre\u00ebren organisaties specifieke rollen of functies (hierna: rol) waarbij wordt verwacht dat medewerkers met deze rol de gevraagde expertise toepassen.  Zo zal een data scientist betrokken zijn bij het ontwikkelen en trainen van algoritme en AI en zal een privacy officer maatregelen defini\u00ebren voor het beschermen van persoonsgegevens. </p> <p>In het Algoritmekader wordt een poging gedaan om te duiden welke rol(len) bij de realisatie van vereisten en maatregelen betrokken (kunnen) zijn.  Deze laag van het Algoritmekader dient om meerdere redenen alleen ter inspiratie.  Dat komt bijvoorbeeld omdat organisaties andere rollen gebruiken, bepaalde expertise samenvoegen in \u00e9\u00e9n rol of omdat bepaalde expertise nog niet is verworven binnen een organisatie.  Het koppelen van vereisten en maatregelen aan rollen raakt ook het onderwerpen van taakstelling en verantwoordelijkheden.  Ook dit zal bij organisaties op verschillende manieren belegd zijn of worden. </p> <p>Ondanks voorgaande wordt in het Algoritmekader hier een aanzet toe gedaan.  Voor sommige maatregelen is het namelijk evident dat dit hoort bij een bepaalde rol.  Het kan medewerkers met vergelijkbare rollen ook een inzicht geven in wat er nodig is en van hen kan worden verwacht.  Het laat daarnaast zien dat het rand voorwaardelijk is dat er voldoende ruimte is om met een multidisciplinair team, en al dan niet met een aanbieder, te kunnen samenwerken om tot een verantwoorde inzet van algoritmes en AI te komen. </p> <p>Als een rol wordt opgenomen in het Algoritmekader, dan wordt geprobeerd om dit aan te laten sluiten bij wat doorgaans wordt gehanteerd binnen (omvangrijkere) organisaties.  Er wordt een beknopte omschrijving gegeven bij deze rol en geen functieprofiel.  Vooralsnog wordt de rol gekoppeld aan vereisten en maatregelen en niet de verantwoordelijke afdeling, directie etc. (bijvoorbeeld CIO of CDO).  Hier wordt wel al verwezen naar het nog te ontwikkelen gedeelte Governance van het Algoritmekader.  Aan dit bouwblok wordt onmiddels gewerkt. </p> <p>Opmerking</p> <p>Er is al een aantal rollen toegevoegd aan het algoritmekader. Dit wordt nog aangvuld, en de rollen worden nog gekoppeld aan vereisten en maatregelen. </p>"},{"location":"rollen/aanbestedingsjurist/","title":"Aanbestedingsjurist","text":""},{"location":"rollen/aanbestedingsjurist/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/aanbestedingsjurist/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/aanbieder/","title":"Aanbieder","text":""},{"location":"rollen/aanbieder/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/aanbieder/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/archiefdeskundige/","title":"Archiefdeskundige","text":""},{"location":"rollen/archiefdeskundige/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/archiefdeskundige/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/behoeftesteller/","title":"Behoeftesteller","text":""},{"location":"rollen/behoeftesteller/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/behoeftesteller/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/beleidsmedewerker/","title":"Beleidsmedewerker","text":""},{"location":"rollen/beleidsmedewerker/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/beleidsmedewerker/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegNeem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregister <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/communicatieadviseur/","title":"Communicatieadviseur","text":""},{"location":"rollen/communicatieadviseur/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/communicatieadviseur/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/contractbeheerder/","title":"Contractbeheerder","text":""},{"location":"rollen/contractbeheerder/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/contractbeheerder/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/data-engineer/","title":"Data engineer","text":""},{"location":"rollen/data-engineer/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/data-engineer/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.FAIR dataMaak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterStel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/data-scientist/","title":"Data scientist","text":""},{"location":"rollen/data-scientist/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/data-scientist/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensVoer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/domeinspecialist/","title":"Domeinspecialist","text":""},{"location":"rollen/domeinspecialist/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/domeinspecialist/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegFormuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/ethicus/","title":"Ethicus","text":""},{"location":"rollen/ethicus/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/ethicus/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanKwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/gebruiker/","title":"Gebruiker","text":""},{"location":"rollen/gebruiker/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/gebruiker/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanControle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/gemandateerd-verantwoordelijke/","title":"Gemandateerd verantwoordelijke(n)","text":""},{"location":"rollen/gemandateerd-verantwoordelijke/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/gemandateerd-verantwoordelijke/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/informatie-analist/","title":"Informatie analist","text":""},{"location":"rollen/informatie-analist/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/informatie-analist/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegVoer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/informatiebeheerder/","title":"Informatiebeheerder","text":""},{"location":"rollen/informatiebeheerder/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/informatiebeheerder/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/inkoopadviseur/","title":"Inkoopadviseur","text":""},{"location":"rollen/inkoopadviseur/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/inkoopadviseur/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/jurist/","title":"Jurist","text":""},{"location":"rollen/jurist/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/jurist/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanControleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/opdrachtgever/","title":"Opdrachtgever","text":""},{"location":"rollen/opdrachtgever/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/opdrachtgever/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegFormuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Kwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/opdrachtnemer/","title":"Opdrachtnemer","text":""},{"location":"rollen/opdrachtnemer/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/opdrachtnemer/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/privacy-officer/","title":"Privacy-officer","text":""},{"location":"rollen/privacy-officer/#vereisten","title":"Vereisten","text":"VereisteUitlegEen DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd."},{"location":"rollen/privacy-officer/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegPas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevens <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/proceseigenaar/","title":"Proceseigenaar","text":""},{"location":"rollen/proceseigenaar/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/proceseigenaar/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Archiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregisterNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.Voer voorafgaand aan een aanbesteding een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit.Het is van belang om voorafgaand aan een aanbesteding vast te stellen of de data die noodzakelijk is om een algoritme of AI-systeem te ontwikkelen beschikbaar is of gaat worden en van voldoende kwaliteit is. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/projectleider/","title":"Projectleider","text":""},{"location":"rollen/projectleider/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/projectleider/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegFormuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Kwetsbare groepen in kaart brengen en beschermenBepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of de er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/security-officer/","title":"Security officer","text":""},{"location":"rollen/security-officer/#vereisten","title":"Vereisten","text":"VereisteUitleg"},{"location":"rollen/security-officer/#maatregelen","title":"Maatregelen","text":"MaatregelUitlegBewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Stel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden. <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"vereisten/","title":"Vereisten","text":"<p>Een kernelement van het Algoritmekader is het beschrijven van de vereisten waar overheidsorganisaties aan moeten voldoen als zij algoritmes en AI (laten) ontwikkelen en gebruiken.  Er is tal van wet- en regelgeving van toepassing op overheidsorganisaties als zij hun wettelijke taken uitvoeren.  Dat geldt ook als algoritmes en AI worden ingezet ter ondersteuning van de bijbehorende werkprocessen.  Hier kan worden gedacht aan de Algemene Wet Bestuursrecht, de Grondwet, de AI-verordening (vanaf inwerkingtreding), Auteurswet, de AVG en meer sectorspecifieke wet- en regelgeving.  In het Algoritmekader wordt een overzicht gegeven van de vereisten die hieruit voortkomen en van toepassing zijn op algoritmes en AI. </p> <p>Opmerking</p> <p>Het algoritmekader is nog volop in ontwikkeling.  Dit betekent dat de lijst met vereisten die nu zijn opgenomen in het algoritmekader nog onvolledig is, en dat de vereisten later nog kunnen worden aangepast.  Meer vereisten volgen in een volgende versie van het Algoritmekader. </p>"},{"location":"vereisten/#welke-vereisten-zijn-wanneer-van-toepassing","title":"Welke vereisten zijn wanneer van toepassing?","text":"<p>In dit deel van het Algoritmekader kan worden genavigeerd door de verschillende vereisten.  Wat precies van toepassing is, is sterk afhankelijk van de specifieke toepassing.  Daarom worden de vereisten gekoppeld aan het type technologie (rekenregel, machine learning of generatieve AI) en aan de risico classificatie (niet-impactvol, impactvol en hoge risico).  Dit moet gebruikers helpen om te duiden welke vereisten in welke situaties moeten worden nageleefd. </p> Opmerking <p>Aan deze functionaliteit wordt nog gewerkt. Meer hierover zal volgen in een volgende versie. </p>"},{"location":"vereisten/#voorbeeld","title":"Voorbeeld","text":"<p>Ter illustratie, ongeacht het type technologie, zijn discriminerende algoritmes en AI verboden en het vereiste van non-discriminatie moet in alle gevallen worden toegepast.  De mate waarin dit speelt kan verschillen en het aantal te treffen maatregelen ook.  Organisaties zullen hier hoe dan ook aandacht aan moeten besteden.  Dit is anders als het gaat om bijvoorbeeld het vereiste om algoritmes en AI op te nemen in het Algoritmeregister.  Dit is van belang bij impactvolle algoritmische toepassingen en hoog-risico AI-systemen.  Voor de niet-impactvolle rekenregels is dit niet noodzakelijk en kan daardoor achterwege blijven. </p>"},{"location":"vereisten/#overzicht-van-vereisten","title":"Overzicht van vereisten","text":"<p>Onderstaand volgt een overzicht van vereisten per fase van de levenscyclus. </p> Probleemanalyse VereisteUitlegProportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Ontwerp VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Documentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Kwaliteitsbeheersysteem voor hoog-risico AIAanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezetVoordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Dataverkenning en datapreparatie VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Auteursrechten mogen niet worden geschondenBepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Verbod op schenden databankenrechtenHet is verboden om zonder goedkeuring van de producent een databanken op te vragen en/of te hergebruiken.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.PrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Verwerking van persoonsgegevens moet rechtmatig plaatsvindenDe verwerking van persoonsgegevens moet rechtmatig plaatsvinden. De verwerking (inclusief het verzamelen) moet worden gebaseerd op een van de wettelijke grondslagen die zijn genoemd in de AVG.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenEenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensBijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Ontwikkelen VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Recht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelImpactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beperkte bewaartermijn van persoonsgegevensPersoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensPrivacyrechtenBetrokkenen kunnen een beroep doen op hun privacyrechten.Juistheid en actualiteit van gegevensDe te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.Persoonsgegevens verzamelen voor specifieke doeleindenDe verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingAI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenRecht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Risicobeoordeling voor jongeren en kwetsbarenBij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verdere verwerking van persoonsgegevens in AI-testomgevingenRechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Verificatie en validatie VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldDocumentatie beoordeling niet-hoog-risico AIEen aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.Een DPIA is verplicht bij hoog risicoEen Data Protection Impact Assessment (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen. Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen. Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaAI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria is te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Implementatie VereisteUitlegAanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemAanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opAanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitAanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteldCorrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdGebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevensGebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Maatregelen van gebruiksverantwoordelijken voor gebruikGebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.Melden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Privacy door ontwerpPas privacy en gegevensbescherming toe door goed ontwerp en door standaardinstellingenEenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoAanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezetVoordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Monitoring en beheer VereisteUitlegRecht op uitleg AI-besluitenElke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregisterHet publiceren van impactvolle algoritmes en AI draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.De archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Beoordeling van grondrechtenVoordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Bevorder AI-geletterdheid van personeel en gebruikersAanbieders en exploitanten van AI-systemen moeten ervoor zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Corrigerende maatregelen voor non-conforme AIAanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.Beschermen van fundamentele rechten en vrijhedenFundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemGebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningGebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemGebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI VerordeningMelden van ernstige incidentenAanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.Monitoring na het in handel brengenAanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.Een besluit berust op een deugdelijke motiveringEen besluit dat tot stand is gekomen door of met behulp van een algoritme of AI-systeem, dient te berusten op een deugdelijke motivering.AI-systemen en algoritmes mogen niet discriminerenOverheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.Klachtrecht aanbieders verder in AI-waardeketenAanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.Recht op niet geautomatiseerde besluitvormingMensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.Eenieder heeft recht op toegang tot publieke informatieEen bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.Veilig melden van inbreuk op AI verordeningInbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.Technische documentatie voor hoog-risico AIDe technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV. 1. Een algemene beschrijving van het AI-syseem. 2. Een gedetailleerde beschrijving van de elementen van het AI systeem en het proces voor de ontwikkeling ervan. 3. Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem. 4. Een beschrijving van de geschiktheid van de prestatiestatistieken. 5. Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening. 6. Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht. 7. Een lijst van normen die worden toegepast. 8. Een exemplaar van de EU-conformiteitsverklaring. 9. Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenAanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882Toezichtmogelijkheden voor gebruikersAI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.Transparantie in ontwerp voor hoog-risico AIAI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.Transparantie bij verwerking persoonsgegevensDe verwerking van persoonsgegevens moet transparant zijn.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoAanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperkenVerstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming. Uitfaseren VereisteUitlegVerplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordeningAanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingAanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het modelDe archiefwet is ook van toepassing op algoritmes en AI-systemenVolgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over algoritmes en AI moet daarom bewaard en vernietigd worden.Automatische logregistratie voor hoog-risico AIAI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d).Proportionaliteit en subsidiariteitProportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI-systeem en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken. Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan redelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritme of AI-systeem moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.Verantwoordelijkheden worden toegewezen en beschrevenBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.Beveiliging informatie en informatiesystemenInformatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.Beveiliging van de verwerkingVoor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieDe aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.Bewaartermijn voor gegenereerde logsAanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.Verantwoordingsplicht voor de rechtmatigheid van de verwerkingBij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijken kunnen aantonen dat de verwerking rechtmatig is.Verboden toepassingen bij evaluatie of classificatie van personen of groepen personenHet in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft; i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld; ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.Verplicht risicobeheersysteem voor hoog-risico AIVoor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenAanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.Verstrekking van informatie op verzoekOp een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.Relevante feiten en belangen zijn bekendDit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming."},{"location":"vereisten/CE_markering_hoog_risico/","title":"Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem","text":"<p>OntwikkelenVerificatie en validatieImplementatieGovernance</p>"},{"location":"vereisten/CE_markering_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.</p>"},{"location":"vereisten/CE_markering_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Op AI-systemen met een hoog risico moet de CE-markering worden aangebracht om aan te geven dat zij in overeenstemming zijn met de AI-verordening, zodat het vrije verkeer ervan op de interne markt mogelijk is. Op AI-systemen met een hoog risico die in een product zijn ge\u00efntegreerd moet een fysieke CE-markering worden aangebracht, die kan worden aangevuld met een digitale CE-markering. Voor AI-systemen met een hoog risico die alleen digitaal worden verstrekt, moet een digitale CE-markering worden gebruikt. De lidstaten mogen het in de handel brengen en het in gebruik stellen van AI-systemen met een hoog risico die aan de in de AI-verordening vastgelegde eisen voldoen en waarop de CE-markering is aangebracht, niet op ongerechtvaardigde wijze belemmeren.</p>"},{"location":"vereisten/CE_markering_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(h) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening Artikel 48 CE-markering - AI verordening"},{"location":"vereisten/CE_markering_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/CE_markering_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/CE_markering_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/","title":"Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op","text":"<p>Verificatie en validatieImplementatieGovernance</p>"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.</p>"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Een EU-conformiteitsverklaring is een verplicht document dat een fabrikant of gemachtigde vertegenwoordiger moet ondertekenen, waarmee wordt verklaard dat het product aan de EU-eisen voldoet. De aanbieder stelt voor elk AI-systeem met een hoog risico een schriftelijke machineleesbare, fysieke of elektronisch ondertekende EU-conformiteitsverklaring op en houdt deze verklaring tot tien jaar na het in de handel brengen of het in gebruik stellen van het AI-systeem met een hoog risico ter beschikking van de nationale bevoegde autoriteiten. De conformiteitsverklaring bevat de informatie zoals genoemd in bijlage V AI-verordening. Voorbeelden hiervan zijn de naam en type van het AI-systeem, naam en adres van de aanbieder, dat de EU-conformiteitsverklaring wordt versterkt onder verantwoordelijkheid van de aanbieder en de vermelding van eventuele toegepaste relevante geharmoniseerde normen of van andere gemeenschappelijke specificaties waarop de conformiteitsverklaring betrekking heeft.</p>"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(g) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening Artikel 47(1) EU-conformiteitsverklaring - AI verordening Bijlage V AI Verordening"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/EU_conformiteitsverklaring_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/","title":"Recht op uitleg AI-besluiten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenMonitoring en beheerGovernanceFundamentele rechten</p>"},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#vereiste","title":"Vereiste","text":"<p>Elke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.</p>"},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#toelichting","title":"Toelichting","text":"<p>Getroffen personen moeten het recht hebben om uitleg te krijgen indien het besluit van een gebruiksverantwoordelijke voornamelijk is gebaseerd op de output van bepaalde AI-systemen met een hoog risico die binnen het toepassingsgebied van de AI-verordening vallen en indien dat besluit rechtsgevolgen of gelijkaardige aanzienlijke gevolgen heeft voor de gezondheid, veiligheid of grondrechten van die personen. Die uitleg moet duidelijk en zinvol zijn en moet de grondslag zijn waarop de getroffen personen zich kunnen baseren om hun rechten uit te oefenen. Het recht om uitleg te krijgen mag niet van toepassing zijn op het gebruik van AI-systemen waarvoor uitzonderingen of beperkingen voortvloeien uit het Unierecht of het nationale recht en moet alleen van toepassing zijn voor zover het Unierecht niet reeds in dit recht voorziet. Dit vereiste geldt bijvoorbeeld niet als het gaat om AI-systemen die bedoeld zijn om te worden gebruikt als veiligheidscomponent bij het beheer of de exploitatie van kritieke digitale infrastructuur, wegverkeer of bij de levering van water, gas, verwerking en electriciteit (punt 2 bij Bijlage III van AI-verordening).</p>"},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#bronnen","title":"Bronnen","text":"Bron Artikel 86(1) Recht op toelichting bij individuele besluitvorming- AI verordening Artikel 26(11) AI Verordening Bijlage III AI Verordening"},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#risico","title":"Risico","text":"<p>Als gebruiksverantwoordelijke geen duidelijke, inhoudelijke toelichting geeft over de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen bij het genomen besluit, is het voor getroffen personen niet mogelijk zich te verdedigen tegen de rechtsgevolgen die hieruit voortkomen of de nadelige gevolgen voor gezondheid, veiligheid of diens grondrechten.</p>"},{"location":"vereisten/Recht_of_uitleg_AI-besluiten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/","title":"Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernance</p>"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden moeten de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI AI verordening vermelde elementen moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt.</p>"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden zijn verplicht om gedetailleerde technische documentatie bij te houden, inclusief informatie over hoe het model is getraind, getest en ge\u00ebvalueerd. Deze documentatie moet voldoen aan de minimale vereisten zoals uiteengezet in bijlage XI van de AI-verordening. Hierbij kan worden gedacht aan taken die het model uitvoert en het type en de aard van AI-systemen waarin het kan worden ge\u00efntegreerd, acceptabel gebruiks beleid, architectuur, het aantal paramaters, licentie, specificaties van het ontwerp van het model, het trainingsproces, informatie over de gegevens die zijn verwerkt en een gedetailleerde beschrijving van de evaluatiestrategie\u00ebn. Zie bijlage XI voor het gehele overzicht.</p> <p>Op verzoek moeten deze documenten beschikbaar zijn voor zowel het AI-bureau als de nationale bevoegde autoriteiten, wat essentieel is om te zorgen voor transparantie en naleving van de voorschriften.</p>"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#bronnen","title":"Bronnen","text":"Bron Artikel 53 Verplichtingen voor aanbieders van AI-systemen voor algemene doeleinden- AI verordening Bijlage XI AI Verordening"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#risico","title":"Risico","text":"<p>Het niet voldoen aan deze verplichtingen kan leiden tot juridische en ethische complicaties, inclusief schendingen van auteursrechten en gebrek aan transparantie in het gebruik van AI-modellen.</p>"},{"location":"vereisten/Verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/","title":"Aanbieders van AI-systemen met een hoog risico kunnen aantonen dat het AI-systeem in overeenstemming is met de vereisten uit de AI-verordening","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernance</p>"},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten op verzoek van een met reden omkleed verzoek van een nationale bevoegde autoriteit aan kunnen tonen dat het AI-systeem in overeenstemming is met de vereisten van afdeling 2 AI-Verordening.</p>"},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Op verzoek van een nationale bevoegde autoriteit moeten aanbieders van AI-systemen met een hoog risico aantonen dat het betreffende systeem voldoet aan de eisen.</p>"},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(k) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening"},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aantoonbaarheid_vereisten_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/","title":"Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het model</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen met systeemrisico moeten zorgen voor passende cyberbeveiligingsmaatregelen. Dit omvat het beschermen van zowel het AI-model als de fysieke infrastructuur tegen potenti\u00eble cyberdreigingen. Het doel is om de integriteit en veiligheid van het model en de infrastructuur te waarborgen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#bronnen","title":"Bronnen","text":"Bron Artikel 55(1d) Verplichtingen voor aanbieders van AI-systemen voor algemene doeleinden met een systeemrisico- AI verordening"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_cyberbeveiliging/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/","title":"Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij","text":"<p>Verificatie en validatieImplementatieMonitoring en beheerGovernance</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten ernstige incidenten documenteren en rapporteren. Deze informatie moet onmiddellijk worden gemeld aan het AI-bureau en eventueel aan nationale autoriteiten. Dit proces is cruciaal voor het waarborgen van de veiligheid en het nemen van passende corrigerende maatregelen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#bronnen","title":"Bronnen","text":"Bron Artikel 55(1c) Verplichtingen voor aanbieders van AI-systemen voor algemene doeleinden met een systeemrisico- AI verordening"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"vereisten/ai_modellen_algemene_doeleinden_syteemrisico_informatie_ernstige_incidenten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/algoritmeregister/","title":"Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregister","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerTransparantie</p>"},{"location":"vereisten/algoritmeregister/#vereiste","title":"Vereiste","text":"<p>Bestuursorganen publiceren algoritmes met impact en hoog-risico AI-systemen in het Nederlandse Algoritmeregister.</p>"},{"location":"vereisten/algoritmeregister/#toelichting","title":"Toelichting","text":"<p>Het publiceren van impactvolle algoritmes en AI-systemen draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.</p>"},{"location":"vereisten/algoritmeregister/#bronnen","title":"Bronnen","text":"Bron Handreiking Algoritmeregister Geactualiseerde Werkagenda Waardengedreven Digitaliseren 2024 Kamerbrieven"},{"location":"vereisten/algoritmeregister/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/algoritmeregister/#risico","title":"Risico","text":"<p>Door het niet publiceren van impactvolle of hoog risico AI -systemen in het Algoritmeregister, is het voor betrokkenen of belanghebbenden minder goed mogelijk om de overheid kritisch te volgen, te bevragen en te controleren op de inzet van deze technologie\u00ebn die hen kunnen raken.  Bij het onjuist of onvolledig publiceren in het Algortimeregister ontstaat er een risico dat betrokkenen en belanghebbenden onjuiste inschattingen maken over het gebruik van het algoritme of het AI-systeem en daardoor in hun rechten worden beperkt.</p>"},{"location":"vereisten/algoritmeregister/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Neem technische documentatie op in het algoritmeregisterNeem geschikte informatie uit technische documentatie op in het algoritmeregister MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen."},{"location":"vereisten/archiefwet/","title":"De archiefwet is ook van toepassing op algoritmes en AI-systemen","text":"<p>UitfaserenImplementatieMonitoring en beheerTechnische robuustheid en veiligheidGovernanceDataPrivacy en gegevensbescherming</p>"},{"location":"vereisten/archiefwet/#vereiste","title":"Vereiste","text":"<p>Overheidsorganen zijn verplicht de onder hen berustende archiefbescheiden in goede, geordende en toegankelijke staat te brengen en te bewaren, alsmede zorg te dragen voor de vernietiging van de daarvoor in aanmerking komende archiefbescheiden.</p>"},{"location":"vereisten/archiefwet/#toelichting","title":"Toelichting","text":"<p>Volgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over en van algoritmes en AI moet daarom bewaard en vernietigd worden.</p>"},{"location":"vereisten/archiefwet/#bronnen","title":"Bronnen","text":"Bron Artikel 3 Archiefwet 1995 Artikel 15 lid 2 Archiefwet 1995 Archiefbesluit 1995 Archiefregeling"},{"location":"vereisten/archiefwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/archiefwet/#risico","title":"Risico","text":"<p>Zonder goede toepassing van de Archiefwet is het voor betrokkene(n) of derden niet mogelijk om achteraf te reconstrueren en te controleren hoe besluiten, waar algoritmes en AI aan hebben bijgedragen, tot stand zijn gekomen. Het nalaten om archiefbescheiden na verloop van tijd te verwijderen brengt risico's met zich mee op het gebied van privacy en informatiebeveiliging.</p>"},{"location":"vereisten/archiefwet/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegArchiveren beperkingen openbaarheidStel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld.Vaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden zijn duurzaam toegankelijkStel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Stel archiefbescheiden vastStel vast welke documenten, data of informatie van het algoritme of het AI-systeem gelden als archiefbescheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/auteursrechten/","title":"Auteursrechten mogen niet worden geschonden","text":"<p>Dataverkenning en datapreparatieOntwerpDataGovernance</p>"},{"location":"vereisten/auteursrechten/#vereiste","title":"Vereiste","text":"<p>Auteursrechten mogen niet geschonden worden bij het ontwikkelen en gebruiken van algoritmes en AI.</p>"},{"location":"vereisten/auteursrechten/#toelichting","title":"Toelichting","text":"<p>Bepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.</p>"},{"location":"vereisten/auteursrechten/#bronnen","title":"Bronnen","text":"Bron Artikel 1 Auteurswet Artikel 4-9 Auteurswet Artikel 10 Auteurswet Artikel 13 Auteurswet Artikel 15n jo. 15o Auteurswet Artikel 3 en 4 van de DSM-richtlijn (EU 2019/790)"},{"location":"vereisten/auteursrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/auteursrechten/#risico","title":"Risico","text":"<p>Het niet voldoen aan het auteursrecht in AI-systemen en algoritmes kan leiden tot onrechtmatig gebruik van auteursrechtelijk beschermde inhoud, wat kan resulteren in mogelijke juridische geschillen, boetes en schadevergoedingen voor inbreuk op het auteursrecht. Bovendien kan het niet naleven van het auteursrecht het vertrouwen van gebruikers en belanghebbenden ondermijnen, wat kan leiden tot reputatieschade en gebrek aan vertrouwen.</p>"},{"location":"vereisten/auteursrechten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Controleren eigen data op schending auteursrechtenControleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingMaak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Contractuele afspraken over data en artefactenMaak (contractuele) afspraken met aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenVerken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling.Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktMaak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/automatische_logregistratie/","title":"Automatische logregistratie voor hoog-risico AI","text":"<p>OntwerpOntwikkelenVerificatie en validatieMonitoring en beheerUitfaserenGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/automatische_logregistratie/#vereiste","title":"Vereiste","text":"<p>Algoritmes en AI-systemen zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d). </p>"},{"location":"vereisten/automatische_logregistratie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren. Dit wordt vaak aangeduid als \"logs\". Deze logs bieden een traceerbaarheidsmechanisme waarmee gebruiksverantwoordelijken en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken. Het doel van deze registratie is om de transparantie en verantwoordingsplicht van AI-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetert.</p> <p>Voor AI-systemen met een hoog-risico voorziet de loggingcapaciteit ten minste in: a) de registratie van de duur van elk gebruik van het systeem; b) de referentiedatabank aan de hand waarvan de inputdata zijn gecontroleerd door het systeem; c) de inputdata ten aanzien waarvan de zoekopdracht een match heeft opgeleverd; d) de identificatie van natuurlijke personen die betrokken zijn bij de verificatie van de resultaten.</p> <p>Voor AI-systemen die door bestuursorganen worden gebruikt of AI-systmen die persoonsgegevens verwerken leveren de BIO en AVG vergelijkbare verplichingen op die ook van toepassing zijn op AI-systmen die niet gezien worden als een AI-systeem met hoog risico. Daarbij komen nog verplichtingen om de logs doorlopend of periodiek te monitoren op incidenten.</p>"},{"location":"vereisten/automatische_logregistratie/#bronnen","title":"Bronnen","text":"Bron Artikel 12 Registratie- AI verordening Baseline Informatiebeveiliging Overheid hoofdstuk 12.4 Artikel 5 en 32 AVG"},{"location":"vereisten/automatische_logregistratie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/automatische_logregistratie/#risico","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert en betrokkenen wiens persoonsgegevens worden verwerkt of geraakt worden door beslissingen van het AI-systeem in hun rechten kunnen worden beperkt.</p>"},{"location":"vereisten/automatische_logregistratie/#wanneer-van-toepassing_1","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/automatische_logregistratie/#risico_1","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert.</p>"},{"location":"vereisten/automatische_logregistratie/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/","title":"Proportionaliteit en subsidiariteit","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernancePrivacy en gegevensbescherming</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#vereiste","title":"Vereiste","text":"<p>Gegevensverwerking moet in verhouding staan tot het beoogde doel en persoonsgegevens mogen alleen verwerkt worden als er geen minder ingrijpende manier is om het doel te bereiken. Voor zover het gaat om de verwerking van persoonsgegevens moet dit vereiste aantoonbaar zijn. </p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#toelichting","title":"Toelichting","text":"<p>Proportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken.  Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritmes en AI moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#bronnen","title":"Bronnen","text":"Bron Overweging 170 Algemene Verordening Gegevensbescherming Artikel 5(4) Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992 Artikel 52 Handvest van de Grondrechten van de Europese Unie Protocol betreffende de toepassing van de beginselen van subsidiariteit en evenredigheid Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992 Artikel 1.10, 1.13 en 1.16 Aanbestedingswet 2012 Artikel 5(1)(c) Algemene Verordening Gegevensbescherming"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#risico","title":"Risico","text":"<p>Zonder toetsing aan het proportinaliteits- en subsidiariteitsbeginsel ontstaat het risico dat er een onnodig zware en daardoor onrechtmatige inbreuk wordt gemaakt op de privacyrechten van betrokkenen.</p>"},{"location":"vereisten/beginsel_van_proportionaliteit_en_subsidiariteit/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie."},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/","title":"Beoordeling van grondrechten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieMonitoring en beheerFundamentele rechten</p>"},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#vereiste","title":"Vereiste","text":"<p>Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.</p>"},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#toelichting","title":"Toelichting","text":"<p>Voordat een AI-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde AI-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben. Deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen. Het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van AI-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiek.</p>"},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#bronnen","title":"Bronnen","text":"Bron Artikel 27(1) Beoordeling van de gevolgen voor de grondrechten van AI-systemen met een hoog risico- AI verordening Artikel 6 lid 2 AI-verordening Punt 2 en punt 5 bij Bijlage III AI-verordening"},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#risico","title":"Risico","text":"<p>Het niet uitvoeren van deze beoordeling kan leiden tot schendingen van de grondrechten, juridische complicaties en verlies van vertrouwen van het publiek in het gebruik van AI-systemen door overheids- en openbare dienstverlenende entiteiten.</p>"},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/beoordelen_gevolgen_voor_grondrechten/#instrumenten","title":"Instrumenten","text":"InstrumentUitlegImpact Assessment Mensenrechten en AlgoritmesHet Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen."},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/","title":"Beperkte bewaartermijn van persoonsgegevens","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens dienen toereikend en ter zake dienend te zijn en beperkt te blijven tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt. Dit vereist dat ervoor wordt gezorgd dat de opslagperiode van de persoonsgegevens tot een strikt minimum wordt beperkt. Het beginsel van opslagbeperking betekent dat persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan voor de realisering van de doeleinden waarvoor de persoonsgegevens worden verwerkt.</p> <p>In de context van algoritmes en AI is het belangrijk dat, wanneer persoonsgegevens worden verwerkt, er onderzocht wordt op welke manieren identificatie van betrokkenen tegen kan worden gegaan. Hierbij kan worden gedacht aan maatregelen als pseudonomisering en anonimisering.</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder de AVG"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig lang bewaren van persoonsgegevens levert een onrechtmatige situatie op. De privacyrechten van betrokken worden hierdoor aangetast. Er ontstaan aanvullende risico's bij bijvoorbeeld een datalek.</p>"},{"location":"vereisten/beperkte_bewaartermijn_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/","title":"Verantwoordelijkheden worden toegewezen en beschreven","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenMonitoring en beheerUitfaserenGovernancePrivacy en gegevensbescherming</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verantwoordelijkheden bij de verwerking van persoonsgegevens voor algoritmes en AI-systemen moeten zijn beschreven en zijn toegekend.</p> <p>De verwerkingsverantwoordelijke is verantwoordelijk voor de naleving van de beginselen inzake de verwerking van persoonsgegevens en kan deze aantonen (\"verantwoordingsplicht\").</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Bij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 24, 26, 27, 28 en 29, 5 lid 2 AVG"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>Door rollen en verantwoordelijkheden rondom de verwerking van persoonsgegevens niet te duiden en te beleggen, ontstaat het risico dat persoonsgegevens onrechtmatig on onveilig worden verwerkt.</p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#normen","title":"Normen","text":"<p>In afwachting van het standaardisatieproces. </p>"},{"location":"vereisten/beschrijven_en_toewijzen_van_verantwoordelijkheden_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Stel een RACI-matrix opStel een RACI-matrix op waarbij de rollen en verantwoordelijkheden worden beschreven en toebedeeld bij het verwerken van persoonsgegevensNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/","title":"Beveiliging informatie en informatiesystemen","text":"<p>OntwerpImplementatieMonitoring en beheerDataverkenning en datapreparatieVerificatie en validatieUitfaserenTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#vereiste","title":"Vereiste","text":"<p>Informatie en informatiesystemen moeten op de juiste manier worden beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#toelichting","title":"Toelichting","text":"<p>Informatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid (BIO) dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#bronnen","title":"Bronnen","text":"Bron Baseline Informatiebeveiliging Overheid Besluit voorschrift informatiebeveiliging rijksdienst 2007"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, verlies, wijziging of niet-toegestane verwerking van gegevens als de informatie en informatiesystemen onvoldoende zijn beveiligd.</p>"},{"location":"vereisten/beveiliging_informatie_en_informatiesystemen/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/beveiliging_van_verwerking/","title":"Beveiliging van de verwerking","text":"<p>Dataverkenning en datapreparatieOntwikkelenVerificatie en validatieMonitoring en beheerUitfaserenPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/beveiliging_van_verwerking/#vereiste","title":"Vereiste","text":"<p>Rekening houdend met de stand van de techniek, de uitvoeringskosten, alsook met de aard, de omvang, de context en de verwerkingsdoeleinden en de qua waarschijnlijkheid en ernst uiteenlopende risico's voor de rechten en vrijheden  van personen, treffen de verwerkingsverantwoordelijke en de verwerker passende technische en organisatorische maatregelen om een op het risico afgestemd beveiligingsniveau te waarborgen.</p>"},{"location":"vereisten/beveiliging_van_verwerking/#toelichting","title":"Toelichting","text":"<p>Voor de ontwikkeling en gebruik van algoritmes en AI is dat data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.</p>"},{"location":"vereisten/beveiliging_van_verwerking/#bronnen","title":"Bronnen","text":"Bron Artikel 32 Algemene Verordening Gegevensbescherming"},{"location":"vereisten/beveiliging_van_verwerking/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/beveiliging_van_verwerking/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals potenti\u00eble cyberaanvallen en datalekken. Dit kan leiden bijvoorbeeld tot verlies of diefstal van gevoelige gegevens, verstoring van organisatieprocessen,ongeautoriseerde toegang, vernietiging en onrechtmatige verwerking.</p>"},{"location":"vereisten/beveiliging_van_verwerking/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegStel een autorisatiematrix opUitsluitend bevoegde personen mogen de data verwerken en mogen werken aan de ontwikkeling van de algoritmes en AI-systemen. Maak hierover afspraken met de aanbieder.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Pas maatregelen toe om (persoons)gegevens te beschermenPas maatregelen toe als dataminimalisatie, pseudonimisering, anonimisering of aggregeren van persoonsgegevens bij het verwerken van de (trainings)data.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/","title":"Bevorder AI-geletterdheid van personeel en gebruikers","text":"<p>ProbleemanalyseOntwerpImplementatieMonitoring en beheerMenselijke controleGovernance</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#vereiste","title":"Vereiste","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken, en houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#toelichting","title":"Toelichting","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen.  Daarnaast moet er worden ingezet op het delen van ervaringen, passend onderwijs en opleiding van inidividuen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#bronnen","title":"Bronnen","text":"Bron Artikel 4 Verordening Artifici\u00eble Intelligentie"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#risico","title":"Risico","text":"<p>Onvoldoende AI-geletterdheid kan leiden tot misbruik of onjuist gebruik van AI-systemen en tot situaties waarin AI-systemen verkeerd worden ingezet, onbedoeld gebruikt worden voor taken waar ze niet geschikt voor zijn, of dat de veiligheid en effectiviteit van de systemen in het gedrang komt. Dit kan leiden tot ineffici\u00ebntie, fouten, en mogelijk schade aan organisaties, gebruikers of betrokkenen.</p>"},{"location":"vereisten/bevorder_ai_geletterdheid_personeel/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingLaat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald gebruikt kan worden na implementatie als het systeem in productie c.q. in gebruik is.Vastellen niveau van benodigde training voor gebruik algoritmen en AI-systemenLaat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden."},{"location":"vereisten/bewaartermijn_voor_documentatie/","title":"Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie","text":"<p>OntwerpOntwikkelenMonitoring en beheerUitfaserenGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#vereiste","title":"Vereiste","text":"<p>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de volgende elementen ter beschikking van de nationale bevoegde autoriteiten: a) de technische documentatie als bedoeld in artikel 11 van de AI-verordening; b) de documentatie betreffende het in artikel 17 bedoelde systeem voor kwaliteitsbeheer; c) in voorkomend geval de documentatie betreffende de door aangemelde instanties goedgekeurde wijzigingen; d) in voorkomend geval de besluiten en andere documenten die door de aangemelde instanties zijn afgegeven; e) de EU-conformiteitsverklaring als bedoeld in artikel 47. </p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#toelichting","title":"Toelichting","text":"<p>De aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#bronnen","title":"Bronnen","text":"Bron Artikel 18(1) Verordening Artifi\u00eble Intelligentie Artikel 16(d) Verordening Artifi\u00eble Intelligentie"},{"location":"vereisten/bewaartermijn_voor_documentatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/bewaartermijn_voor_documentatie/#risico","title":"Risico","text":"<p>Niet voldoen aan de bewaartermijn kan leiden tot juridische consequenties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/bewaartermijn_voor_documentatie/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegVaststellen bewaartermijnen voor archiefbescheidenStel de bewaartermijnen vast voor de archiefbescheiden.Bewaartermijnen zijn toegepastZorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende systemen. Controleer of deze maatregelen zijn getroffen en zorg dat dit aantoonbaar is.Archiefbescheiden vaststellenStel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde.Bespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/","title":"Bewaartermijn voor gegenereerde logs","text":"<p>OntwerpOntwikkelenVerificatie en validatieMonitoring en beheerUitfaserenGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen. Deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door Unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#bronnen","title":"Bronnen","text":"Bron Artikel 19(1) Automatisch gegenereerde logs- AI verordening Artikel 16(e) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening Artikel 12(1) Registratie- AI verordening"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/bewaartermijn_voor_gegenereerde_logs/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/","title":"Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit","text":"<p>Verificatie en validatieImplementatieGovernance</p>"},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld</p>"},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat de conformiteitsbeoordelingsprocedure wordt uitgevoerd voor het systeem op de markt wordt gebracht of in gebruik wordt genomen. Dit is mogelijk door middel van een interne controle (als bedoeld in bijlage VI van de AI-verordening) of met betrokkenheid van een aangemelde instantie voor de beoordeling van het systeem voor kwaliteitsbeheer en de technische documentatie (als bedoeld in bijlage VII van de AI-verordening).</p> <p>AI-systemen met een hoog risico die reeds aan een conformiteitsbeoordelingsprocedure zijn onderworpen, ondergaan een nieuwe conformiteitsbeoordelingsprocedure telkens wanneer zij substantieel zijn gewijzigd, ongeacht of het gewijzigde systeem bedoeld is om verder te worden gedistribueerd of door de huidige gebruiksverantwoordelijke gebruikt blijft worden.</p>"},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(f) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening Artikel 43 Conformiteitsbeoordeling - AI verordening Bijlage VI en VII AI Verordening"},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/conformiteitsbeoordelingsprocedure_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/","title":"Corrigerende maatregelen voor non-conforme AI","text":"<p>Monitoring en beheerOntwerpImplementatieGovernance</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem. Ze moeten ook alle relevante partijen, zoals distributeurs, gebruiksverantwoordelijken en importeurs, op de hoogte stellen van deze maatregelen.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 20(1) Corrigerende maatregelen en mededelingsverplichting- AI verordening Artikel 16(j) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#risico","title":"Risico","text":"<p>Niet reageren op non-conformiteit kan leiden tot risico's voor gebruikers en derden. Het kan leiden tot juridische procedures en reputatieschade voor organisaties.</p>"},{"location":"vereisten/corrigerende_maatregelen_voor_non_conforme_ai/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/databankenwet/","title":"Verbod op schenden databankenrechten","text":"<p>OntwerpDataverkenning en datapreparatieData</p>"},{"location":"vereisten/databankenwet/#vereiste","title":"Vereiste","text":"<p>Het is verboden om zonder goedkeuring van de producent een databank op te vragen en/of te hergebruiken.</p>"},{"location":"vereisten/databankenwet/#toelichting","title":"Toelichting","text":"<p>De Databankrichtlijn en Databankenwet beschermt de producten/fabrikanten van databanken tegen onrechtmatige toe-eigening van een databank. Degene die een substanti\u00eble financi\u00eble en professionele investering heeft verricht om de inhoud van de databank te verkijgen en te verzamelen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken. Bij verkrijgen gaat het om \"het verzamelen van de werken, gegevens of andere zelfstandige elementen die tezamen de inhoud van de databank vormen\". Dit recht bestaat naast het recht op bescherming van de originele keuze of rangschikking van de inhoud van databanken (auteurswet).</p> <p>Voor het ontwikkelen van algoritme en AI is data nodig. De data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank.</p>"},{"location":"vereisten/databankenwet/#bronnen","title":"Bronnen","text":"Bron Artikel 1 en 2 Databankenwet Artikel 5a en 5b Databankenwet Artikel 7 Databankrichtlijn Overwegingen 39 - 41 Databankrichtlijn"},{"location":"vereisten/databankenwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/databankenwet/#risico","title":"Risico","text":"<p>Als een ontwikkelaar onbevoegd gebruik heeft gemaakt van data uit een databank bij de ontwikkeling van algoritmes en AI, wordt het databankenrecht geschonden van de eigenaar.  De eigenaar van de databank kan bijvoorbeeld ontrekking van de data uit het handelsverkeer, vernietiging en onbruikbaarmaking  eisen, wat vergaande gevolgen kan hebben voor het gebruik kunnen maken van de algoritmische toepassing of AI-systeem.</p>"},{"location":"vereisten/databankenwet/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/","title":"Documentatie beoordeling niet-hoog-risico AI","text":"<p>OntwerpVerificatie en validatieGovernance</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Een aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Een aanbieder die oordeelt dat een AI-systeem niet valt onder hoog-risico zoals gefedinieerd in bijlage III van de AI-verordening, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem. Op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordeling. De aanbieder of in voorkomend geval de gemachtigd registreert zichzelf en het betreffende AI-systeem in de EU-databank (artikel 71 AI-verordening). AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 6(4) Classificatieregels voor AI-systemen met een hoog risico - AI verordening Artikel 49(2) AI Verordening Artikel 71 AI Verordening Bijlage III AI Verordening"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#risico","title":"Risico","text":"<p>Gebrek aan transparantie en verantwoording bij risicobeoordeling kan leiden tot onrechtmatig in de markt brengen en onrechtmatig gebruik van risicovolle AI-systemen.</p>"},{"location":"vereisten/documentatie_beoordeling_niet_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/","title":"Een DPIA is verplicht bij hoog risico","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatiePrivacy officerPrivacy en gegevensbescherming</p>"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Een gegevensbeschermingseffectbeoordeling (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Een Gegevensbeschermingseffectbeoordeling (GEB) of Data Protection Impact Assessment (DPIA) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen.  Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen.  Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.</p> <p>Let op: de DPIA verplichting is niet gebaseerd op de hoog-risico criteria uit de AI-act. Volgens Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens moet voor het uitvoeren van een DPIA in ieder geval uitgegaan worden van een hoog risico als er sprake is van \u00e9\u00e9n van de volgende voorwaarden:  1. Evaluatie of scoretoekenning  2. Geautomatiseerde besluitvorming met rechtsgevolg of vergelijkbaar wezenlijk gevolg  3. Stelselmatige monitoring  4. Gevoelige gegevens of gegevens van zeer persoonlijke aard  5. Op grote schaal verwerkte gegevens  6. Matching of samenvoeging van datasets  7. Gegevens met betrekking tot kwetsbare betrokkenen  8. Innovatief gebruik of innovatieve toepassing van nieuwe technologische of organisatorische oplossingen  9. de situatie waarin als gevolg van de verwerking zelf \"betrokkenen [...] een recht niet kunnen uitoefenen of geen beroep kunnen doen op een dienst of een overeenkomst\";</p> <p>Het is mogelijk dat algoritmes die niet aan \u00e9\u00e9n of meer van deze eigenschappen voldoen toch voor een potentieel hoog risico zorgen. </p> <p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruiken die informatie op grond van artikel 13 AI Verordening om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren. </p>"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 35 Algemene Verordening Gegevensbescherming Artikel 26(9) Verordening Artifici\u00eble Intelligentie Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#risico","title":"Risico","text":"<p>Het niet evalueren van de impact van het verwerking van persoonsgegevens in AI-systemen en algoritmes kan resulteren in het niet onderkennen van de bijbehorende risico's  en het niet op tijd te mitigieren van deze risico's. Dit kan leiden tot potenti\u00eble schendingen van de rechten en vrijheden van betrokkenen en een onrechtmatige verwerking.</p>"},{"location":"vereisten/dpia_verplicht_bij_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegEen model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst. MaatregelUitleg MaatregelUitlegEen model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktInventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst."},{"location":"vereisten/fundamentele_rechten/","title":"Beschermen van fundamentele rechten en vrijheden","text":"<p>ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerFundamentele rechten</p>"},{"location":"vereisten/fundamentele_rechten/#vereiste","title":"Vereiste","text":"<p>Fundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.</p>"},{"location":"vereisten/fundamentele_rechten/#toelichting","title":"Toelichting","text":"<p>Mensenrechten gelden voor alle mensen op de wereld. De mensenrechten in Nederland zijn beschermd door nationale wetten en internationale verdragen. In Nederland staan veel mensenrechten in hoofdstuk 1 van de Grondwet. Deze rechten heten ook wel \u2019grondrechten\u2019. Een bekend voorbeeld is artikel 1 van de Grondwet. Om mensenrechten te beschermen zijn ze op Europees en internationaal niveau in verschillende verklaringen en verdragen vastgelegd.</p> <p>Mensenrechten kunnen soms onder druk komen te staan. De inzet van algoritmes en AI-systemen kan bijvoorbeeld een bedreiging vormen voor de privacy van burgers, voor het  recht op gelijke behandeling en voor het recht op behoorlijk bestuur. Het is daarom belangrijk om tijdig te onderzoeken of er sprake is of kan zijn van een eventuele inbreuk op fundamentele rechten en vrijheden van burgers. Het is van belang dat maatregelen worden getroffen om een eventuele inbreuk te voorkomen.</p>"},{"location":"vereisten/fundamentele_rechten/#bronnen","title":"Bronnen","text":"Bron Grondwet Europees Verdragvoor de Rechten van de Mens (EVRM) Handvest van de grondrechten van de Europese Unie Universele Verklaring van de Rechten van de Mens (UVRM) Internationaal Statuut van de Rechten van de Mens Internationale Verdrag inzake burgerrechten en politieke rechten (IVBPR) Internationale Verdrag inzake economische, sociale en culturele rechten (IVESCR) Internationaal Verdrag inzake de uitbanning van alle vormen van rassendiscriminatie (CERD) Internationaal Verdrag voor de rechten van het kind (CRC) Internationaal Verdrag voor de Rechten van Mensen met een Handicap (VN-verdrag Handicap) Artikel 27 AI-verordening"},{"location":"vereisten/fundamentele_rechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/fundamentele_rechten/#risico","title":"Risico","text":"<p>Grondrechten kunnen worden aangetast door de inzet van algoritmes</p>"},{"location":"vereisten/fundamentele_rechten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/","title":"Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd","text":"<p>ImplementatieOntwikkelenGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevens</p>"},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#toelichting","title":"Toelichting","text":"<p>Anders dan in artikel 16(e) AI-verordening, waar een vergelijkbare vereiste geldt voor aanbieders, gaat het hier om een vereiste specifiek voor de gebruiksverantwoordelijken. Het is van belang dat de gebruiksverantwoordelijken een zelfstandige beoordeling maakt wat moet worden gelogd en voor welke periode gezien de doelstelling van de inzet van het AI-systeem. Daarbij is het van belang om te beoordelen in hoeverre een gebruiksverantwoordelijke hier 'controle' over heeft. De gebruiksverantwoordelijke zal, al dan niet samen met de aanbieder, (technische) maatregelen moeten treffen om dit te realiseren.</p> <p>Gebruiksverantwoordelijken die in de hoedanigheid van financi\u00eble instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financi\u00eble diensten bewaren de logs als onderdeel van de documentatie die bewaard wordt krachtens het desbetreffende Unierecht inzake financi\u00eble diensten.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#bronnen","title":"Bronnen","text":"Bron Artikel 26(6) AI Verordening"},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_bewaren_automatisch_gegenereerde_logs%20/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/","title":"Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem","text":"<p>ImplementatieMonitoring en beheerTransparantieGovernance</p>"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat gebruiksverantwoordelijken nagaan of het betreffende hoog risico AI-systeem door aanbieder is geregistreerd in de EU-databank (zoals omschreven in artikel 71 AI-verordening). Voordat het betreffende AI-systeem (bijlage III vermeld AI-systeem met een hoog risico) in gebruik te stellen of te gebruiken (met uitzondering van de in punt 2 van bijlage III vermelde AI-systemen met een hoog risico) registreren gebruiksverantwoordelijken die overheidsinstanties, instellingen, organen of instanties van de Unie, of personen die namens hen optreden, zichzelf en selecteren zij het systeem en registreren zij het gebruik ervan in de in artikel 71 bedoelde EU-databank.</p> <p>Heeft de aanbieder het betreffende hoog risico AI-systeem niet geregistreerd in de EU-Databank, dan mag het hoog risico AI-systeem niet worden gebruikt. De aanbieder of distributeur wordt door de gebruiksverantwoordelijke ge\u00efnformeerd dat het systeem niet is geregistreerd in de EU-databank.</p> <p>AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#bronnen","title":"Bronnen","text":"Bron Artikel 26(8) AI Verordening Artikel 49 (3) AI Verordening Artikel 71 AI Verordening"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#risico","title":"Risico","text":"<p>Zonder registratie van het hoge risico AI-systeem en het registreren welke organisaties of personen hier gebruik van maken, is het negatieve negatieve van het mogelijk onjuist of ongewenst functioneren van het AI-systeem niet te overzien en onduidelijk welke betrokken dit raakt.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_leven_registratieverplichting_na/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/","title":"Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning","text":"<p>ImplementatieMonitoring en beheerGovernanceMenselijke controle</p>"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat natuurlijke personen die het menselijk toezicht moeten uitvoeren over het AI-systeem met een hoog risico, daarvoor over de nodige bekwaamheid, opleiding en autoriteit beschikt. Daarbij kan het van belang zijn dat deze natuurlijke personen ondersteuning krijgen bij het uitvoeren van deze taak.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#bronnen","title":"Bronnen","text":"Bron Artikel 26(2) AI Verordening"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#risico","title":"Risico","text":"<p>Als de natuurlijke toezichthouder geen effectief toezicht kan houden op het hoog risico AI-systeem, kunnen ongewenste, negatieve effecten onstaan voor betrokkenen en de organisatie.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_menselijk_toezicht_natuurlijke_personen/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/","title":"Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem","text":"<p>Monitoring en beheerGovernanceMenselijke controle</p>"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI Verordening</p>"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken moeten de werking van hoog risico AI-systemen monitoren. Dit is van belang om passende maatregelen te kunnen treffen als het systeem onbedoeld anders gaat functioneren.</p> <p>Wanneer gebruiksverantwoordelijken redenen hebben om aan te nemen dat het gebruik overeenkomstig de gebruiksaanwijzingen ertoe kan leiden dat dat AI-systeem een risico vormt in de zin van artikel 79, lid 1, stellen zij de aanbieder of distributeur en de betreffende markttoezichtautoriteit hiervan zonder onnodige vertraging in kennis en onderbreken zij het gebruik van dat systeem. Wanneer gebruiksverantwoordelijke een ernstig incident vaststellen, stellen zij ook onmiddellijk eerst de aanbieder hiervan in kennis, en vervolgens de importeur of distributeur en de betreffende markttoezichtautoriteiten van dat incident. Wanneer de gebruiksverantwoordelijke de aanbieder niet kan bereiken, is artikel 73 mutatis mutandis van toepassing. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijke van AI-systemen die de hoedanigheid van rechtshandhavingsinstanties hebben.</p> <p>Voor gebruiksverantwoordelijke die in de hoedanigheid van financi\u00eble instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financi\u00eble diensten, wordt de monitoringsverplichting overeenkomstig de eerste alinea geacht te zijn vervuld door te voldoen aan de regels inzake interne governance, regelingen of processen en -mechanismen uit hoofde van het desbetreffende recht inzake financi\u00eble diensten.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#bronnen","title":"Bronnen","text":"Bron Artikel 26(5) AI Verordening"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#risico","title":"Risico","text":"<p>Zonder monitoring door gebruiksverantwoordelijken en (waar nodig) het informeren van aanbieder, distributeur of markttoezichtautoriteit, kan de foutieve werking van een hoog risico AI-systeem niet worden gesignaleerd en hersteld.</p>"},{"location":"vereisten/gebruiksverantwoordelijken_monitoren_werking_%20hoog_risico_AI-systeem/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/","title":"Privacyrechten","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Betrokkenen kunnen een beroep doen op hun privacyrechten.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens. Dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang te krijgen tot hun gegevens of om wijzigingen aan te brengen indien nodig. Het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen, het waarborgen van transparantie en controle uitvoeren over persoonsgegevens. Als persoonsgegevens worden verwerkt voor het ontwikkelen en gebruiken van algoritmes en AI, is het van belang dat maatregelen worden getroffen om deze rechten te eerbiedigen.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 15 - 21 AVG"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens wanneer ze geen beroep kunnen doen op hun privacyrechten.</p>"},{"location":"vereisten/inroepen_privacyrecht_bij_verwerking_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/","title":"Juistheid en actualiteit van gegevens","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De te verwerken persoonsgegevens moeten nauwkeurig, juist en zo nodig actueel zijn. Dit betekent dat alle maatregelen moeten worden genomen om ervoor te zorgen dat onjuiste persoonsgegevens worden gerectificeerd of gewist. Dat kan betekenen dat persoonsgegevens moeten worden geactualiseerd of verbeterd. In de context van algoritmes en AI is het van belang dat ook daar wordt onderzocht welke maatregelen nodig zijn om die juistheid toe te passen.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 sub d AVG"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#risico","title":"Risico","text":"<p>Als er geen rekening wordt gehouden met de juistheid, nauwkeurigheid en volledigheid van persoonsgegevens, kunnen kwaliteit en integriteit van data niet voldoende worden gewaarborgd.</p>"},{"location":"vereisten/juistheid_en_actualiteit_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/","title":"Kwaliteitsbeheersysteem voor hoog-risico AI","text":"<p>ProbleemanalyseOntwerpGovernance</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een kwaliteitsbeheersysteem implementeren om te garanderen dat ze voldoen aan de AI-verordening. Dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en behandelt beknopt de volgende aspecten:</p> <ol> <li>een strategie voor de naleving van de regelgeving, inclusief de naleving van de conformiteitsbeoordelingsprocedures en de procedures voor het beheer van de wijzigingen van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor het ontwerp, de controle van het ontwerp en de verificatie van het ontwerp van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor de ontwikkeling, de kwaliteitscontrole en de kwaliteitsborging van het AI-systeem met een hoog risico;</li> <li>procedures voor het inspecteren, testen en valideren die v\u00f3\u00f3r, tijdens en na de ontwikkeling van het AI-systeem met een hoog risico moeten worden uitgevoerd en de regelmaat waarmee zij moeten worden uitgevoerd;</li> <li>technische specificaties, met inbegrip van normen, die moeten worden toegepast en, wanneer de relevante geharmoniseerde normen niet volledig worden toegepast of geen betrekking hebben op alle relevante eisen van afdeling 2, de middelen die worden gebruikt om ervoor te zorgen dat het AI-systeem met een hoog risico in overeenstemming is met deze eisen;</li> <li>systemen en procedures voor databeheer, met inbegrip van dataverwerving, - verzameling, -analyse, -labeling, -opslag, -zuivering, -aggregatie en -behoud en datamining en eventuele andere operaties met betrekking tot de data die worden uitgevoerd voorafgaand aan en met het oog op het in de handel brengen of in gebruik stellen van AI-systemen met een hoog risico;</li> <li>het systeem voor risicobeheer zoals bedoeld in artikel 9 van de AI-verordening;</li> <li>het opzetten, toepassen en onderhouden van een systeem voor monitoring na het in de handel brengen, overeenkomstig artikel 72 AI-verordening;</li> <li>procedures in verband met het melden van een ernstig incident in overeenstemming met artikel 73 van de AI-verordening;</li> </ol>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 17(1) Systeem voor kwaliteitsbeheer- AI verordening Artikel 16(c) Verplichtingen van aanbieders van AI-systemen met een hoog risico - AI veordening"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Zonder toepassing van een kwaliteitsbeheersysteem kunnen risico's ontstaan voor de veiligheid, betrouwbaarheid en naleving van het AI-systeem en conformiteit met wet- en regelgeving.</p>"},{"location":"vereisten/kwaliteitsbeheersysteem_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/kwaliteitscriteria_voor_data/","title":"Data van hoog-risico ai moet voldoen aan kwaliteitscriteria","text":"<p>OntwerpDataverkenning en datapreparatieVerificatie en validatieGovernanceData</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico die technieken gebruiken die het trainen van AI-modellen met data omvatten, worden ontwikkeld op basis van datasets voor training, validatie en tests die voldoen aan de kwaliteitscriteria telkens wanneer dergelijke datasets worden gebruikt.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt.</p> <p>Deze vereiste houdt in dat de gebruikte datasets onder meer moeten voldoen aan: - datasets voor training, validatie en tests worden onderworpen aan praktijken op het gebied van databeheer die stroken met het beoogde doel van het AI-systeem met een hoog risico. Dit heeft in het bijzonder betrekking op relevante ontwerpkeuzes, processen voor dataverzameling, verwerkingsactiviteiten voor datavoorbereiding, het opstellen van aannames met name betrekking tot de informatie die de data moeten meten en vertegenwoordigen, beschikbaarheid, kwantiteit en geschiktheid van de datasets en een beoordeling op mogelijke vooringenomenheid en passende maatregelen om deze vooringenomenheid op te sporen, te voorkomen en te beperken.  - datasets voor training, validatie en tests zijn relevant, voldoende representatief en zoveel mogelijk foutenvrij en volledig met het oog op het beoogde doel. - Er wordt rekening gehouden met de eigenschappen of elementen die specifiek zijn voor een bepaalde geografische, contextuele, functionele of gedragsomgeving waarin het AI-systeem wordt gebruikt.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#bronnen","title":"Bronnen","text":"Bron Artikel 10(1) Verordening Artifici\u00eble Intelligentie"},{"location":"vereisten/kwaliteitscriteria_voor_data/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/kwaliteitscriteria_voor_data/#risico","title":"Risico","text":"<p>Gebruik van laagkwalitatieve of bevooroordeelde datasets kan leiden tot onbetrouwbare en oneerlijke AI-besluitvorming. Onvoldoende kwaliteitsborging van testdata kan leiden tot vertekende resultaten en gebrekkige prestaties van het AI-systeem bij gebruik in de praktijk.</p>"},{"location":"vereisten/kwaliteitscriteria_voor_data/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/","title":"Maatregelen van gebruiksverantwoordelijken voor gebruik","text":"<p>ImplementatieGovernance</p>"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.</p>"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico moeten geschikte maatregelen nemen om ervoor te zorgen dat zij deze systemen gebruiken volgens de bijgevoegde instructies. De gebruiksverantwoordelijke zorgt ervoor dat de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico, voor zover hij daar controle over heeft.</p>"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#bronnen","title":"Bronnen","text":"Bron Artikel 26 Verplichtingen van gebruiksverantwoordelijken van AI-systemen met een hoog risico- AI verordening"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#risico","title":"Risico","text":"<p>Het niet naleven van deze maatregelen kan leiden tot onjuist gebruik van de AI-systemen, wat de effectiviteit en veiligheid ervan kan verminderen, en kan resulteren in risico's voor gebruikers en derden.</p>"},{"location":"vereisten/maatregelen_van_gebruiksverantwoordelijken_voor_gebruik/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/melding_ernstige_incidenten/","title":"Melden van ernstige incidenten","text":"<p>ImplementatieMonitoring en beheerGovernance</p>"},{"location":"vereisten/melding_ernstige_incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die binnen de EU worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden. Een 'ernstig incident' wordt in artikel 3 van de AI-verordening gedefinieerd als: een incident of gebrekkig functioneren van een AI-systeem dat direct of indirect leidt tot: </p> <ol> <li>het overlijden van een persoon of ernstige schade voor de gezondheid van een persoon;</li> <li>een ernstige en onomkeerbare verstoring van het beheer of de exploitatie van kritieke infrastructuur;</li> <li>een schending van de uit het recht van de Unie voortvloeiende verplichtingen ter bescherming van de grondrechten;</li> <li>ernstige schade aan eigendommen of het milieu.</li> </ol> <p>Dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze AI-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek. Het doel is om de veiligheid en betrouwbaarheid van AI-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliseren.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#bronnen","title":"Bronnen","text":"Bron Artikel 73(1) Melding van ernstige incidenten AI verordening"},{"location":"vereisten/melding_ernstige_incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/melding_ernstige_incidenten/#risico","title":"Risico","text":"<p>Het niet melden van ernstige incidenten kan leiden tot vertraagde reactie op potenti\u00eble gevaren voor gebruikers en kan het vertrouwen in AI-systemen ondermijnen.</p>"},{"location":"vereisten/melding_ernstige_incidenten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/","title":"Persoonsgegevens verzamelen voor specifieke doeleinden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.</p>"},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat \u00e9nkel persoonsgegevens worden verwerkt die noodzakelijk zijn gezien de doeleinden van die vewerking. Er moet een beoordeling worden gemaakt welke persoonsgegevens dit wel en eventueel niet zijn. Voor het ontwikkelen en gebruiken van algoritmes of AI-systemen is het van belang om te beoordelen welke persoonsgegevens noodzakelijk zijn om het beoogde doel te bereiken. Afhankelijk van de toepassing vraagt dit om een intensieve toets. Er moet voor worden gezorgd dat persoonsgegevens die niet als noodzakelijk worden beschouwd, buiten de verwerking blijven. </p>"},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder c AVG"},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig verwerken van persoonsgegevens kan een inbreuk maken op rechten van betrokkenen, en zou kunnen leiden tot een datalek.</p>"},{"location":"vereisten/minimale_verwerking_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/","title":"Monitoring na het in handel brengen","text":"<p>Monitoring en beheerPrivacy en gegevensbescherming</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#vereiste","title":"Vereiste","text":"<p>Aanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#toelichting","title":"Toelichting","text":"<p>Aanbieders moeten een monitoringssysteem opzetten voor het monitoren na het in de handel brengen. Dit systeem moet documenteren op een wijze die passend is bij de aard van de AI-technologie\u00ebn en de risico's van het betreffende AI-systeem met een hoog risico. Dit monitoringssysteem moet proportioneel zijn aan de complexiteit en potenti\u00eble impact van het AI-systeem.</p> <p>Het systeem voor monitoring na het in de handel brengen verzamelt, documenteert en analyseert actief en systematisch relevante data die door gebruiksverantwoordelijken kunnen zijn verstrekt of via andere bronnen kunnen zijn verzameld, over de prestaties van AI-systemen met een hoog risico gedurende hun hele levensduur. Dit stelt de aanbieder in staat na te gaan of AI-systemen blijvend voldoen aan de in hoofdstuk III, afdeling 2, van de AI-verordening vermelde voorschriften. In voorkomend geval omvat de monitoring na het in de handel brengen een analyse van de interactie met andere AI-systemen. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijken die rechtshandhavingsinstanties zijn.</p> <p>Het systeem voor monitoring na het in de handel brengen is gebaseerd op een plan voor monitoring na het in de handel brengen. Het plan voor monitoring na het in de handel brengen maakt deel uit van de in bijlage IV bedoelde technische documentatie.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#bronnen","title":"Bronnen","text":"Bron Artikel 72(1) Monitoring door aanbieders na het in de handel brengen en plan voor monitoring na het in de handel brengen voor AI-systemen met een hoog risico- AI verordening"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#risico","title":"Risico","text":"<p>Zonder monitoringssysteem voor na het in handel brengen is er een risico dat verminderde pestaties van een AI-systeem met hoog risico ongedeteceerd blijven. Een aanbieder kan niet nagaan of een AI-systeem blijvend voldoet aan voorschriften.</p>"},{"location":"vereisten/monitoring_na_het_in_de_handel_brengen/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/motiveringsbeginsel/","title":"Een besluit berust op een deugdelijke motivering","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerGovernance</p>"},{"location":"vereisten/motiveringsbeginsel/#vereiste","title":"Vereiste","text":"<p>Een besluit berust op een deugdelijke motivering</p>"},{"location":"vereisten/motiveringsbeginsel/#toelichting","title":"Toelichting","text":"<p>Een bestuursorgaan moet inzichtelijk maken:  1. dat een besluit tot stand is gekomen met behulp van een algoritme;  2. van welke feiten het is uitgegaan en welke gegevens van de burger gebruikt c.q. verwerkt zijn; 3. welke relevante belangen tegen elkaar zijn afgewogen en hoe die afweging is verlopen (bijvoorbeeld het gewicht dat wordt toegekend aan elk afgewogen kenmerk; welke analytische technieken gebruikt zijn; welke specifieke voorspellende data; wat de belangrijkste policy-keuzes waren; een uitleg van het voorspellende algoritme);  4. hoe het algoritme werkt (niet de techniek, maar hoe de uitkomsten van het algoritme tot stand komen).  De keuzes en aannames die zijn gemaakt en gedaan moeten worden beschreven en toegelicht.</p>"},{"location":"vereisten/motiveringsbeginsel/#bronnen","title":"Bronnen","text":"Bron Artikel 3:46 - 3:50 Awb Jurisprudentie over AERIUS (ABRvS 18 juli 2018, ECLI:NL:RVS:2018:2454), Hof van Justitie C-274/18"},{"location":"vereisten/motiveringsbeginsel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/motiveringsbeginsel/#risico","title":"Risico","text":"<p>Het is onduidelijk op wat voor manier het algoritmes of AI-systeem heeft bijgedragen aan de totstandkoming van een besluit. </p>"},{"location":"vereisten/motiveringsbeginsel/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/non_discriminatie/","title":"AI-systemen en algoritmes mogen niet discrimineren","text":"<p>ProbleemanalyseDataverkenning en datapreparatieOntwerpVerificatie en validatieImplementatieMonitoring en beheerFundamentele rechten</p>"},{"location":"vereisten/non_discriminatie/#vereiste","title":"Vereiste","text":"<p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Directe en indirecte discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan.</p>"},{"location":"vereisten/non_discriminatie/#toelichting","title":"Toelichting","text":"<p>Overheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.</p>"},{"location":"vereisten/non_discriminatie/#bronnen","title":"Bronnen","text":"Bron Artikel 1 Grondwet Artikel 14 Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-1950 Artikel 21 Handvest van de Grondrechten van de Europese Unie Artikel 1 Algemene wet gelijke behandeling Artikel 1 Protocol nr. 12 bij het Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-2000 Artikel 9 Algemene Verordening Gegevensbescherming Artikel 2:4 Algemene wet bestuursrecht"},{"location":"vereisten/non_discriminatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/non_discriminatie/#risico","title":"Risico","text":"<p>Het risico bestaat dat het model onwenselijke systematische afwijkingen cre\u00ebert voor specifieke personen, groepen of andere eenheden, wat kan duiden op directe of indirecte discriminerende effecten van het algoritme.</p>"},{"location":"vereisten/non_discriminatie/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Configuratie met de mensZorg voor complementariteit tussen algoritmische systeem en de mensen die ermee moeten werken.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/","title":"Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden. Dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgd.</p> <p>Technische robuustheid is een essenti\u00eble eis voor AI-systemen met een hoog risico. Deze systemen moeten bestand zijn tegen schadelijk of anderszins ongewenst gedrag dat kan voortvloeien uit de beperkingen binnen de systemen of de omgeving waarin de systemen opereren (bijvoorbeeld fouten, onregelmatigheden, onverwachte situaties). Daarom moeten technische en organisatorische maatregelen worden getroffen om de robuustheid van AI-systemen met een hoog risico te waarborgen. Een technische oplossing kan bijvoorbeeld bestaan uit mechanismen die het systeem in staat stellen zijn werking veilig te onderbreken (storingsbeveiligingsplannen) wanneer zich bepaalde anomalie\u00ebn voordoen of wanneer de werking buiten bepaalde vooraf bepaalde grenzen plaatsvindt.</p> <p>Cyberbeveiliging is cruciaal om te waarborgen dat AI-systemen bestand zijn tegen pogingen van kwaadwillige derden die gebruikmaken van de kwetsbaarheden van het systeem om het gebruik, het gedrag of de prestaties ervan te wijzigen of de veiligheidskenmerken ervan in gevaar te brengen. Bij cyberaanvallen tegen AI-systemen kunnen AI-specifieke activa worden gebruikt, zoals trainingsdatasets (bv. datavervuiling) of getrainde modellen (bv. vijandige aanvallen of membership inference), of kwetsbaarheden in de digitale activa van het AI-systeem of de onderliggende ICT-infrastructuur worden benut. Om te zorgen voor een niveau van cyberbeveiliging dat aansluit op de risico\u2019s, moeten aanbieders van AI-systemen met een hoog risico passende maatregelen zoals veiligheidscontroles nemen, waarbij ook rekening wordt gehouden met de onderliggende ICT infrastructuur.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#bronnen","title":"Bronnen","text":"Bron Artikel 15(1) Nauwkeurigheid, robuustheid en cyberbeveiliging- AI verordening"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#risico","title":"Risico","text":"<p>Gebrek aan nauwkeurigheid, robuustheid of cyberbeveiliging kan leiden tot onbetrouwbare prestaties, kwetsbaarheid voor storingen en blootstelling aan beveiligingsrisico's, wat de effectiviteit en veiligheid van het AI-systeem in gevaar kan brengen.</p>"},{"location":"vereisten/ontwerp_voor_nauwkeurigheid_robuustheid_en_cyberbeveiliging/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/","title":"Verwerking van persoonsgegevens moet rechtmatig plaatsvinden","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatiePrivacy en gegevensbescherming</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet rechtmatig plaatsvinden.</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet rechtmatig plaatsvinden, wat betekent dat de verwerking gebaseerd moet zijn op \u00e9\u00e9n van de wettelijke grondslagen die zijn geformuleerd in artikel 6 Algemene Verordening Gegevensbescherming. Persoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden. Het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden.</p> <p>Bij het verwerken van persoonsgegevens ten behoeve van de ontwikkeling en gebruik van algoritmes en AI moet worden onderzocht of dit kan worden gebaseerd op \u00e9\u00e9n van de verwerkingsgrondslagen. Het is van belang dat wordt uitgewerkt welke persoonsgegevens waarvoor worden verwerkt en op basis van welke grondslag. Hierbij kan worden gedacht aan persoonsgegevens ten behoeve van trainingsdata, voor het genereren van output of, indien (juridisch) mogelijk, voor het uitvoeren van een onderzoek naar onbewuste vooringenomenheid.</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 onder a en b  AVG Artikel 6 lid 1 onder b AVG Artikel 6 AVG Overweging 39 en 45 AVG"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#risico","title":"Risico","text":"<p>Het risico wanneer persoonsgegevens niet op een rechtmatige manier worden verwerkt (verzamelen van gegevens valt hier ook onder), is dat er niet aan de AVG wordt voldaan. Er worden dan onrechtmatig persoonsgegevens verwerkt, waarmee privacy van personen in het geding komt. Ook kan het leiden tot hoge boetes voor organisaties, en kan een datalek plaatsvinden.</p>"},{"location":"vereisten/persoonsgegevens_worden_rechtmatig_verwerkt/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/","title":"Privacy door ontwerp","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenImplementatiePrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Privacy en gegevensbescherming door goed ontwerp en door standaardinstellingen</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen (ook wel privacy-by-design genoemd). Door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt. Hierbij kan worden gedacht een het pseudonimiseren van persoonsgegevens of dataminimalisatie. Deze aanpak zorgt ervoor dat privacy-overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevens. Dit is eveneens van toepassing als persoonsgegevens worden verwerkt bij het ontwikkelen en gebruiken van algoritmes en AI.</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 25 AVG"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#risico","title":"Risico","text":"<p>Door privacy en gegevensbescherming door ontwerp en standaardinstellingen niet toe te passen, kan een inbreuk op rechten van betrokkenen ontstaan.</p>"},{"location":"vereisten/privacy_bij_ontwerp_bij_verwerking_van_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/","title":"Klachtrecht aanbieders verder in AI-waardeketen","text":"<p>Monitoring en beheerGovernanceFundamentele rechten</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#vereiste","title":"Vereiste","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#toelichting","title":"Toelichting","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht om een klacht in te dienen bij het AI-bureau in het geval van een inbreuk op de AI-verordening. Dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot AI-modellen voor algemene doeleinden die zij ge\u00efntrigeerd hebben in AI-systemen. Het AI-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen tussen aanbieders op te lossen.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#bronnen","title":"Bronnen","text":"Bron Artikel 89(2) Monitoringmaatregelen- AI verordening"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#risico","title":"Risico","text":"<p>Gebrek aan klachtrecht verhindert het AI-bureau om tijdig en zorgvuldig te kunnen ingrijpen bij overtreding van de AI-verordening.</p>"},{"location":"vereisten/recht_klacht_indienen_bij_ai_bureau/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/","title":"Recht op niet geautomatiseerde besluitvorming","text":"<p>OntwerpOntwikkelenMonitoring en beheerPrivacy en gegevensbescherming</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#vereiste","title":"Vereiste","text":"<p>Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate treft.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#bronnen","title":"Bronnen","text":"Bron Artikel 22 Algemene Verordening Gegevensbescherming Artikel 1:3 Algemene wet bestuursrecht"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#risico","title":"Risico","text":"<p>Bij geautomatiseerde besluitvorming kan het risico ontstaan dat kenmerken van een bepaalde groep ten onrechte worden tegengeworpen aan een individu die deze kenmerken niet hoeft te bezitten.</p>"},{"location":"vereisten/recht_op_niet_geautomatiseerd_besluitvorming/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Controle mechanisme voor betekenisvolle menselijke tussenkomst bij gebruiken outputZorg voor een controle mechanisme waarmee kan worden voorkomen dat gebruikers belangrijke output van algoritmen en AI-systemen, zonder betekenisvolle menselijke tussenkomst, bv. enkel met doorklikken, kunnen overnemen.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBepaal of de output bepalende invloed heeft in een besluit richting personenVergewis of het algoritme of AI-systeem overwegend bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervanBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem het element van menselijke tussenkomst op in het projectplan en dchargedocument.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/","title":"Eenieder heeft recht op toegang tot publieke informatie","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerTransparantie</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#vereiste","title":"Vereiste","text":"<p>Een bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#toelichting","title":"Toelichting","text":"<p>Bij het ontwikkelen en gebruiken van algoritmes en AI kunnen documenten en publieke informatie ontstaan die (op verzoek) in aanmerking komen voor openbaarmaking. Het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat. De Wet open overheid gaat uit van een recht op openbaarheid van publieke informatie. Iedereenkan een verzoek tot openbaarmaking van publieke informatie doen bij een bestuursorgaan zonder daarbij een belang te stellen (artikel 4.1 Woo). De aan een verzoeker verstrekte informatie wordt openbaar voor iedereen. De Woo is niet van toepassing op informatie die al openbaar is (uitspraken van de Afdeling bestuursrechtspraak van de Raad van State van 1 december 2010 (ECLI:NL:RVS:2010:BNS6990) en 20 oktober 2010 (ECLI:NL:RVS:2010:BO1165)). Er kunnen uitsluitingsgronden bestaan voor het openbaarmaken van documenten (artikel 5.1 Woo).</p> <p>In de context van het ontwikkelen en gebruiken van algoritmes en AI-systemen is het van belang dat tijdig wordt vastgesteld welke documenten in aanmerking komen voor openbaarmaking. Dit moet worden bekeken in het licht van wat 'actief' moet worden geopenbaard, dus proactief vanuit overheidsinstanties zelf, of wat op 'verzoek' van iemand moet worden geopenbaard.</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#bronnen","title":"Bronnen","text":"Bron Artikel 1.1, 2.5, 4.1, 5 Woo"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#risico","title":"Risico","text":"<p>Zonder het openbaren van overheidsinformatie kan de overheid niet effectief worden gecontroleerd bij het uitvoeren van wettelijke taken.</p>"},{"location":"vereisten/recht_op_toegang_tot_publieke_informatie/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/recht_op_uitleg_ai_besluiten/","title":"Veilig melden van inbreuk op AI verordening","text":"<p>OntwerpOntwikkelenMonitoring en beheerGovernanceFundamentele rechten</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#vereiste","title":"Vereiste","text":"<p>Inbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#toelichting","title":"Toelichting","text":"<p>Personen die optreden als klokkenluiders bij inbreuken op de AI-verordening, moeten worden beschermd uit hoofde van het Unierecht. Richtlijn (EU) 2019/1937 (https://eur-lex.europa.eu/legal-content/NL/LSU/?uri=CELEX:32019L1937) van het Europees Parlement en de Raad moet daarom van toepassing zijn. De richtlijn biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders (\"klokkenluiders\") beschermt tegen represailles of vervolging. Deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteit.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#bronnen","title":"Bronnen","text":"Bron Artikel 87 Melding van inbreuken en bescherming van melders- AI verordening"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#risico","title":"Risico","text":"<p>Gebrek aan een veilige omgeving kan ertoe leiden dat klokkenluiders geen melding maken van inbreuk op de AI-verordening.  Dit schaadt het rapportagesysteem en heeft negatief effect op het maatschappelijk welzijn.</p>"},{"location":"vereisten/recht_op_uitleg_ai_besluiten/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/registratieverplichtingen_hoog_risico/","title":"Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico","text":"<p>OntwikkelenVerificatie en validatieImplementatieGovernanceTransparantie</p>"},{"location":"vereisten/registratieverplichtingen_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.</p>"},{"location":"vereisten/registratieverplichtingen_hoog_risico/#toelichting","title":"Toelichting","text":"<p>V\u00f3\u00f3r de distributie of inbedrijfstelling van een AI-systeem met een hoog risico van bijlage III, met uitzondering van specifieke gevallen zoals beschreven in punt 2 van bijlage III, is het vereist dat de aanbieder of gemachtigde zichzelf en het systeem registreert in de EU-databank zoals genoemd in art. 71 AI-verordening.</p>"},{"location":"vereisten/registratieverplichtingen_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(i) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening Artikel 49(1) Registratie - AI verordening"},{"location":"vereisten/registratieverplichtingen_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/registratieverplichtingen_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/registratieverplichtingen_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/","title":"Risicobeoordeling voor jongeren en kwetsbaren","text":"<p>ProbleemanalyseOntwerpOntwikkelenFundamentele rechten</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#vereiste","title":"Vereiste","text":"<p>Bij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#toelichting","title":"Toelichting","text":"<p>Bij de uitvoering van het in de leden 1 tot en met 7 van art. 9 AI-Verordening bedoelde systeem voor risicobeheer houden aanbieders rekening met de vraag of het beoogde doel van het AI-systeem met een hoog risico waarschijnlijk negatieve gevolgen zal hebben voor personen jonger dan 18 jaar en, in voorkomend geval, voor andere groepen kwetsbare personen. Er moet een grondige risicoanalyse plaatsvinden en worden vertaald naar mitigerende maatregelen om het risico te elimineren of te mitigeren.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#bronnen","title":"Bronnen","text":"Bron Artikel 9(9) Systeem voor risicobeheer -  AI verordening"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#risico","title":"Risico","text":"<p>Niet adequaat adresseren van risico's voor jongeren en kwetsbare groepen kan leiden tot ernstige ethische en maatschappelijke schade.</p>"},{"location":"vereisten/risicobeoordeling_voor_jongeren_en_kwetsbaren/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/","title":"Technische documentatie voor hoog-risico AI","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt opgesteld voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld, en wordt geactualiseerd. De technische documentatie wordt op zodanige wijze opgesteld dat wordt aangetoond dat het AI-systeem met een hoog risico in overeenstemming is met de eisen van Afdeling 2 van de AI-verordening en dat nationale bevoegde autoriteiten en aangemelde instanties over de noodzakelijke, op heldere en begrijpelijke wijze gestelde informatie beschikken om de overeenstemming van het AI-systeem met deze voorschriften te kunnen beoordelen.</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen.</p> <p>De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV:</p> <ol> <li>Een algemene beschrijving van het AI-syseem.</li> <li>Een gedetailleerde beschrijving van de elementen van het AI-systeem en het proces voor de ontwikkeling ervan.</li> <li>Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem.</li> <li>Een beschrijving van de geschiktheid van de prestatiestatistieken.</li> <li>Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening.</li> <li>Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht.</li> <li>Een lijst van normen die worden toegepast.</li> <li>Een exemplaar van de EU-conformiteitsverklaring.</li> <li>Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI verordening.</li> </ol>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 11 Verordening Artifici\u00eble Intelligentie Bijlage IV Verordening Artifici\u00eble Intelligentie"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Het ontbreken van de benodigde informatie over de algoritmische toepassing of AI-systeem kan ertoe leiden dat de technische functionering onduidelijk is. Dat kan tot problemen leiden bij de verantwoording, controle en het beheer. Onvolledige of ontoereikende technische documentatie kan leiden tot onduidelijkheid over de conformiteit van het AI-systeem met de regelgeving, wat de veiligheid en naleving in gevaar kan brengen.</p>"},{"location":"vereisten/technische_documentatie_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeBespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld."},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/","title":"Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerGovernance</p>"},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882</p>"},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat hun systeem toegankelijk is volgens de EU-richtlijnen 2016/2102 en 2019/882. In het kader van Richtlijn 2016/2102 moet onder toegankelijkheid worden verstaan het geheel van principes en technieken die in acht moeten worden genomen bij het ontwerpen, bouwen, beheren en bijwerken van websites en mobiele applicaties om hen voor gebruikers toegankelijker te maken, met name voor personen met een beperking. Bijlage 1 bevat de toegankelijkheidsvoorschriften voor producten en diensten die moeten worden toegepast op hoog-risico AI-systemen.</p> <p>Richtlijn 2019/882 strekt ertoe een bijdrage te leveren tot het goed functioneren van de interne markt middels onderlinge  aanpassing van de wettelijke en bestuursrechtelijke bepalingen van de lidstaten inzake de toegankelijkheidsvoorschriften  voor bepaalde producten en diensten, in het bijzonder door het wegwerken en voorkomen van belemmeringen voor het vrije verkeer van onder deze richtlijn vallende producten en diensten ten gevolge van uiteenlopende toegankelijkheidsvoorschriften in de lidstaten</p>"},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#bronnen","title":"Bronnen","text":"Bron Artikel 16(l) Verplichtingen van aanbieders van AI-systemen met een hoog risico- AI verordening EU-richtlijn 2016/2102 Bijlage 1: Toegankelijkheidsvoorschriften voor producten en diensten. EU-richtlijn 2019/882"},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/toegankelijkheidseisen_hoog_risico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/","title":"Toezichtmogelijkheden voor gebruikers","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerMenselijke controle</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#toelichting","title":"Toelichting","text":"<p>Het menselijk toezicht is gericht op het voorkomen of beperken van de risico\u2019s voor de gezondheid, veiligheid of grondrechten die zich kunnen voordoen wanneer een AI-systeem met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan of in een situatie van redelijkerwijs te voorzien misbruik, met name wanneer dergelijke risico\u2019s blijven bestaan ondanks de toepassing van andere eisen van deze afdeling.</p> <p>De toezichtmaatregelen staan in verhouding met de risico's, de mate van autonomie en de gebruikscontext van het AI-systeem met een hoog risico. Hierbij kan het gaan om: a) door de aanbieder bepaalde maatregelen die waar technisch haalbaar in het AI-systeem met een hoog risico worden ingebouwd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld; b) door de aanbieder bepaalde maatregelen voordat het AI-systeem met een hoog risico in de handel wordt gebracht of in gebruik wordt gesteld en die passend zijn om door de gebruiksverantwoordelijke te worden uitgevoerd.</p> <p>De natuurlijke personen die verantwoordelijk zijn voor het menselijk toezicht, moeten in staat worden gesteld om waar passend en in verhouding tot de omstandigheden het volgende te kunnen doen: a) Goed kunnen begrijpen van de relevante capaciteiten en beperkingen van het AI-systeem met een hoog risico. Met het oog op het opsporen en aanpakken van onregelmatigheden, storingen en onverwachte prestaties moet de werking van het AI-systeem goed kunnen worden begrepen; b) Bewust blijven van de mogelijke neiging om automatisch of te veel te vertrouwen op de output van een AI-systeem met hoog risico (automation bias). Dit geldt in het bijzonder voor het gebruik van een hoog risico AI-systeem dat wordt gebruikt om informatie of aanbevelingen te versterkken voor beslisisngen die door natuurlijke personen moeten worden genomen; c) De output juist kunnen interpreteren, bijvoorbeeld met behulp van de juiste instrumenten en methoden voor interpretatie; d) In alle specifieke situaties kunnen besluiten om het hoog risico AI-systeem niet te gebruiken of de output op een andere wijze te negeren, door een andere beslissing te vervangen of terug te draaien; e) ingrijpen in de werking van het hoog risico AI-systeem of het systeem onderbreken door middel van een stopknop of een vergelijkbare procedure waarmee het systeem op een veilige wijze kan worden stopgezet.</p> <p>In het geval van een hoog risico systeem als bedoeld in bijlage III, punt 1, a  (systemen voor biometrische identificatie op afstand) geldt het vereiste dat twee natuurlijke personen met de nodige bekwaamheid, opleiding en bevoegdheid apart de indentificatie van het systeem verifici\u00ebren en bevestigen, tenzij het wordt gebruikt voor rechtshandhaving, migratie, grenstoezicht of asiel, in gevallen waarin het Unierecht of het nationale recht de toepassing van dit vereiste onevenredig acht.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#bronnen","title":"Bronnen","text":"Bron Artikel 14 Menselijk toezicht- AI verordening"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#risico","title":"Risico","text":"<p>Ontbreken van betekenisvol menselijk toezicht kan leiden tot gebrek aan controle en begrip over het functioneren van het AI-systeem, wat kan resulteren in ongewenste of onvoorspelbare uitkomsten.</p>"},{"location":"vereisten/toezichtmogelijkheden_voor_gebruikers/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/transparantie/","title":"Transparantie in ontwerp voor hoog-risico AI","text":"<p>OntwerpOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerTransparantie</p>"},{"location":"vereisten/transparantie/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat de werking ervan voldoende transparant is om gebruiksverantwoordelijken in staat te stellen de output van een systeem te interpreteren en op passende wijze te gebruiken. Een passende soort en mate van transparantie wordt gewaarborgd met het oog op de naleving van de relevante verplichtingen van de aanbieder en de gebruiksverantwoordelijke zoals uiteengezet in afdeling 3 van Artikel 13 van de AI verordening.</p>"},{"location":"vereisten/transparantie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.</p>"},{"location":"vereisten/transparantie/#bronnen","title":"Bronnen","text":"Bron Artikel 13(1) Verordening Artifici\u00eble Intelligentie"},{"location":"vereisten/transparantie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/transparantie/#risico","title":"Risico","text":"<p>Onvoldoende transparantie kan leiden tot een gebrek aan begrip over hoe het AI-systeem functioneert, wat de effectiviteit van de inzet ervan kan belemmeren en de naleving van wettelijke verplichtingen in gevaar kan brengen.</p>"},{"location":"vereisten/transparantie/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste.Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing zijn en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. Dit is mede afhankelijk van de bijbehorende risicoclassificatie."},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/","title":"Transparantie bij verwerking persoonsgegevens","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerPrivacy en gegevensbeschermingTransparantie</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet transparant zijn.</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Een betrokkene moet op de hoogte worden gesteld van het feit dat er verwerking plaatsvindt van diens persoonsgegevens en van de doeleinden daarvan (zoals ook is verwoord in het beginsel van transparante verwerking, artikel 5 AVG). Hierbij moeten de specifieke omstandigheden en de context waarin de persoonsgegevens worden verwerkt, worden meegenomen. In artikel 13 en 14 AVG wordt toegelicht welke informatie in welke gevallen moet worden verstrekt door de verwerkersverantwoordelijke. Als persoonsgegevens worden verwerkt ten behoeve van het ontwikkelen of gebruiken van algoritmes en AI-systemen, zal deze informatie moeten worden verstrekt.</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 AVG Artikel 12, 13 en 14 AVG Overweging 58 AVG"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#risico","title":"Risico","text":"<p>Rechten van betrokken worden geschonden als er geen sprake is van transparantie over de verwerkingen van de persoonsgegevens.</p>"},{"location":"vereisten/transparantie_bij_verwerken_persoonsgegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/","title":"Verantwoordingsplicht voor de rechtmatigheid van de verwerking","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieMonitoring en beheerUitfaserenGovernancePrivacy en gegevensbescherming</p>"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#vereiste","title":"Vereiste","text":"<p>De verantwoordelijken moeten bij de verwerking van persoonsgegevens door algoritmes en AI-systemen kunnen aantonen dat de verwerkingen rechtmatig plaatsvinden. Dit betekent concreet dat de volgende punten aangetoond kunnen worden:</p> <ul> <li>Rechtmatigheid, behoorlijkheid en transparantie</li> <li>Doelbinding</li> <li>Minimale gegevensverwerking</li> <li>Juistheid</li> <li>Opslagbeperking</li> <li>Integriteit en vertrouwelijkheid Een aandachtpunt daarbij is dat de rechtmatigheid van de verwerking ten opzichte van andere gerelateerde wetgeving zoals de AI Act en de Algemene wet gelijke behandeling ook moeten kunnen worden aangetoond voor zover de rechtmatigheid van de verwerking onder de AVG daarvan afhankelijk is.</li> </ul>"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#toelichting","title":"Toelichting","text":"<p>Bij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.</p>"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#bronnen","title":"Bronnen","text":"Bron Artikel 5 AVG Verantwoordingsplicht]"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"<p>Deze vereiste is van toepassing op alle algoritmen die persoonsgegevens verwerken.</p>"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#risico","title":"Risico","text":"<p>Het niet naleven van deze norm moet worden gekwalificeerd als een onrechtmatigheid, niet als een risico voor de rechten en vrijheden van betrokkenen onder de AVG. Maar het niet voldoen aan artikel 5 betekent in de praktijk vaak wel dat er onvoldoende zicht is op risico's voor de rechten en vrijheden van betrokkenen of dat er te grote risico's worden genomen. Deze gevolgen zijn echter indirect een gevolg van het niet naleven van artikel 5 AVG. Het moeten voldoen aan het aantoonbaarheidsvereiste kan wel risico's hebben voor de organisatie die een algortime inzet. Enkele risico's zijn:</p> <ul> <li>Aantoonbaarheidsvereisten vragen in de praktijk veel documentatie. Deze documentatie kan via de Woo opgevraagd worden. Het ontbreken van documentatie kan door externen vaak relatief makkelijk in verband worden gebracht met een overtreding van deze vereisten.</li> <li>Algoritmen die van nature slecht inzichtelijk en uitlegbaar zijn (zoals deep-learning) hebben een zeer hoge drempel om aan deze vereiste te voldoen. Aantonen van rechtmatigheid is voor een belangrijk deel afhankelijk van inzicht in de werking van het algoritme. De inzet van een algortime kan dus mogelijk tegengehouden worden door deze vereisten.</li> <li>Bij leveranciers die niet of gedeeltelijke transparant zijn over hun product of dienstverlening ontstaat een vergelijkbaar risico. Waar de Woo uitzonderingen heeft voor bedrijfsgeheimen heeft de AVG daar maar beperkte ruimte voor. Het is dus mogelijk dat leveranciers terughoudend zullen zijn met het delen van informatie die onder de AVG ook aan betrokkenen gecommuniceerd moeten worden.</li> <li>Samenwerkingsverbanden en externe leveranciers kunnen niet als argumenten worden gebruikt om de aantoonbaarheidsvereisten op af te schuiven. Onafhankelijk van de onderlinge afspraken daarover hebben alle verwerkingsverantwoordelijken de verplichting om aan deze vereisten te kunnen voldoen. </li> </ul>"},{"location":"vereisten/verantwoordingsplicht_rechtmatigheid/#maatregelen","title":"Maatregelen","text":"MaatregelUitleg"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/","title":"Verboden toepassingen bij evaluatie of classificatie van personen of groepen personen","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernanceFundamentele rechten</p>"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#vereiste","title":"Vereiste","text":"<p>Het in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft:</p> <ol> <li> <p>de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld;</p> </li> <li> <p>de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is.</p> </li> </ol>"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#toelichting","title":"Toelichting","text":"<p>AI-systemen die door publieke of door private actoren worden gebruikt om een beoordeling van natuurlijke personen (\u201csocial scoring\u201d) uit te voeren, kunnen discriminerende resultaten en de uitsluiting van bepaalde groepen tot gevolg hebben. Deze systemen kunnen een schending inhouden van het recht op waardigheid en nondiscriminatie en van waarden als gelijkheid en rechtvaardigheid. Dergelijke AI-systemen beoordelen of classificeren natuurlijke personen of groepen natuurlijke personen op basis van meerdere datapunten met betrekking tot hun sociale gedrag in meerdere contexten of op basis van bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken gedurende een bepaalde periode. De sociale score die deze AI-systemen opleveren, kan leiden tot een nadelige of ongunstige behandeling van personen of hele groepen personen in sociale contexten die geen verband houden met de context waarin de data oorspronkelijk zijn gegenereerd of verzameld, of tot een nadelige behandeling die onevenredig of ongerechtvaardigd is in verhouding tot de ernst van het sociale gedrag. AI-systemen die onaanvaardbare scoringpraktijken met zich meebrengen en tot dergelijke nadelige of ongunstige resultaten leiden, moeten daarom worden verboden. Dat verbod mag geen afbreuk doen aan wettige praktijken voor de evaluatie van natuurlijke personen die worden verricht voor een specifieke doeleinde in overeenstemming met het Unierecht en het nationale recht.</p>"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#bronnen","title":"Bronnen","text":"Bron Artikel 5 lid 1 sub c AI Verordening"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#risico","title":"Risico","text":"<p>Het risico ontstaat dat personen of bepaalde groepen worden gediscrimineerd en uitgesloten, wat een schending kan inhouden van het recht op waardigheid, non-discriminatie en van waarden als gelijkheid en rechtvaardigheid.</p>"},{"location":"vereisten/verboden_toepassingen_evaluatie_of_classificatie_natuurlijke_personen_of_groepen_personen/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/","title":"Verdere verwerking van persoonsgegevens in AI-testomgevingen","text":"<p>OntwikkelenDataverkenning en datapreparatiePrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#vereiste","title":"Vereiste","text":"<p>Rechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.</p>"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens voor AI-testdoeleinden is mogelijk maar het moet voldoen aan strikte voorwaarden die zijn opgenomen in artikel 57 AI-Verordening. Hierbij kan worden gedacht aan voorwaarden als het beschermen van persoonsgevens met passende technische en organisatorische maatregelen,  persoonsgegevens die in de testomgeving worden aangemaakt mogen niet buiten de testomgeving worden gedeeld en logbestanden worden bijgehouden voor de duur van de deelname aan de testomgeving. Voor toepassingen voor het verder verwerken van gegevens kan worden gedacht aan het ontwikkelen van een AI-systeem zodat een overheidsinstantie of een andere natuurlijke of rechtspersoon een aanzienlijk openbaar belang kan waarborgen, bijvoorbeeld op het gebied van kwaliteit van milieu, duurzaamheid, openbare veiligheid en gezondheid.</p>"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#bronnen","title":"Bronnen","text":"Bron Artikel 57(1) Verdere verwerking van persoonsgegevens voor het ontwikkelen van bepaalde AI-systemen"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#risico","title":"Risico","text":"<p>Verdere verwerking van persoonsgegevens buiten een AI-testomgeving vergroot de kans op bijvoorbeeld het lekken van de persoonsgegevens, wat kan leiden tot een inbreuk op de privacyrechten van betrokken.</p>"},{"location":"vereisten/verdere_verwerking_van_persoonsgegevens_in_ai_testomgevingen/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/","title":"Verplicht risicobeheersysteem voor hoog-risico AI","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernance</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#vereiste","title":"Vereiste","text":"<p>Voor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#toelichting","title":"Toelichting","text":"<p>Het systeem voor risicobeheer moet bestaan uit een tijdens de gehele levensduur van een AI-systeem met een hoog risico doorlopend en gepland iteratief proces. Dit proces moet gericht zijn op het vaststellen en beperken van de relevante risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten. Het systeem voor risicobeheer moet periodiek worden ge\u00ebvalueerd en geactualiseerd om de blijvende doeltreffendheid ervan te waarborgen, alsook de motivering en de documentatie van eventuele significante besluiten en maatregelen die op grond van de AI-verordening zijn genomen.</p> <p>Dit proces moet ervoor zorgen dat de aanbieder de risico\u2019s of negatieve effecten vaststelt en risicobeperkende maatregelen uitvoert voor de bekende en de redelijkerwijs te voorziene risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten. Hierin moeten ook maatregelen zitten voor redelijkerwijs te voorzien misbruik, met inbegrip van de mogelijke risico\u2019s die voortvloeien uit de wisselwerking tussen het AI-systeem en de omgeving waarin het werkt. Het systeem voor risicobeheer moet de passendste risicobeheersmaatregelen vaststellen. Bij het vaststellen van de passendste risicobeheersmaatregelen moet de aanbieder de gemaakte keuzes documenteren en toelichten en, in voorkomend geval, deskundigen en externe belanghebbenden betrekken. Bij het vaststellen van het redelijkerwijs te voorzien misbruik van AI-systemen met een hoog risico moet de aanbieder aandacht hebben voor het gebruik van AI-systemen waarvan, hoewel zij niet rechtstreeks onder het beoogde doel vallen en niet in de gebruiksinstructies worden vermeld, mag worden verwacht dat zij kunnen voortvloeien uit gemakkelijk voorspelbaar menselijk gedrag.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#bronnen","title":"Bronnen","text":"Bron Artikel 9(1) Systeem voor risicobeheer - AI verordening"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#risico","title":"Risico","text":"<p>Het ontbreken van risicobeheer kan leiden tot schade aan gebruikers of derden en wettelijke aansprakelijkheid voor de aanbieder.</p>"},{"location":"vereisten/verplicht_risicobeheersysteem_voor_hoog_risico_ai/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/","title":"Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden","text":"<p>OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenTransparantie</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden hebben een bijzondere rol en verantwoordelijkheid. Zij leveren modellen die de basis kunnen vormen voor weer andere systemen en algoritmen, die vaak weer door andere partijen worden aangeboden dan de ontwikkelaar van het algemene systeem. Dit vraagt om een goed inzicht in de modellen en hun capaciteiten, zowel qua integratie van de modellen in producten als qua naleving van verplichtingen.</p> <p>Er zijn daarom evenredige transparantiemaatregelen nodig, zoals het opstellen en bijwerken van documentatie en verstrekken van informatie over het AI-model voor algemeen gebruik door de aanbieders van systemen die de algemene modellen gebruiken in hun product. De aanbieder van het AI-model voor algemene doeleinden dient technische documentatie op te stellen en bij te werken om deze op verzoek te kunnen overleggen aan het AI-bureau en de nationale bevoegde autoriteiten. De minimaal in de documentatie op te nemen elementen moeten worden vastgelegd volgens bijlage XII van de AI-Verordening. Hierbij is het ook van belang dat de aanbieder van AI-modellen voor algemene doelstelling beleid opstellen voor naleving van auteursrechten en naburige rechten (artikel 4, lid 3 Richtlijn (EU) 2019/790).</p> <p>In art. 53 lid 2 wordt een uitzondering gemaakt op deze vereisten.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#bronnen","title":"Bronnen","text":"Bron Artikel 53 AI-Verordening"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#risico","title":"Risico","text":"<p>Het niet voldoen aan deze verplichtingen kan leiden tot juridische en ethische complicaties, inclusief schendingen van auteursrechten en gebrek aan transparantie in het gebruik van AI-modellen.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/","title":"Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico","text":"<p>OntwikkelenVerificatie en validatieImplementatieMonitoring en beheerGovernance</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperken.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#toelichting","title":"Toelichting","text":"<p>De aanbieders van AI-modellen voor algemene doeleinden die systeemrisico\u2019s inhouden, moeten, naast de verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden, onderworpen worden aan verplichtingen die gericht zijn op het identificeren en beperken van die risico\u2019s en op waarborging van een passend niveau van cyberbeveiliging, ongeacht of het model een op zichzelf staand model is of ingebed in een AI-systeem of in een product. Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluaties uitvoeren. Dit omvat het testen en documenteren van het model volgens de stand van de techniek, met specifieke aandacht voor het identificeren en beperken van kwetsbaarheden. Deze maatregelen zijn bedoeld om systematische risico's te adresseren en te verminderen. Deze vereiste is een aanvulling op de genoemde verplichtingen in artikel 53 van de AI-verordening.</p> <p>Systeemrisico betekent: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleienden, die aanzienlijke gevolgen hebben voor de markt van de Uniek vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid.</p> <p>Systeemrisico\u2019s nemen logischerwijs toe naargelang de capaciteiten en het bereik van een model groter zijn, kunnen zich voordoen gedurende de gehele levenscyclus van het model en worden be\u00efnvloed door elementen als misbruik van het model, de betrouwbaarheid, billijkheid, beveiliging en mate van autonomie ervan. Ook worden ze be\u00efnvloed door de toegang van het model tot instrumenten, nieuwe of gecombineerde modaliteiten, introductie- en distributiestrategie\u00ebn, en door het potentieel om waarborgen te omzeilen en andere factoren.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#bronnen","title":"Bronnen","text":"Bron Artikel 55 AI-Verordening Overweging 110 AI-Verordening"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot negatieve gevolgen voor de gezondheid, veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel.</p>"},{"location":"vereisten/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/","title":"Verstrekking van informatie op verzoek","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernance</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#vereiste","title":"Vereiste","text":"<p>Op een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen offici\u00eble taal van de instellingen van de Unie. Onderdeel van dit verzoek kan zijn het toegang geven tot de in artikel 12 lid 1 bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten op verzoek van een bevoegde autoriteit alle benodigde informatie verstrekken om de conformiteit met de voorschriften van de AI-verordening aan te tonen. Deze informatie moet worden verstrekt in een begrijpelijke offici\u00eble taal van de EU, zoals gekozen door de betrokken lidstaat.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#bronnen","title":"Bronnen","text":"Bron Artikel 21 Samenwerking met bevoegde autoriteiten- AI verordening"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#risico","title":"Risico","text":"<p>Weigering om informatie te verstrekken kan leiden tot juridische sancties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/verstrekking_van_informatie_op_verzoek/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingDoor aanbieders bewijs te laten leveren dat zij voldoen aan de vereiste, kan worden beoordeeld in hoeverre daadwerkelijk wordt voldaan aan deze vereiste.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Maak de vereiste onderdeel van Service Level AgreementOnderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement. Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Door de vereiste op te nemen als subgunningscriteria ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/","title":"Werknemersvertegenwoordigers en betrokken werknemers worden ge\u00efnformeerd door de gebruiksverantwoordelijken die werknemers zijn, voordat een hoog risico AI-systeem wordt ingezet","text":"<p>ImplementatieOntwerpGovernance</p>"},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#vereiste","title":"Vereiste","text":"<p>Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.</p>"},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#toelichting","title":"Toelichting","text":"<p>Dit vereiste benadrukt het belang van het informeren van werknemersvertegenwoordigers en betrokken werknemers over de inzet van een hoog risico AI-systeem op de werkplaats. Dit dient voorafgaand aan de inzet van het systeem plaats te vinden. De gebruiksverantwoordelijke als werknemer dient hier zorg voor te dragen.</p>"},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#bronnen","title":"Bronnen","text":"Bron Artikel 26(7) AI Verordening"},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#risico","title":"Risico","text":"<p>Als werknemersvertegenwoordigers en werknemers niet worden ge\u00efnformeerd over de inzet van een hoog risico AI-systeem, kunnen zij zich niet weren tegen mogelijk ongewenste en negatieve effecten van de inzet van het hoog risico AI-systeem.</p>"},{"location":"vereisten/werknemersvertegenwoordigers_en_betrokken_werknemers_worden_ge%C3%AFnformeerd_inzet_hoog_risico_AI/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitleg MaatregelUitleg MaatregelUitleg"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/","title":"Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens","text":"<p>OntwerpDataverkenning en datapreparatiePrivacy en gegevensbeschermingFundamentele rechten</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#vereiste","title":"Vereiste","text":"<p>Bijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens die door hun aard bijzonder gevoelig zijn wat betreft de grondrechten en fundamentele vrijheden, verdienen specifieke bescherming. Dit komt doordat de context van de verwerking ervan significante risico's kan meebrengen voor de grondrechten en de fundamentele vrijheden. Denk hierbij aan persoonsgegevens als ras, ethnische afkomst, politieke opvattingen of religieuze of levenschouwelijke overtuigingen.</p> <p>Bijzondere categorie\u00ebn persoonsgegevens mogen alleen worden verwerkt als er hier een wettelijke uitzondering voor is (art. 9 AVG en art. 30 UAVG). Deze vereiste is ook van toepassing bij het ontwikkelen en gebruiken van algoritmes of AI-systemen en stelt daarmee beperkingen aan het mogen verwerken van deze categorie\u00ebn persoonsgegevens, bv. ten behoeve van trainingsdata of het genereren van de beoogde output.</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#bronnen","title":"Bronnen","text":"Bron Artikel 9 AVG Overweging 51 - 54 AVG Hoofdstuk 22 - 30 UAVG"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#risico","title":"Risico","text":"<p>Het (onrechtmatige) verwerken van bijzondere categorie\u00ebn persoonsgegevens brengt risico's met zich mee op het gebied van respecteren van de persoonlijke levenssfeer en discriminatie.</p>"},{"location":"vereisten/wettelijke_verwerking_van_gevoelige_gegevens/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste. MaatregelUitleg MaatregelUitlegBespreek de vereiste met aanbieder of opdrachtnemerGa met aanbieder of opdrachtnemer in gesprek over in hoeverre invulling is gegeven of kan worden gegeven aan de vereiste.Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Om op een betekenisvolle manier invulling te geven bepaalde vereisten, kan het nodig zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenDoor de vereiste onderdeel te maken van het programma van eisen bij de aanbesteding, is het voor aanbieders duidelijk aan welke specifieke eisen hun oplossing moet voldoen.Maak de vereiste onderdeel van contractvoorwaardenDoor de vereiste onderdeel te maken van contractvoorwaarden, is het voor aanbieders vooraf duidelijk waar zij aan moeten voldoen.Maak de vereiste onderdeel van de contractovereenkomstDoor de vereiste onderdeel te maken van de contractvereenkomst, worden deze contractueel afdwingbaar.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstHet is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de vereiste."},{"location":"vereisten/zorgvuldigheidsbeginsel/","title":"Relevante feiten en belangen zijn bekend","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenGovernance</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#vereiste","title":"Vereiste","text":"<p>De ontwikkeling en het gebruik van algoritmes en AI-systemen komt zorgvuldig tot stand.</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#toelichting","title":"Toelichting","text":"<p>Dit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming.</p> <p>Het doel en eventuele subdoelen van het algoritme of AI-systeem moet helder zijn gedefinieerd, ook in relatie tot het maatschappelijke resultaat (outcome), en wordt gedeeld door de eigenaar, ontwikkelaar en gebruiker van het algoritme. Een bewuste afweging of het algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen is gemaakt en vastgelegd. </p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#bronnen","title":"Bronnen","text":"Bron Afdeling 3.2 Algemene wet bestuursrecht Afdeling 3.4 Algemene wet bestuursrecht"},{"location":"vereisten/zorgvuldigheidsbeginsel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":"RekenregelMachine learningGeneratieve AI niet-impactvol impactvol niet-impactvol impactvol hoog-risico-ai niet-impactvol impactvol hoog-risico-ai"},{"location":"vereisten/zorgvuldigheidsbeginsel/#risico","title":"Risico","text":"<p>De werking van het algoritmes of AI sluit niet of onvoldoende aan bij de juridische en ethische grenzen van de te ondersteunen wettelijke taak. Hierdoor kunnen ongewenste gevolgen ontstaan zoals een onjuist of onzorgvuldig genomen besluit op een aanvraag.</p>"},{"location":"vereisten/zorgvuldigheidsbeginsel/#maatregelen","title":"Maatregelen","text":"AllenGovernancePublieke inkoop MaatregelUitlegFormuleren doelstellingHet doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.Formuleren aanleiding en probleemdefinitieFormuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.Formuleren aanleiding en probleemdefinitieBepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. MaatregelUitleg MaatregelUitleg"}]}